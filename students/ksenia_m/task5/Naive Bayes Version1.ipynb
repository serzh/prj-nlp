{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from ukr_stemmer3 import UkrainianStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksenia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_set = pd.read_csv('./collectdata/comments_ua.txt', sep = ':::::', names = [\"score\", \"comment\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.groupby(\"score\").count()\n",
    "data_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(data_set)) < 0.8\n",
    "train = data_set[msk]\n",
    "test = data_set[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_base_form(use_lemma, word):\n",
    "    if (use_lemma):\n",
    "        return UkrainianStemmer(word.lower()).stem_word()\n",
    "    return word.lower()\n",
    "\n",
    "def train_model(stop_words=[], use_lemma=False, **kwargs):\n",
    "    \n",
    "    def calc_probabilities_in_class(data):\n",
    "        bag_of_words = {}\n",
    "        for index, row in data.iterrows():\n",
    "            words = nltk.word_tokenize(row['comment'])\n",
    "            for word in words:\n",
    "                base_form = to_base_form(use_lemma, word)\n",
    "                if not base_form in stop_words:\n",
    "                    if not base_form in bag_of_words:\n",
    "                        bag_of_words[base_form] = 1\n",
    "                    else:\n",
    "                        bag_of_words[base_form] = bag_of_words[base_form] + 1\n",
    "        return bag_of_words\n",
    "    \n",
    "    probabilities = {}\n",
    "    for key in kwargs:\n",
    "        probabilities[key] = calc_probabilities_in_class(kwargs[key])\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def predict_model_comment(model, comment, stop_words = [], use_lemma = False):\n",
    "    \n",
    "    def comment_log_probabitlity(words, class_model, total_words, total_unique_words):\n",
    "        denominator = sum(class_model.values()) + total_unique_words\n",
    "        log_prob = math.log(sum(class_model.values()) / total_words)\n",
    "        for word in words:\n",
    "            n = class_model[word] if word in class_model else 0 \n",
    "            log_prob += math.log((n + 1)/denominator)\n",
    "        return log_prob\n",
    "        \n",
    "    log_probablitites = {}\n",
    "    words = [to_base_form(use_lemma, word) for word in nltk.word_tokenize(comment) if word.lower not in stop_words]\n",
    "    \n",
    "    total_words = 0\n",
    "    total_unique_words = 0\n",
    "    for key in model:\n",
    "        total_words += sum(model[key].values())\n",
    "        total_unique_words += len(model[key])\n",
    "        \n",
    "    for key in model:\n",
    "        log_probablitites[key] = comment_log_probabitlity(words, model[key], total_words, total_unique_words)\n",
    "    return log_probablitites\n",
    "\n",
    "def print_report(true_positive, true_negative, false_positive, false_negative):\n",
    "    print(\"True Positive:\", true_positive, \"; True negative:\", \n",
    "          true_negative, \"; False positive:\", false_positive, \"; False negative:\", false_negative)\n",
    "    print(\"Preсision:\", true_positive/(true_positive + false_positive),\n",
    "          \"; Recall:\", true_positive/(true_positive + false_negative), \"\\n\")\n",
    "\n",
    "def predict_on_set(predict_comment_lambda, test_set, labeled_negative):\n",
    "    \n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for index, row in test_set.iterrows():\n",
    "        max_prob = float('-inf')\n",
    "        max_key = \"\"\n",
    "        probs = predict_comment_lambda(row[\"comment\"])\n",
    "        for key_class in probs:\n",
    "            if probs[key_class] > max_prob:\n",
    "                max_prob = probs[key_class]\n",
    "                max_key = key_class\n",
    "        is_negative_eval = max_key == 'negative'\n",
    "        is_negative_label = labeled_negative(row[\"score\"]) \n",
    "        #print(\"is_negative_eval:\", is_negative_eval, \" is_neg_label:\", is_negative_label)\n",
    "      \n",
    "        if is_negative_eval and is_negative_label:\n",
    "            true_negative += 1\n",
    "            \n",
    "        if not is_negative_eval and not is_negative_label:\n",
    "            true_positive += 1\n",
    "            \n",
    "        if not is_negative_eval and is_negative_label:\n",
    "            false_positive += 1\n",
    "            \n",
    "        if is_negative_eval and not is_negative_label:\n",
    "            false_negative += 1\n",
    "        \n",
    "    return print_report(true_positive, true_negative, false_positive, false_negative)\n",
    "        \n",
    "def predict_random_comment(train_data, comment):\n",
    "    total_positive = train_data[train_data[\"score\"] > 3][\"comment\"].count()\n",
    "    positive_prob = total_positive / train_data[\"comment\"].count()\n",
    "\n",
    "    if random.random() > positive_prob:\n",
    "        return {\"positive\": 0, \"negative\": 1}\n",
    "    return {\"positive\": 1, \"negative\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pure model (no rules or sentiment dictionary) and compare it with random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pure model on test(just to check that algorythm is corect):\n",
      "True Positive: 2202 ; True negative: 156 ; False positive: 105 ; False negative: 45\n",
      "Presision: 0.9544863459037711 ; Recall: 0.9799732977303071\n",
      "For pure model on test:\n",
      "True Positive: 506 ; True negative: 16 ; False positive: 48 ; False negative: 48\n",
      "Presision: 0.9133574007220217 ; Recall: 0.9133574007220217\n",
      "For random:\n",
      "True Positive: 488 ; True negative: 2 ; False positive: 62 ; False negative: 66\n",
      "Presision: 0.8872727272727273 ; Recall: 0.8808664259927798\n"
     ]
    }
   ],
   "source": [
    "model = train_model(positive = train[train[\"score\"] > 3], negative = train[train[\"score\"] <= 3])\n",
    "print(\"For pure model on test(just to check that algorythm is corect):\")\n",
    "predict_on_set(lambda comment: predict_model_comment(model, comment), train, lambda x: x <= 3)\n",
    "print(\"For pure model on test:\")\n",
    "predict_on_set(lambda comment: predict_model_comment(model, comment), test, lambda x: x <= 3)\n",
    "print(\"For random:\")\n",
    "predict_on_set(lambda comment: predict_random_comment(train, comment), test, lambda x: x <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-6f3afd210a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_as_words = [({word: (word in nltk.word_tokenize(row[\"comment\"])) for word in all_words},\n\u001b[0;32m----> 4\u001b[0;31m                    \"negative\" if row[\"score\"] <= 3 else \"positive\")  for index,row in train.iterrows()]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_as_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-229-6f3afd210a82>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_as_words = [({word: (word in nltk.word_tokenize(row[\"comment\"])) for word in all_words},\n\u001b[0;32m----> 4\u001b[0;31m                    \"negative\" if row[\"score\"] <= 3 else \"positive\")  for index,row in train.iterrows()]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_as_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-229-6f3afd210a82>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check classifier from nltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_as_words = [({word: (word in nltk.word_tokenize(row[\"comment\"])) for word in all_words},\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \"negative\" if row[\"score\"] <= 3 else \"positive\")  for index,row in train.iterrows()]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kseniia/anaconda/envs/py36/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     return [token for sent in sentences\n\u001b[0m\u001b[1;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m/Users/kseniia/anaconda/envs/py36/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 132\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[0;32m/Users/kseniia/anaconda/envs/py36/lib/python3.6/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# We are not using CONTRACTIONS4 since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check classifier from nltk\n",
    "all_words = set(word.lower() for index,row in train.iterrows() for word in nltk.word_tokenize(row[\"comment\"]))\n",
    "train_as_words = [({word: (word in nltk.word_tokenize(row[\"comment\"])) for word in all_words},\n",
    "                   \"negative\" if row[\"score\"] <= 3 else \"positive\")  for index,row in train.iterrows()]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_as_words)\n",
    "classifier.show_most_informative_features()\n",
    "    \n",
    "def prdic_by_nltk(comment):\n",
    "    global all_words\n",
    "    global classifier\n",
    "    test_sent_features = {word.lower(): (word in nltk.word_tokenize(comment.lower())) for word in all_words}\n",
    "    label = classifier.classify(test_sent_features)\n",
    "    return {\"positive\": (1 if label == \"positive\" else 0), \"negative\": (1 if label == \"negative\" else 0)}\n",
    "\n",
    "predict_on_set(prdic_by_nltk, test, lambda x: x <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for use sentiment dictionary (if both + and - select lareger module)\n",
      "True Positive: 549 ; True negative: 2 ; False positive: 62 ; False negative: 5\n",
      "Presision: 0.8985270049099836 ; Recall: 0.9909747292418772 \n",
      "\n",
      "Test for use sentiment dictionary (if both + and - skip)\n",
      "True Positive: 540 ; True negative: 3 ; False positive: 61 ; False negative: 14\n",
      "Presision: 0.8985024958402662 ; Recall: 0.9747292418772563 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tonal_dict = pd.read_csv('../../../../sources/tone-dict-uk.tsv', sep = '\\t', names = [\"word\", \"sentiment\"])\n",
    "\n",
    "def predict_comment_with_tonal(model, comment, skip_contradict = False):\n",
    "    \n",
    "    def sentiment_score():\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        for index, row in tonal_dict.iterrows():\n",
    "            if to_base_form(True, row[\"word\"]) in comment:\n",
    "                if int(row[\"sentiment\"]) > 0:\n",
    "                    positive += int(row[\"sentiment\"])\n",
    "                else:\n",
    "                    negative += int(row[\"sentiment\"])\n",
    "        #use only if there is no contradictions\n",
    "        if skip_contradict and positive != 0 and negative != 0:\n",
    "            return 0\n",
    "        return positive if positive > -negative else negative\n",
    "            \n",
    "    score = sentiment_score()\n",
    "   \n",
    "    if score > 0:\n",
    "        return {\"positive\": 1, \"negative\":0}\n",
    "    if score < 0:\n",
    "        return {\"negative\": 0, \"positive\":1}\n",
    "    \n",
    "    return predict_model_comment(model, comment)\n",
    "\n",
    "print(\"Test for use sentiment dictionary (if both + and - select lareger module)\")  \n",
    "predict_on_set(lambda comment: predict_comment_with_tonal(model, comment), test, lambda x: x <= 3)\n",
    "\n",
    "print(\"Test for use sentiment dictionary (if both + and - skip)\")  \n",
    "predict_on_set(lambda comment: predict_comment_with_tonal(model, comment, True), test, lambda x: x <= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words(model, tonal_dict):\n",
    "    def is_tonal(word):\n",
    "        for index, row in tonal_dict.iterrows():\n",
    "            if to_base_form(True, row[\"word\"]) in word:\n",
    "                return True\n",
    "        return False\n",
    "                \n",
    "    stop_words = []\n",
    "    for word, rank in sorted(model[\"positive\"].items(), key=lambda kv: kv[1], reverse=True):\n",
    "        if rank > 100 and not is_tonal(word):\n",
    "            stop_words.append(word)\n",
    "    return stop_words\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', ',', 'на', 'не', 'і', '!', 'в', ')', 'з', 'для', 'за', '-', 'що', 'як', 'але', 'все', '(', 'та', 'у', 'до', '?', 'це', 'а', 'я', 'від', 'можна', '%', 'по', ':', '2', 'рекомендую', 'так', 'ще', 'є', 'вже', 'то']\n"
     ]
    }
   ],
   "source": [
    "stop_words = get_stop_words(model, tonal_dict)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рекомендув\n",
      "['.', ',', 'на', 'не', 'і', '!', 'в', ')', 'з', 'для', 'за', '-', 'що', 'як', 'але', 'все', '(', 'та', 'у', 'до', '?', 'це', 'а', 'я', 'від', 'можна', '%', 'по', ':', '2', 'так', 'ще', 'є', 'вже', 'то']\n"
     ]
    }
   ],
   "source": [
    "print(to_base_form(True, 'рекомендувати'))\n",
    "stop_words.remove('рекомендую')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train with stop words and stemming:\n",
      "True Positive: 323 ; True negative: 43 ; False positive: 21 ; False negative: 231\n",
      "Presision: 0.938953488372093 ; Recall: 0.5830324909747292 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_ext = train_model(stop_words, True, positive = train[train[\"score\"] > 3], negative = train[train[\"score\"] <= 3])\n",
    "print(\"For train with stop words and stemming:\")\n",
    "predict_on_set(lambda comment: predict_model_comment(model_ext, comment, stop_words, True), test, lambda x: x <= 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
