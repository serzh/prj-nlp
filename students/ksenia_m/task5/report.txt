Досліджувалась категорія "Спорт та дозвілля"

Всього було отримано 3126 коментарів з них:
	
score	comment
1	70
2	84
3	171
4	605
5	2196

Ділимо вибірку та тренувальну(80%) та тестувальну(20%)

Перший запуск классифікатора на тестовій вибірці (без лематизації та стоп слів) дає наступні резульатти

For pure model on test:
True Positive: 506 ; True negative: 16 ; False positive: 48 ; False negative: 48
Precision: 0.9133574007220217 ; Recall: 0.9133574007220217                          (*)                   

Що зароджують деяки сумніви в правильності алгорітму. Порівняємо з рендомом 

For random:
True Positive: 488 ; True negative: 2 ; False positive: 62 ; False negative: 66
Precision: 0.8872727272727273 ; Recall: 0.8808664259927798

Модель вийшла краще рендома на 3%. Це є добре.
Порівняємо що модель видасть на тренувальній вибірці

For pure model on test(just to check that algorithm is correct):
True Positive: 2202 ; True negative: 156 ; False positive: 105 ; False negative: 45
Preсision: 0.9544863459037711 ; Recall: 0.9799732977303071

Як і очікувалось, резульат значно краще, але все одно не теоретичний 99%, що все ще заглиблює сумніви у правильністі реалізації алгориму. Тому порівняємо з дефолтним классифікатором.

Після довгих обрахунків отримуємо для nltk.NaiveBayesClassifier

True Positive: 536 ; True negative: 8 ; False positive: 56 ; False negative: 18
Preсision: 0.9054054054054054 ; Recall: 0.9675090252707581

Отже наша модель на 1% вийшла краще за дефолтну реалізацю, що добре, бо результати не сильно відрізняється і різниця у позитивний бік.

Крім того маємо цікаву статистику слів що більш всього впливають на негативність коментару, 
мабуть у розетці не все гарно з велосипедами і у спортивному хачруванні багато цукру. 

Most Informative Features
                  жодної = True           negati : positi =     20.0 : 1.0
              велосипеда = True           negati : positi =     20.0 : 1.0
            розчарування = True           negati : positi =     20.0 : 1.0
                   цукру = True           negati : positi =     20.0 : 1.0
                 залишив = True           negati : positi =     20.0 : 1.0
                   тонка = True           negati : positi =     20.0 : 1.0
                 ніякого = True           negati : positi =     20.0 : 1.0
                 питання = True           negati : positi =     18.9 : 1.0
             гарантійний = True           negati : positi =     15.4 : 1.0
                  реагує = True           negati : positi =     15.4 : 1.0

Щоб покращити алгорітм застосуємо тональний словник. Якщо є позитивні та негативні слова -
беремо більше за модулем і визначаємо лише словником, якщо нема тональних слів то застосовуємо модель,
що було обраховано раніше 
отримуємо:
Test for use sentiment dictionary (if both + and - select larger module)
True Positive: 549 ; True negative: 2 ; False positive: 62 ; False negative: 5
Preсision: 0.8985270049099836 ; Recall: 0.9909747292418772 

Бачимо що модель проацює гірше за (*) стало більше false positive. Спробуємо застосовувати 
класифікацює за тональним словником лише якщо воно однозначна (є лише негативні або лише позитивні слова)
Test for use sentiment dictionary (if both + and - skip)
True Positive: 540 ; True negative: 3 ; False positive: 61 ; False negative: 14
Preсision: 0.8985024958402662 ; Recall: 0.9747292418772563 

бачимо що False positive покращилось, але лише на 1, зате збільшилось False negative з 5 до 14

Щоб отримати словник стоп слів - виберемо найбілшь популярні слова для позитивного сета(бо він значно більший за негативний)
та візьмемо з ньго слова що не містяться у словнику сентіментів. 
Бачимо що в нас в словник потрапило слово 'рекомендую', що безумовно є позитивним словом.
(потрапило бо для нашего стемера корінь від 'рекомендувати' є 'рекомендув'), видаляємо його зі словника стоп слів.

Щоб покращити алгоритм застосуємо стоп слова та лемматизацію отримаємо покращення
майже на 4 процента.
For train with stop words and stemming:
True Positive: 323 ; True negative: 43 ; False positive: 21 ; False negative: 231
Preсision: 0.938953488372093 ; Recall: 0.5830324909747292 