{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition-based arc-eager unlabeled dependency parser for Ukrainian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data\n",
    "\n",
    "Useful links:\n",
    "* [UD corpus for Ukrainian](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
    "* [Easy-to-use library for parsing UD](https://github.com/EmilStenstrom/conllu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "PATH = \"/Users/admin/edu/NLP/\"\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-train.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "trees = parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "tree = trees[0]\n",
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design actions and the oracle\n",
    "\n",
    "We will be using a static oracle that reproduces a single valid order of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "\n",
    "def oracle(top_stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         top_queue[\"head\"] < top_stack[\"id\"]:\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack: ['ROOT']\n",
      "Queue: ['У', 'домі', 'римського', 'патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: []\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'У']\n",
      "Queue: ['домі', 'римського', 'патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: []\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT']\n",
      "Queue: ['домі', 'римського', 'патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'домі']\n",
      "Queue: ['римського', 'патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'домі', 'римського']\n",
      "Queue: ['патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT', 'домі']\n",
      "Queue: ['патриція', 'Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'домі', 'патриція']\n",
      "Queue: ['Руфіна', 'була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'домі', 'патриція', 'Руфіна']\n",
      "Queue: ['була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'домі', 'патриція']\n",
      "Queue: ['була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'домі']\n",
      "Queue: ['була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT']\n",
      "Queue: ['була', 'прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була']\n",
      "Queue: ['прегарна', 'фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'прегарна']\n",
      "Queue: ['фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була']\n",
      "Queue: ['фреска', ',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска']\n",
      "Queue: [',', 'зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', ',']\n",
      "Queue: ['зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска']\n",
      "Queue: ['зображення', 'Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення']\n",
      "Queue: ['Венери', 'та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення', 'Венери']\n",
      "Queue: ['та', 'Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.SHIFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення', 'Венери', 'та']\n",
      "Queue: ['Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10)]\n",
      "Actions.LEFT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення', 'Венери']\n",
      "Queue: ['Адоніса', '.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення', 'Венери', 'Адоніса']\n",
      "Queue: ['.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення', 'Венери']\n",
      "Queue: ['.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска', 'зображення']\n",
      "Queue: ['.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'була', 'фреска']\n",
      "Queue: ['.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'була']\n",
      "Queue: ['.']\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11)]\n",
      "Actions.RIGHT\n",
      "========================\n",
      "Stack: ['ROOT', 'була', '.']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT', 'була']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Stack: ['ROOT']\n",
      "Queue: []\n",
      "Relations: [(1, 2), (3, 4), (4, 2), (5, 4), (2, 6), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Actions.REDUCE\n",
      "========================\n",
      "Gold relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n",
      "Retrieved relations:\n",
      "[(1, 2), (2, 6), (3, 4), (4, 2), (5, 4), (6, 0), (7, 8), (8, 6), (9, 10), (10, 8), (11, 10), (12, 13), (13, 11), (14, 6)]\n"
     ]
    }
   ],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack[-1] if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"] for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"] for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))\n",
    "\n",
    "trace_actions(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Reference: [Dependency Parsing by Kübler, McDonald, and Nivre](https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA21&hl=uk&source=gbs_toc_r&cad=4#v=onepage&q&f=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        if stack_top[\"feats\"]:\n",
    "            for k, v in stack_top[\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack_top[\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        if queue_top[\"feats\"]:\n",
    "            for k, v in queue_top[\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    if stack and queue:\n",
    "        features[\"distance\"] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trees):\n",
    "    features, labels = [], []\n",
    "    for tree in trees:\n",
    "        stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "        while queue or stack:\n",
    "            action = oracle(stack[-1] if len(stack) > 0 else None,\n",
    "                            queue[0] if len(queue) > 0 else None,\n",
    "                            relations)\n",
    "            features.append(extract_features(stack, queue))\n",
    "            labels.append(action.value)\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 14\n",
      "Number of actions: 29\n",
      "List of actions taken: ['shift', 'left', 'shift', 'shift', 'left', 'right', 'right', 'reduce', 'reduce', 'left', 'right', 'shift', 'left', 'right', 'shift', 'left', 'right', 'right', 'shift', 'left', 'right', 'reduce', 'reduce', 'reduce', 'reduce', 'right', 'reduce', 'reduce', 'reduce']\n",
      "Features:\n",
      "{'s0-word': 'ROOT', 's0-lemma': 'ROOT', 's0-tag': 'ROOT', 'q0-word': 'У', 'q0-lemma': 'у', 'q0-tag': 'ADP', 'q0-Case': 'Loc', 'q1-word': 'домі', 'q1-tag': 'NOUN', 'q2-tag': 'ADJ', 'q3-tag': 'NOUN', 'distance': 1}\n"
     ]
    }
   ],
   "source": [
    "features, labels = get_data([tree])\n",
    "print(\"Number of words:\", len(tree))\n",
    "print(\"Number of actions:\", len(labels))\n",
    "print(\"List of actions taken:\", labels)\n",
    "print(\"Features:\")\n",
    "for word in features:\n",
    "    print(word)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 154709\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = get_data(trees)\n",
    "\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q0-tag</th>\n",
       "      <th>q1-tag</th>\n",
       "      <th>q2-tag</th>\n",
       "      <th>q3-tag</th>\n",
       "      <th>s0-tag</th>\n",
       "      <th>s1-tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q0-tag q1-tag q2-tag q3-tag s0-tag s1-tag\n",
       "0    ADP   NOUN    ADJ   NOUN   ROOT    NaN\n",
       "1   NOUN    ADJ   NOUN  PROPN    ADP    ADP\n",
       "2   NOUN    ADJ   NOUN  PROPN   ROOT    NaN\n",
       "3    ADJ   NOUN  PROPN   VERB   NOUN   NOUN\n",
       "4   NOUN  PROPN   VERB    ADJ    ADJ    ADJ"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[x for x in train_df.columns if 'tag' in x]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30661 30661\n"
     ]
    }
   ],
   "source": [
    "with open(PATH + \"/uk_iu-ud-test.conllu\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "test_trees = parse(data)\n",
    "test_features, test_labels = get_data(test_trees)\n",
    "print(len(test_features), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111525\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features + test_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 30661\n"
     ]
    }
   ],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(random_state=42)\n",
    "lrc.fit(train_features_vectorized, train_labels)\n",
    "predicted = lrc.predict(test_features_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.84      0.86      0.85      7352\n",
      "     reduce       0.81      0.73      0.77      8370\n",
      "      right       0.72      0.78      0.75      7182\n",
      "      shift       0.86      0.86      0.86      7757\n",
      "\n",
      "avg / total       0.81      0.81      0.81     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>reduce</th>\n",
       "      <th>right</th>\n",
       "      <th>shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>6296</td>\n",
       "      <td>394</td>\n",
       "      <td>326</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduce</th>\n",
       "      <td>557</td>\n",
       "      <td>6103</td>\n",
       "      <td>1372</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>212</td>\n",
       "      <td>880</td>\n",
       "      <td>5630</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>392</td>\n",
       "      <td>184</td>\n",
       "      <td>494</td>\n",
       "      <td>6687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        left  reduce  right  shift\n",
       "left    6296     394    326    336\n",
       "reduce   557    6103   1372    338\n",
       "right    212     880   5630    460\n",
       "shift    392     184    494   6687"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_fscore_support, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "classes = ['left', 'reduce', 'right', 'shift']\n",
    "conf_matrix = confusion_matrix(test_labels, predicted, labels=classes)\n",
    "pd.DataFrame(conf_matrix, columns=classes, index=classes)\n",
    "# conf_matrix_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the unlabeled attachment score\n",
    "UAS - the percentage of words in an input that are assigned the correct head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Зречення', 'культурної', 'ідентичності', '—', 'це', 'втрата', 'свободи', 'й', 'самовладності', '.']\n",
      "[(1, 0), (2, 3), (3, 1), (4, 6), (5, 6), (6, 1), (7, 6), (8, 9), (9, 7), (10, 0)]\n",
      "[(1, 6), (2, 3), (3, 1), (4, 6), (5, 6), (6, 0), (7, 6), (8, 9), (9, 7), (10, 6)]\n"
     ]
    }
   ],
   "source": [
    "print([node[\"form\"] for node in test_trees[0]])\n",
    "print(dep_parse(test_trees[0], lrc, vec))\n",
    "print([(node[\"id\"], node[\"head\"]) for node in test_trees[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 14939\n",
      "Correctly defined: 10236\n",
      "UAS: 0.69\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to add few more features to the model:\n",
    "<li>position in the sentance for q0 and s0</li>\n",
    "<li>is the words q0 and s0 are the Beggining or End of the sentence</li>\n",
    "<li>is the words q0 and s0 are neibhors in the sentence</li>\n",
    "<li>is punctuation before or after q0 (but not the '.')</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New feature generation function and normalize few features:\n",
    "<li>position and distance in the sentence. I assume, that the mean length of the sentence is 6, and the upper border is 12, so I am going to divide position in the sentence in 12, and if it > 1 the The value is 1</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_upd(stack, queue, sent_len):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        features[\"s0-start\"] = stack_top[\"id\"] == 0\n",
    "        features[\"s0-eos\"] = sent_len - stack_top[\"id\"] == 2\n",
    "        features[\"s0-posit\"] = 1.0 if stack_top[\"id\"] > 12 else (stack_top[\"id\"] + 1 / 12.0)\n",
    "        if stack_top[\"feats\"]:\n",
    "            for k, v in stack_top[\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack_top[\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        features[\"q0-start\"] = queue_top[\"id\"] == 0\n",
    "        features[\"q0-eos\"] = sent_len - queue_top[\"id\"] == 2\n",
    "        features[\"q0-posit\"] = 1.0 if queue_top[\"id\"] > 12 else (queue_top[\"id\"] + 1 / 12.0)\n",
    "        if queue_top[\"feats\"]:\n",
    "            for k, v in queue_top[\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "        features[\"q0-bef_punct\"] = queue_next[\"upostag\"] == \"PUNCT\" and queue_next[\"form\"] != \".\"\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    if stack and queue:\n",
    "        features[\"distance\"] = (queue[0][\"id\"] - stack[-1][\"id\"]) / 12.0\n",
    "        features[\"is-neib\"] = abs(queue[0][\"id\"] - stack[-1][\"id\"]) == 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataframe genearator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_upd(trees):\n",
    "    features, labels = [], []\n",
    "    for tree in trees:\n",
    "        stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "        while queue or stack:\n",
    "            action = oracle(stack[-1] if len(stack) > 0 else None,\n",
    "                            queue[0] if len(queue) > 0 else None,\n",
    "                            relations)\n",
    "            features.append(extract_features_upd(stack, queue, len(tree)))\n",
    "            labels.append(action.value)\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 154709\n"
     ]
    }
   ],
   "source": [
    "train_features_upd, train_labels_upd = get_data_upd(trees)\n",
    "print(len(train_features), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30661 30661\n"
     ]
    }
   ],
   "source": [
    "with open(PATH + \"/uk_iu-ud-test.conllu\", \"r\") as f:\n",
    "    data_test = f.read()\n",
    "\n",
    "test_trees = parse(data_test)\n",
    "test_features_upd, test_labels_upd = get_data_upd(test_trees)\n",
    "print(len(test_features_upd), len(test_labels_upd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111533\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec_upd = vectorizer.fit(train_features_upd + test_features_upd)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec_upd.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154709 30661\n"
     ]
    }
   ],
   "source": [
    "train_features_upd_vectorized = vec_upd.transform(train_features_upd)\n",
    "test_features_upd_vectorized = vec_upd.transform(test_features_upd)\n",
    "\n",
    "print(len(train_features_upd_vectorized.toarray()), len(test_features_upd_vectorized.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lru = LogisticRegression(random_state=42)\n",
    "lru.fit(train_features_upd_vectorized, train_labels_upd)\n",
    "predicted_upd = lru.predict(test_features_upd_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.85      0.86      0.86      7352\n",
      "     reduce       0.81      0.74      0.77      8370\n",
      "      right       0.72      0.79      0.75      7182\n",
      "      shift       0.86      0.86      0.86      7757\n",
      "\n",
      "avg / total       0.81      0.81      0.81     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_upd, predicted_upd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that after adding few new features the scores very slightly increased, so we can notice that this new features are not important and almoast useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic regression with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lrcv = LogisticRegressionCV(random_state=42, multi_class='multinomial')\n",
    "lrcv.fit(train_features_upd_vectorized, train_labels_upd)\n",
    "predicted_lrcv = lrcv.predict(test_features_upd_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.85      0.87      0.86      7352\n",
      "     reduce       0.83      0.73      0.78      8370\n",
      "      right       0.73      0.81      0.77      7182\n",
      "      shift       0.88      0.88      0.88      7757\n",
      "\n",
      "avg / total       0.82      0.82      0.82     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_upd, predicted_lrcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see a slight improvement in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SVM with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM classifier uses C parameter as panalty of the error term. I will prepare cross-validartion manually, because of big amount of resources are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(C=100, cache_size=1000)\n",
    "clf_svm.fit(train_features_upd_vectorized, train_labels_upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.77      0.86      0.81      7352\n",
      "     reduce       0.79      0.73      0.76      8370\n",
      "      right       0.76      0.72      0.74      7182\n",
      "      shift       0.85      0.87      0.86      7757\n",
      "\n",
      "avg / total       0.79      0.79      0.79     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = clf_svm.predict(test_features_upd_vectorized)\n",
    "print(classification_report(test_labels_upd, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.75      0.81      0.78      7352\n",
      "     reduce       0.76      0.69      0.73      8370\n",
      "      right       0.69      0.65      0.67      7182\n",
      "      shift       0.80      0.86      0.83      7757\n",
      "\n",
      "avg / total       0.75      0.75      0.75     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = clf_svm.predict(test_features_upd_vectorized)\n",
    "print(classification_report(test_labels_upd, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.60      0.79      0.68      7352\n",
      "     reduce       0.58      0.76      0.66      8370\n",
      "      right       0.87      0.18      0.29      7182\n",
      "      shift       0.72      0.80      0.75      7757\n",
      "\n",
      "avg / total       0.69      0.64      0.60     30661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = clf_svm.predict(test_features_upd_vectorized)\n",
    "print(classification_report(test_labels_upd, predicted_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that sligthly tuned Logistic Regression did not beat SVM. But more tuning is needed, Unfortunately, My resources are limited but if I had, the SVM results would be better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PNCT\": \"PUNCT\", \"PRED\": \"ADV\", \"PREP\": \"ADP\",\n",
    "           \"PRCL\": \"PART\"}\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if \"coord\" in word.tag:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    else:\n",
    "        return mapping.get(word.tag.POS, word.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
