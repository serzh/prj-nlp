Дані

Дані було сгенеровано на основі корпусу коментарів з Reddit за вересень 2015 року. Усього було зібрано ~140к коментарів, з яких 10к було використано для генерації тренувальних даних та 50к для оцінки 1-2-3-грам.

Модель

На усіх ітераціях використовувалась логістична регресія. 

Фічі

Спочатку були побудовані наступні фічі для слова та його сусідів: форма (Хххх, is title, is digit, is upper, is bracket, is alphanumeric, etc.), лема, POS тег, чи є стоп-словом, etc. 
Далі були додані н-грами з СОСА та додана фіча P(w_n|w_n-1), що суттєво покращило результат. 
На наступній ітерації н-грами були замінені на власні, що оцінювалися за допомогою розширенного тренувального корпусу та отримано додаткові фічі P(DOT|w_n) та P(DOT|w_n, w_n-1), що покращило результат в порівнянні з СОСА н-грамами. Цей результат поки є найкращим з усіх ітерацій.

Найкращий результат на датасеті run-on-test.json

Metrics:

Recall: 0.947
Precision: 0.971
F1: 0.956
accuracy: 0.947

Confusion matrix:

       pred_False  pred_True
False        4327        215
True           35        120

Report:

             precision    recall  f1-score   support

      False       0.99      0.95      0.97      4542
       True       0.36      0.77      0.49       155

avg / total       0.97      0.95      0.96      4697
