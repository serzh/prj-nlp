## Дані
* Було отримано 3797 відгуків українською мовою з категорії "Смартфони"
* Класи не є збалансованими, близько 66% відсотків відгуків мають 5 зірочок

## Моделювання
Для моделювання використовувався Multinominal NB та XGBoost

1. Спочатку було побудовано простий бейзлайн - будь-який коментар має 5 зірок, результати:

Recall: 	0.604  
Precision: 	0.365  
F1: 		0.455  
accuracy: 	0.604  

   	class	pred_1  pred_2  pred_3  pred_4  pred_5

	1       0       0       0       0      28
	2       0       0       0       0      27
	3       0       0       0       0      48
	4       0       0       0       0     198
	5       0       0       0       0     459

             precision    recall  f1-score   support

          1       0.00      0.00      0.00        28
          2       0.00      0.00      0.00        27
          3       0.00      0.00      0.00        48
          4       0.00      0.00      0.00       198
          5       0.60      1.00      0.75       459
      avg / total 0.36      0.60      0.45       760

2. Було побудовано TF-IDF на топ 3500 термів з фільтрування стоп-слів:

Recall: 	0.634   
Precision: 	0.561  
F1: 		0.586   
accuracy: 	0.634   

    class	pred_1  pred_2  pred_3  pred_4  pred_5

	1       2       0       2      13      11
	2       1       0       3      13      10
	3       2       0       1      27      18
	4       0       0       4      73     121
	5       0       1       1      51     406
             
             precision    recall  f1-score   support

          1       0.40      0.07      0.12        28
          2       0.00      0.00      0.00        27
          3       0.09      0.02      0.03        48
          4       0.41      0.37      0.39       198
          5       0.72      0.88      0.79       459

      avg / total 0.56      0.63      0.59       760

3. Далі було додано різні агрегації сентиментів (21 фіча, див. код):

Recall: 	0.646  
Precision: 	0.558  
F1: 		0.586  
accuracy: 	0.646  

   	class	pred_1  pred_2  pred_3  pred_4  pred_5
	1       1       0       2      11      14
	2       1       0       2      15       9
	3       0       0       0      30      18
	4       0       0       0      68     130
	5       0       0       0      37     422
             
             precision    recall  f1-score   support

          1       0.50      0.04      0.07        28
          2       0.00      0.00      0.00        27
          3       0.00      0.00      0.00        48
          4       0.42      0.34      0.38       198
          5       0.71      0.92      0.80       459

     avg / total  0.56      0.65      0.59       760

4. також були побудовані кастомні фічі:
* target encoding ідентифікатора товару
* довжини та співвідношення довжин самого відгуку, секцій недоліки та переваги
* чи задовольняє секція недоліки патерну - "не має|не знайш|немає|не вияв|відсутн|нема|--"

Recall: 	0.646  
Precision:  0.537  
F1: 		0.580  
accuracy: 	0.646  

   	class	pred_1  pred_2  pred_3  pred_4  pred_5
	1       0       0       1      12      15
	2       0       0       0      17      10
	3       0       0       0      23      25
	4       0       0       2      64     132
	5       0       0       1      31     427
             
             precision    recall  f1-score   support

          1       0.00      0.00      0.00        28
          2       0.00      0.00      0.00        27
          3       0.00      0.00      0.00        48
          4       0.44      0.32      0.37       198
          5       0.70      0.93      0.80       459

      avg / total 0.54      0.65      0.58       760

5. Було додано лематизацію, як preprocessing до TF-IDF та сентименту (+усі інші фічі):


Recall: 	0.643  
Precision: 	0.571  
F1: 		0.581  
accuracy: 	0.643  

   	class	pred_1  pred_2  pred_3  pred_4  pred_5
	1       1       0       1      12      14
	2       0       0       0      18       9
	3       0       0       0      28      20
	4       0       0       1      65     132
	5       0       0       0      36     423

             precision    recall  f1-score   support

          1       1.00      0.04      0.07        28
          2       0.00      0.00      0.00        27
          3       0.00      0.00      0.00        48
          4       0.41      0.33      0.36       198
          5       0.71      0.92      0.80       459

	avg / total   0.57      0.64      0.58       760

6. Найкращі результати було отримано з використанням усіх фічей, лематизації, стоп-слів, IDF та нормування на XGBoost:

Recall: 	0.649  
Precision: 	0.564  
F1: 		0.573  
accuracy: 	0.649  

	class	pred_1  pred_2  pred_3  pred_4  pred_5
	1       0       0       0      11      17
	2       0       0       1      12      14
	3       0       0       3      17      28
	4       0       0       1      50     147
	5       0       0       1      18     440

             precision    recall  f1-score   support

          1       0.00      0.00      0.00        28
          2       0.00      0.00      0.00        27
          3       0.50      0.06      0.11        48
          4       0.46      0.25      0.33       198
          5       0.68      0.96      0.80       459

	avg / total   0.56      0.65      0.57       760

## Проблема
Найбільшою проблемою є розділення відгуків з 4 та 5 зірочками. Вирішення цієї задачі хоча б на половину може дуже істотно підвищити основні метрики.


