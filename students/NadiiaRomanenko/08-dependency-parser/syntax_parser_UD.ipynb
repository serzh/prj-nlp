{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse, parse_tree\n",
    "from collections import OrderedDict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import re, glob, pdb, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UD_Ukrainian-IU/eval.log',\n",
       " 'UD_Ukrainian-IU/LICENSE.txt',\n",
       " 'UD_Ukrainian-IU/stats.xml',\n",
       " 'UD_Ukrainian-IU/uk_iu-ud-test.conllu',\n",
       " 'UD_Ukrainian-IU/uk_iu-ud-dev.conllu',\n",
       " 'UD_Ukrainian-IU/uk_iu-ud-train.conllu',\n",
       " 'UD_Ukrainian-IU/README.md']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('UD*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UD_Ukrainian-IU/uk_iu-ud-train.conllu') as f:\n",
    "    trees = re.sub(r\" +\", r\"\\t\", f.read())\n",
    "    trees = parse(trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(stack, queue, relations, tree):\n",
    "    feature_dict = {}\n",
    "    if len(queue) > 0:\n",
    "        feature_dict['q0-form'] = queue[0]['form']\n",
    "        feature_dict['q0-lemma'] = queue[0]['lemma']\n",
    "        feature_dict['q0-pos'] = queue[0]['upostag']\n",
    "        if isinstance(queue[0]['feats'], OrderedDict):\n",
    "            for k, v in queue[0]['feats'].items():\n",
    "                feature_dict[f'q0-{k}'] = v\n",
    "\n",
    "    if len(queue) > 1:\n",
    "        feature_dict['q1-form'] = queue[1]['form']\n",
    "        feature_dict['q1-lemma'] = queue[1]['lemma']\n",
    "        feature_dict['q1-pos'] = queue[1]['upostag']\n",
    "\n",
    "    if len(queue) > 2:\n",
    "        feature_dict['q2-form'] = queue[2]['form']\n",
    "        feature_dict['q2-lemma'] = queue[2]['lemma']\n",
    "        feature_dict['q2-pos'] = queue[2]['upostag']\n",
    "\n",
    "    if len(stack) > 1:\n",
    "        feature_dict['st0-form'] = stack[-1]['form']\n",
    "        feature_dict['st0-lemma'] = stack[-1]['lemma']\n",
    "        feature_dict['st0-pos'] = stack[-1]['upostag']\n",
    "        if isinstance(stack[-1]['feats'], OrderedDict):\n",
    "            for k, v in stack[-1]['feats'].items():\n",
    "                feature_dict[f'q0-{k}'] = v\n",
    "\n",
    "    if len(stack) > 2:\n",
    "        feature_dict['st1-form'] = stack[-2]['form']\n",
    "        feature_dict['st1-lemma'] = stack[-2]['lemma']\n",
    "        feature_dict['st1-pos'] = stack[-2]['upostag']\n",
    "\n",
    "    if len(stack) > 3:\n",
    "        feature_dict['st2-form'] = stack[-3]['form']\n",
    "        feature_dict['st2-lemma'] = stack[-3]['lemma']\n",
    "        feature_dict['st2-pos'] = stack[-3]['upostag']\n",
    "\n",
    "    if len(queue) > 0 and len(stack) > 0:\n",
    "        feature_dict['distance'] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "\n",
    "def get_action(top_stack, top_queue, relations):\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    \n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    \n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         top_queue[\"head\"] < top_stack[\"id\"]:\n",
    "        return Actions.REDUCE\n",
    "\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT\n",
    "\n",
    "ROOT = OrderedDict([('id', 0),\n",
    "                    ('form', 'ROOT'),\n",
    "                    ('lemma', 'ROOT'),\n",
    "                    ('upostag', None),\n",
    "                    ('xpostag', None),\n",
    "                    ('feats', None),\n",
    "                    ('head', None),\n",
    "                    ('deprel', None),\n",
    "                    ('deps', None),\n",
    "                    ('misc', None)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree, estimator=None):\n",
    "    datum = []\n",
    "    \n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        \n",
    "        features = get_features(stack, queue, relations, tree)\n",
    "        \n",
    "        action = get_action(stack[-1] if len(stack) > 0 else None,\n",
    "                            queue[0] if len(queue) > 0 else None,\n",
    "                            relations)\n",
    "        \n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "\n",
    "        datum += [(features, action.value)]\n",
    "\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and get feature arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "\n",
    "shuffle(trees)\n",
    "test_mark = int(len(trees) * 0.2)\n",
    "test_trees = trees[: test_mark]\n",
    "train_trees = trees[test_mark: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for tree in train_trees:\n",
    "    if any(w['head'] == None for w in tree):\n",
    "        continue\n",
    "    train += get_data(tree)\n",
    "    \n",
    "test = []\n",
    "for tree in test_trees:\n",
    "    if any(w['head'] == None for w in tree):\n",
    "        continue\n",
    "    test += get_data(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = [w[0] for w in train]\n",
    "train_labs = [w[1] for w in train]\n",
    "\n",
    "test_feats = [w[0] for w in test]\n",
    "test_labs = [w[1] for w in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446341871756237"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_lr = Pipeline([('vect', DictVectorizer()),\n",
    "                          ('lr', LogisticRegression())])\n",
    "\n",
    "action_lr.fit(train_feats, train_labs)\n",
    "action_lr.score(test_feats, test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.88      0.86      0.87      7565\n",
      "     reduce       0.81      0.88      0.84      7340\n",
      "      right       0.82      0.78      0.80      7129\n",
      "      shift       0.87      0.85      0.86      7831\n",
      "\n",
      "avg / total       0.85      0.84      0.84     29865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(action_lr.predict(test_feats), test_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6679,  295,  377,  480],\n",
       "       [ 114, 6482,  202,  542],\n",
       "       [ 431,  458, 6494,  182],\n",
       "       [ 484,  768,  307, 5570]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(action_lr.predict(test_feats), test_labs,\n",
    "                 labels=['shift', 'reduce', 'left', 'right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if len(queue) > 0 and len(stack) == 0:\n",
    "            print(' '.join([w['form'] for w in tree]), '\\nOrphans in queue\\n')\n",
    "            return sorted(relations)\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = get_features(stack, queue, relations, tree)\n",
    "            action = oracle.predict(features)[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У 1995-му Сінгапур із 26 дол . США на душу населення обійшов Британію ( 19 ) . \n",
      "Orphans in queue\n",
      "\n",
      "Правила поводження з тваринами , що використовуються в наукових експериментах , тестуванні , навчальному процесі , виробництві біологічних препаратів \n",
      "Orphans in queue\n",
      "\n",
      "Total: 14499\n",
      "Correctly defined: 10335\n",
      "UAS: 0.71\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, action_lr)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add relations data to features to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_rel(stack, queue, relations, tree, is_test=True):\n",
    "    feature_dict = {}\n",
    "    if len(queue) > 0:\n",
    "        feature_dict['q0-form'] = queue[0]['form']\n",
    "        feature_dict['q0-lemma'] = queue[0]['lemma']\n",
    "        feature_dict['q0-pos'] = queue[0]['upostag']\n",
    "        if isinstance(queue[0]['feats'], OrderedDict):\n",
    "            for k, v in queue[0]['feats'].items():\n",
    "                feature_dict[f'q0-{k}'] = v\n",
    "\n",
    "    if len(queue) > 1:\n",
    "        feature_dict['q1-form'] = queue[1]['form']\n",
    "        feature_dict['q1-lemma'] = queue[1]['lemma']\n",
    "        feature_dict['q1-pos'] = queue[1]['upostag']\n",
    "\n",
    "    if len(queue) > 2:\n",
    "        feature_dict['q2-form'] = queue[2]['form']\n",
    "        feature_dict['q2-lemma'] = queue[2]['lemma']\n",
    "        feature_dict['q2-pos'] = queue[2]['upostag']\n",
    "\n",
    "    if len(stack) > 1:\n",
    "        feature_dict['st0-form'] = stack[-1]['form']\n",
    "        feature_dict['st0-lemma'] = stack[-1]['lemma']\n",
    "        feature_dict['st0-pos'] = stack[-1]['upostag']\n",
    "        if isinstance(stack[-1]['feats'], OrderedDict):\n",
    "            for k, v in stack[-1]['feats'].items():\n",
    "                feature_dict[f'q0-{k}'] = v\n",
    "\n",
    "        # Relations in stack\n",
    "        if not is_test:\n",
    "            st0_child_id = next((rel[0] for rel in relations if rel[1] == stack[-1]['id']), None)\n",
    "            st0_child = next((tok for tok in tree if tok['id'] == st0_child_id), None)\n",
    "            if st0_child:\n",
    "                feature_dict['st0-child-form'] = st0_child['form']\n",
    "                feature_dict['st0-child-lemma'] = st0_child['lemma']\n",
    "                feature_dict['st0-child-pos'] = st0_child['upostag']\n",
    "\n",
    "            st0_parent_id = next((rel[1] for rel in relations if rel[0] == stack[-1]['id']), None)\n",
    "            st0_parent = next((tok for tok in tree if tok['id'] == st0_parent_id), None)\n",
    "            if st0_parent:\n",
    "                feature_dict['st0-parent-form'] = st0_parent['form']\n",
    "                feature_dict['st0-parent-lemma'] = st0_parent['lemma']\n",
    "                feature_dict['st0-parent-pos'] = st0_parent['upostag']\n",
    "\n",
    "    if len(stack) > 2:\n",
    "        feature_dict['st1-form'] = stack[-2]['form']\n",
    "        feature_dict['st1-lemma'] = stack[-2]['lemma']\n",
    "        feature_dict['st1-pos'] = stack[-2]['upostag']\n",
    "\n",
    "    if len(stack) > 3:\n",
    "        feature_dict['st2-form'] = stack[-3]['form']\n",
    "        feature_dict['st2-lemma'] = stack[-3]['lemma']\n",
    "        feature_dict['st2-pos'] = stack[-3]['upostag']\n",
    "\n",
    "    if len(queue) > 0 and len(stack) > 0:\n",
    "        feature_dict['distance'] = queue[0][\"id\"] - stack[-1][\"id\"]\n",
    "        \n",
    "    feature_dict['len_queue'] = len(queue)\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tree, is_test=True, estimator=None):\n",
    "    datum = []\n",
    "    \n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        if len(queue) > 0 and len(stack) == 0:\n",
    "            print(' '.join([w['form'] for w in tree]), '\\nOrphans in queue\\n')\n",
    "            return datum\n",
    "        \n",
    "        if estimator:\n",
    "            is_test = False\n",
    "        \n",
    "        features = get_features_rel(stack, queue, relations, tree, is_test=is_test)\n",
    "        \n",
    "        if estimator:\n",
    "            action = estimator.predict([features])[0]\n",
    "            action = Actions[action.upper()]\n",
    "            \n",
    "            top_stack = stack[-1] if len(stack) > 0 else None\n",
    "            top_queue = queue[0] if len(queue) > 0 else None\n",
    "            \n",
    "            if top_stack and not top_queue:\n",
    "                action = Actions.REDUCE\n",
    "            \n",
    "        else:\n",
    "            action = get_action(stack[-1] if len(stack) > 0 else None,\n",
    "                                queue[0] if len(queue) > 0 else None,\n",
    "                                relations)            \n",
    "        \n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "            \n",
    "        if estimator:\n",
    "            datum += [(features, action.value)]\n",
    "        else:\n",
    "            datum += [(features, action.value)]\n",
    "\n",
    "    return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for tree in train_trees:\n",
    "    if any(w['head'] == None for w in tree):\n",
    "        continue\n",
    "    train += get_data(tree, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = [w[0] for w in train]\n",
    "train_labs = [w[1] for w in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=3,\n",
       "          penalty='l2', random_state=23, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_lr_rel = Pipeline([('vect', DictVectorizer()),\n",
    "                          ('lr', LogisticRegression(n_jobs=3,\n",
    "                                                    random_state=23,\n",
    "                                                    max_iter=500))])\n",
    "\n",
    "action_lr_rel.fit(train_feats, train_labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**add relation data to test during prediction**<br/><br/>\n",
    "    We can\\`t use traditional metrics, because adding relations dynamically makes golden test tree and predicted one different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if len(queue) > 0 and len(stack) == 0:\n",
    "            print('There were orphans in queue\\n')\n",
    "            return sorted(relations)\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = get_features_rel(stack, queue, relations, tree, is_test=False)\n",
    "            action = oracle.predict(features)[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Красуня \n",
      "Orphans in queue\n",
      "\n",
      "Правила поводження з тваринами , що використовуються в наукових експериментах , тестуванні , навчальному процесі , виробництві біологічних препаратів \n",
      "Orphans in queue\n",
      "\n",
      "Total: 14499\n",
      "Correctly defined: 10638\n",
      "UAS: 0.73\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, action_lr_rel)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\+2% to UAS score, comparing previous version, the one that did not account for relations**\n",
    "\n",
    "Let's optimize parameters for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': np.arange(0.5, 1.0, 0.1),\n",
    "    'lr__intercept_scaling': np.arange(1, 3, 1),\n",
    "    'lr__class_weight': [None, 'balanced'],\n",
    "    'lr__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'lr__multi_class': ['multinomial', 'ovr'],\n",
    "}\n",
    "\n",
    "param_search = RandomizedSearchCV(action_lr_rel, param_grid, n_iter=10, verbose=2)\n",
    "param_search.fit(train_feats, train_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>param_lr__class_weight</th>\n",
       "      <th>param_lr__intercept_scaling</th>\n",
       "      <th>param_lr__multi_class</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.590307</td>\n",
       "      <td>1.120119</td>\n",
       "      <td>0.840375</td>\n",
       "      <td>0.905920</td>\n",
       "      <td>0.6</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840390</td>\n",
       "      <td>0.892933</td>\n",
       "      <td>0.835910</td>\n",
       "      <td>0.894462</td>\n",
       "      <td>0.844824</td>\n",
       "      <td>0.930365</td>\n",
       "      <td>0.911937</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.017296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77.722170</td>\n",
       "      <td>1.123349</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>0.903459</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839765</td>\n",
       "      <td>0.890564</td>\n",
       "      <td>0.835934</td>\n",
       "      <td>0.891901</td>\n",
       "      <td>0.845185</td>\n",
       "      <td>0.927912</td>\n",
       "      <td>0.516441</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.017299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>82.550735</td>\n",
       "      <td>1.121272</td>\n",
       "      <td>0.837986</td>\n",
       "      <td>0.879670</td>\n",
       "      <td>0.7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836736</td>\n",
       "      <td>0.868273</td>\n",
       "      <td>0.832712</td>\n",
       "      <td>0.868998</td>\n",
       "      <td>0.844511</td>\n",
       "      <td>0.901738</td>\n",
       "      <td>0.231906</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.015608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.959078</td>\n",
       "      <td>1.146315</td>\n",
       "      <td>0.837682</td>\n",
       "      <td>0.881934</td>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836639</td>\n",
       "      <td>0.870377</td>\n",
       "      <td>0.832159</td>\n",
       "      <td>0.871258</td>\n",
       "      <td>0.844247</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>5.549765</td>\n",
       "      <td>0.036134</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.015725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.651601</td>\n",
       "      <td>1.230611</td>\n",
       "      <td>0.837361</td>\n",
       "      <td>0.981260</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837505</td>\n",
       "      <td>0.981135</td>\n",
       "      <td>0.834299</td>\n",
       "      <td>0.981737</td>\n",
       "      <td>0.840279</td>\n",
       "      <td>0.980908</td>\n",
       "      <td>2.354670</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.121730</td>\n",
       "      <td>1.142227</td>\n",
       "      <td>0.833586</td>\n",
       "      <td>0.952177</td>\n",
       "      <td>0.6</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832504</td>\n",
       "      <td>0.951955</td>\n",
       "      <td>0.830452</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.837802</td>\n",
       "      <td>0.952005</td>\n",
       "      <td>1.068308</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.183931</td>\n",
       "      <td>1.138237</td>\n",
       "      <td>0.832632</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>0.9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831542</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.829322</td>\n",
       "      <td>0.965638</td>\n",
       "      <td>0.837033</td>\n",
       "      <td>0.965687</td>\n",
       "      <td>0.120272</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339.528357</td>\n",
       "      <td>1.238817</td>\n",
       "      <td>0.832504</td>\n",
       "      <td>0.879389</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830532</td>\n",
       "      <td>0.868057</td>\n",
       "      <td>0.828408</td>\n",
       "      <td>0.868745</td>\n",
       "      <td>0.838572</td>\n",
       "      <td>0.901366</td>\n",
       "      <td>11.851931</td>\n",
       "      <td>0.057442</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.015542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>350.488326</td>\n",
       "      <td>1.123182</td>\n",
       "      <td>0.831045</td>\n",
       "      <td>0.880203</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.868550</td>\n",
       "      <td>0.827013</td>\n",
       "      <td>0.869971</td>\n",
       "      <td>0.836335</td>\n",
       "      <td>0.902087</td>\n",
       "      <td>2.009454</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.015486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>353.074894</td>\n",
       "      <td>1.152179</td>\n",
       "      <td>0.826813</td>\n",
       "      <td>0.859166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824713</td>\n",
       "      <td>0.848903</td>\n",
       "      <td>0.821531</td>\n",
       "      <td>0.850843</td>\n",
       "      <td>0.834195</td>\n",
       "      <td>0.877753</td>\n",
       "      <td>0.617123</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.013167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3      77.590307         1.120119         0.840375          0.905920   \n",
       "6      77.722170         1.123349         0.840295          0.903459   \n",
       "7      82.550735         1.121272         0.837986          0.879670   \n",
       "1      88.959078         1.146315         0.837682          0.881934   \n",
       "2      84.651601         1.230611         0.837361          0.981260   \n",
       "4      32.121730         1.142227         0.833586          0.952177   \n",
       "8      36.183931         1.138237         0.832632          0.965650   \n",
       "0     339.528357         1.238817         0.832504          0.879389   \n",
       "5     350.488326         1.123182         0.831045          0.880203   \n",
       "9     353.074894         1.152179         0.826813          0.859166   \n",
       "\n",
       "  param_lr__C param_lr__class_weight param_lr__intercept_scaling  \\\n",
       "3         0.6                   None                           1   \n",
       "6         0.5               balanced                           1   \n",
       "7         0.7               balanced                           1   \n",
       "1         0.8                   None                           2   \n",
       "2         0.9                   None                           2   \n",
       "4         0.6               balanced                           1   \n",
       "8         0.9               balanced                           1   \n",
       "0         0.5                   None                           1   \n",
       "5         0.5               balanced                           2   \n",
       "9         0.5               balanced                           2   \n",
       "\n",
       "  param_lr__multi_class param_lr__penalty param_lr__solver       ...         \\\n",
       "3           multinomial                l2              sag       ...          \n",
       "6           multinomial                l2              sag       ...          \n",
       "7           multinomial                l2             saga       ...          \n",
       "1           multinomial                l2             saga       ...          \n",
       "2           multinomial                l2            lbfgs       ...          \n",
       "4                   ovr                l2        newton-cg       ...          \n",
       "8                   ovr                l2        newton-cg       ...          \n",
       "0                   ovr                l2              sag       ...          \n",
       "5                   ovr                l2              sag       ...          \n",
       "9                   ovr                l2             saga       ...          \n",
       "\n",
       "  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "3          0.840390            0.892933           0.835910   \n",
       "6          0.839765            0.890564           0.835934   \n",
       "7          0.836736            0.868273           0.832712   \n",
       "1          0.836639            0.870377           0.832159   \n",
       "2          0.837505            0.981135           0.834299   \n",
       "4          0.832504            0.951955           0.830452   \n",
       "8          0.831542            0.965625           0.829322   \n",
       "0          0.830532            0.868057           0.828408   \n",
       "5          0.829787            0.868550           0.827013   \n",
       "9          0.824713            0.848903           0.821531   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "3            0.894462           0.844824            0.930365      0.911937   \n",
       "6            0.891901           0.845185            0.927912      0.516441   \n",
       "7            0.868998           0.844511            0.901738      0.231906   \n",
       "1            0.871258           0.844247            0.904167      5.549765   \n",
       "2            0.981737           0.840279            0.980908      2.354670   \n",
       "4            0.952569           0.837802            0.952005      1.068308   \n",
       "8            0.965638           0.837033            0.965687      0.120272   \n",
       "0            0.868745           0.838572            0.901366     11.851931   \n",
       "5            0.869971           0.836335            0.902087      2.009454   \n",
       "9            0.850843           0.834195            0.877753      0.617123   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "3        0.008252        0.003639         0.017296  \n",
       "6        0.004192        0.003795         0.017299  \n",
       "7        0.004598        0.004897         0.015608  \n",
       "1        0.036134        0.004989         0.015725  \n",
       "2        0.131903        0.002443         0.000350  \n",
       "4        0.005531        0.003097         0.000278  \n",
       "8        0.006335        0.003241         0.000027  \n",
       "0        0.057442        0.004377         0.015542  \n",
       "5        0.001747        0.003908         0.015486  \n",
       "9        0.065320        0.005379         0.013167  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(param_search.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr/prjctr/nlp_env/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('lr', LogisticRegression(C=0.6, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='multinomial',\n",
       "          n_jobs=3, penalty='l2', random_state=23, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_lr_rel = param_search.best_estimator_\n",
    "calibrated_lr_rel.fit(train_feats, train_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дуже потрібно , дякую \n",
      "Orphans in queue\n",
      "\n",
      "Вилов та тимчасова ізоляція домашніх тварин \n",
      "Orphans in queue\n",
      "\n",
      "Красуня \n",
      "Orphans in queue\n",
      "\n",
      "Total: 14499\n",
      "Correctly defined: 10560\n",
      "UAS: 0.73\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in test_trees:\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, calibrated_lr_rel)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad, bad randomized parameter search, use previous classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just use it: parse plain sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from tokenize_uk import tokenize_words\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2ud = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PRED\": \"ADV\", \"PREP\": \"ADP\", \"PRCL\": \"PART\"}\n",
    "\n",
    "CONJ_COORD = [\"а\", \"або\", \"але\", \"ані\", \"все\", \"все-таки\", \"втім\", \"ж\", \"же\",\n",
    "              \"зате\", \"і\", \"й\", \"ніже\", \"однак\", \"одначе\", \"прецінь\", \"проте\",\n",
    "              \"та\", \"так\", \"також\", \"усе\", \"усе-таки\", \"утім\", \"чи\"]\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if word.word in CONJ_COORD:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    else:\n",
    "        return pm2ud.get(word.tag.POS, word.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_dict(i, w):\n",
    "    parsed = morph.parse(w)\n",
    "    if len(parsed) < 1:\n",
    "        return {\n",
    "            'form': w,\n",
    "            'lemma': w,\n",
    "            'pos': None,\n",
    "        }\n",
    "    parsed = parsed[0]\n",
    "    return {\n",
    "        'id': i,\n",
    "        'form': w,\n",
    "        'lemma': parsed.normal_form,\n",
    "        'upostag': normalize_pos(parsed),\n",
    "        'feats': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_new_sent(sent):\n",
    "    print('----------------\\n' + sent)\n",
    "    sent = tokenize_words(sent)\n",
    "    sent_word_dicts = [get_word_dict(i + 1, w) for i, w in enumerate(sent)]\n",
    "    relations = dep_parse(sent_word_dicts, action_lr_rel)\n",
    "    sent = ['root'] + sent\n",
    "    for child, head in relations:\n",
    "        print(f'{sent[child]} <--- {sent[head]}')\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Маленькі собаки залишаються щенятами.\n",
      "There were orphans in queue\n",
      "\n",
      "Маленькі <--- залишаються\n",
      "собаки <--- Маленькі\n",
      "залишаються <--- root\n",
      "щенятами <--- залишаються\n",
      "----------------\n",
      "Хто розлив каву на столі?\n",
      "There were orphans in queue\n",
      "\n",
      "розлив <--- Хто\n",
      "каву <--- Хто\n",
      "столі <--- на\n",
      "----------------\n",
      "Щенята грались на траві й кусали своїх господарів\n",
      "Щенята <--- root\n",
      "Щенята <--- грались\n",
      "на <--- кусали\n",
      "траві <--- на\n",
      "й <--- кусали\n",
      "кусали <--- грались\n",
      "своїх <--- кусали\n",
      "господарів <--- грались\n",
      "----------------\n",
      "Сонце гріє лице, радує це.\n",
      "There were orphans in queue\n",
      "\n",
      "Сонце <--- root\n",
      "гріє <--- Сонце\n",
      "лице <--- Сонце\n",
      ", <--- радує\n",
      "радує <--- Сонце\n",
      "це <--- Сонце\n",
      "----------------\n",
      "Полюбляю тебе, відпустка.\n",
      "There were orphans in queue\n",
      "\n",
      "Полюбляю <--- root\n",
      "тебе <--- Полюбляю\n",
      ", <--- Полюбляю\n",
      "відпустка <--- Полюбляю\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_new_sent('Маленькі собаки залишаються щенятами.')\n",
    "parse_new_sent('Хто розлив каву на столі?')\n",
    "parse_new_sent('Щенята грались на траві й кусали своїх господарів')\n",
    "parse_new_sent('Сонце гріє лице, радує це.')\n",
    "parse_new_sent('Полюбляю тебе, відпустка.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Парсер показав непогані результати на тестовій вибірці, проте робить очевидні помилки на незнайомих реченнях. Чому? Я думаю, причина в тому, що \n",
    "    - речення у тренувальній вибірці було взято з літератури, багато з них не відображають сучасний стиль мовлення. \n",
    "    - парсер натреновано на обмеженому словнику, а слово, його лемма - це змінні в моделі.\n",
    "  \n",
    "З \"зовнішніх\" речень видно, що парсер погано впорується з питальними й скадними реченнями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# ud_feat_options = defaultdict(set)\n",
    "# for d in train_feats:\n",
    "#     for k, v in d.items():\n",
    "#         if not re.search('form|lemma|-pos|distance|len_', k):\n",
    "#             ud_feat_options[k.replace('q0-', '')].add(v)\n",
    "# ud_feat_options"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
