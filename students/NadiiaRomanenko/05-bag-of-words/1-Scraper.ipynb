{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Категорія - \"Крупная и встраиваемая бытовая техника\"<br/>**\n",
    "https://rozetka.com.ua/big-builtin-bt/c4628180/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, pdb\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote, urljoin\n",
    "from time import sleep\n",
    "from csv import DictWriter\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect links to individual products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://rozetka.com.ua/big-builtin-bt/c4628180/'\n",
    "\n",
    "base_r = requests.get(base_url)\n",
    "base_soup = BeautifulSoup(base_r.text, 'lxml')\n",
    "category_links = [{'catname': cat.text.strip(),\n",
    "                   # add '/filter/' to url path, and magically get full list of products in category\n",
    "                   # even if link leads to another sub-catalogue\n",
    "                   'link': urljoin(cat.get('href'), 'filter'),}\n",
    "                  for cat in base_soup.select('#menu_categories_left a.m-cat-l-i-title-link')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(pr, catname):\n",
    "    price = re.search('pricerawjson = \\'(.+)\\'', str(pr.find_previous('script')))\n",
    "    if not price:\n",
    "        pdb.set_trace()\n",
    "        \n",
    "    try:\n",
    "        price = json.loads(unquote(price.group(1)))['price']\n",
    "        total_reviews = pr.get('data-count')\n",
    "        reviews_link = pr.get('href')\n",
    "        product_id = re.search('/p?(\\d+)', reviews_link).group(1)\n",
    "        assert isinstance(price, int)\n",
    "    except Exception as e:\n",
    "        pdb.set_trace()\n",
    "    \n",
    "    return {\n",
    "        'price': price,\n",
    "        'total_reviews': total_reviews,\n",
    "        'reviews_link': reviews_link,\n",
    "        'product_id': product_id,\n",
    "        'category': catname,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_links(cat, writer):\n",
    "    r1 = requests.get(cat['link'], allow_redirects=True)\n",
    "    soup1 = BeautifulSoup(r1.text, 'lxml')\n",
    "    pagination = soup1.select('.paginator-catalog a')\n",
    "    \n",
    "    # in case there are still sub-catalogues - go recursive    \n",
    "    if len(pagination) == 0 and len(soup1.select('div.pab-table')) > 0:\n",
    "        subcat_links = [{'link': urljoin(subcat.get('href'), 'filter'),\n",
    "                         'catname': cat['catname'],}\n",
    "                        for subcat in soup1.select('.pab-table .pab-h3 a')]\n",
    "        for subcat in subcat_links:\n",
    "            get_product_links(subcat, writer)\n",
    "        return\n",
    "    # single-page category\n",
    "    elif len(pagination) == 0:\n",
    "        pagination = 1\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            pagination = int(pagination[-1].text)\n",
    "        except Exception as e:\n",
    "            pdb.set_trace()\n",
    "    products = [get_product_info(pr, cat['catname'])\n",
    "                for pr in [\n",
    "                    stars.find_parent('a')\n",
    "                    for stars in soup1.select('#catalog_goods_block span.g-rating-stars')\n",
    "                ]]\n",
    "\n",
    "    for page in range(2, pagination + 1):\n",
    "        rp = requests.get(urljoin(cat['link'], f'page={page}'), allow_redirects=True)\n",
    "        soup_p = BeautifulSoup(rp.text, 'lxml')\n",
    "        ranked_products = soup_p.select('#catalog_goods_block span.g-rating-stars')\n",
    "\n",
    "        products += [get_product_info(pr, cat['catname'])\n",
    "                     for pr in [\n",
    "                         stars.find_parent('a')\n",
    "                         for stars in soup_p.select('#catalog_goods_block span.g-rating-stars')\n",
    "                     ]]\n",
    "        sleep(0.1)\n",
    "\n",
    "    for pr in products:\n",
    "        writer.writerow(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22 of 22) |#########################| Elapsed Time: 0:03:17 Time: 0:03:17\n"
     ]
    }
   ],
   "source": [
    "f = open('review_links.csv', 'w')\n",
    "colnames = ['product_id',\n",
    "            'reviews_link',\n",
    "            'category',\n",
    "            'price',\n",
    "            'total_reviews',]\n",
    "writer = DictWriter(f, fieldnames=colnames)\n",
    "writer.writerow({h:h for h in colnames})\n",
    "\n",
    "bar = ProgressBar()\n",
    "for cat in bar(category_links):\n",
    "    get_product_links(cat, writer)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \\>1300 products with at least one \"self-annotated\" review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrape reviews themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('review_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'Холодильники',\n",
       " 'price': 16499,\n",
       " 'product_id': 13991066,\n",
       " 'reviews_link': 'https://bt.rozetka.com.ua/samsung_rb37j5100sa_ua/p13991066/comments/',\n",
       " 'total_reviews': 92}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_link = df.loc[5, ].to_dict()\n",
    "reviews_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reviews(rv):\n",
    "    id = rv.get('name')\n",
    "    ranking = rv.select('span.sprite.g-rating-stars-i')[0].get('content')\n",
    "    text = '\\n'.join([p.get_text().strip() for p in rv.select('.pp-review-text-i')]).replace('\\xa0', '')\n",
    "    return {\n",
    "        'id': id,\n",
    "        'text': text,\n",
    "        'ranking': ranking,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(soup):\n",
    "    reviews = list(filter(lambda r: len(r.select('span.sprite.g-rating-stars-i')) > 0, # has product ranking\n",
    "                          soup.select('article.pp-review-i')))\n",
    "    return list(map(parse_reviews, reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(product):\n",
    "    r = requests.get(product['reviews_link'])\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    pagination = soup.select('.paginator-catalog-l-link')\n",
    "    \n",
    "    # single-page category\n",
    "    if len(pagination) == 0:\n",
    "        pagination = 1\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            pagination = int(pagination[-1].text)\n",
    "        except Exception as e:\n",
    "            pdb.set_trace()\n",
    "            \n",
    "    reviews = scrape_reviews(soup)\n",
    "\n",
    "    for page in range(2, pagination + 1):\n",
    "        rp = requests.get(urljoin(product['reviews_link'], f'page={page}'), allow_redirects=True)\n",
    "        soup_p = BeautifulSoup(rp.text, 'lxml')\n",
    "        ranked_products = soup_p.select('#catalog_goods_block span.g-rating-stars')\n",
    "\n",
    "        reviews += scrape_reviews(soup_p)\n",
    "        sleep(0.1)\n",
    "\n",
    "    reviews = pd.DataFrame(reviews)\n",
    "    reviews['product_id'] = product['product_id']\n",
    "    reviews['category'] = product['category']\n",
    "    reviews['price'] = product['price']\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1360 of 1360) |#####################| Elapsed Time: 0:39:55 Time: 0:39:55\n"
     ]
    }
   ],
   "source": [
    "allreviews = None\n",
    "\n",
    "bar = ProgressBar()\n",
    "for product in bar(df.to_dict(orient='records')):\n",
    "    allreviews = pd.concat([allreviews,\n",
    "                            get_reviews(product)])       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.detect import Detector\n",
    "# based on cld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreviews['lang'] = allreviews.text.apply(lambda t: Detector(t, quiet=True).language.code)\n",
    "allreviews = allreviews.loc[allreviews.lang == 'uk', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreviews.to_csv('reviews.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
