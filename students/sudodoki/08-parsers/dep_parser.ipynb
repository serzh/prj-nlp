{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://explosion.ai/blog/parsing-english-in-python#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conllu import parse, parse_tree\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu_file(filename):\n",
    "    with open(filename) as input_file:\n",
    "        text = input_file.read()\n",
    "        result = parse(text)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "train = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-train.conllu')\n",
    "test = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-dev.conllu')\n",
    "val = read_conllu_file('../../../../UD_Ukrainian-IU/uk_iu-ud-test.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed_to_sent(parsed_toks):\n",
    "    return ' '.join([t['form'] for t in parsed_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У домі римського патриція Руфіна була прегарна фреска , зображення Венери та Адоніса .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_to_sent(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('id', 1),\n",
       "              ('form', 'У'),\n",
       "              ('lemma', 'у'),\n",
       "              ('upostag', 'ADP'),\n",
       "              ('xpostag', 'Spsl'),\n",
       "              ('feats', OrderedDict([('Case', 'Loc')])),\n",
       "              ('head', 2),\n",
       "              ('deprel', 'case'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0003')]))]),\n",
       " OrderedDict([('id', 2),\n",
       "              ('form', 'домі'),\n",
       "              ('lemma', 'дім'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncmsln'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Loc'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'obl'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0004')]))]),\n",
       " OrderedDict([('id', 3),\n",
       "              ('form', 'римського'),\n",
       "              ('lemma', 'римський'),\n",
       "              ('upostag', 'ADJ'),\n",
       "              ('xpostag', 'Ao-msgf'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 4),\n",
       "              ('deprel', 'amod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0005')]))]),\n",
       " OrderedDict([('id', 4),\n",
       "              ('form', 'патриція'),\n",
       "              ('lemma', 'патрицій'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 2),\n",
       "              ('deprel', 'nmod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0006')]))]),\n",
       " OrderedDict([('id', 5),\n",
       "              ('form', 'Руфіна'),\n",
       "              ('lemma', 'Руфін'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 4),\n",
       "              ('deprel', 'flat:title'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0007')]))]),\n",
       " OrderedDict([('id', 6),\n",
       "              ('form', 'була'),\n",
       "              ('lemma', 'бути'),\n",
       "              ('upostag', 'VERB'),\n",
       "              ('xpostag', 'Vapis-sf'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Aspect', 'Imp'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Mood', 'Ind'),\n",
       "                            ('Number', 'Sing'),\n",
       "                            ('Tense', 'Past'),\n",
       "                            ('VerbForm', 'Fin')])),\n",
       "              ('head', 0),\n",
       "              ('deprel', 'root'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0008')]))]),\n",
       " OrderedDict([('id', 7),\n",
       "              ('form', 'прегарна'),\n",
       "              ('lemma', 'прегарний'),\n",
       "              ('upostag', 'ADJ'),\n",
       "              ('xpostag', 'Ao-fsns'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Case', 'Nom'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 8),\n",
       "              ('deprel', 'amod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '0009')]))]),\n",
       " OrderedDict([('id', 8),\n",
       "              ('form', 'фреска'),\n",
       "              ('lemma', 'фреска'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncfsnn'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Nom'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'nsubj'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000a'), ('SpaceAfter', 'No')]))]),\n",
       " OrderedDict([('id', 9),\n",
       "              ('form', ','),\n",
       "              ('lemma', ','),\n",
       "              ('upostag', 'PUNCT'),\n",
       "              ('xpostag', 'U'),\n",
       "              ('feats', None),\n",
       "              ('head', 10),\n",
       "              ('deprel', 'punct'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000b')]))]),\n",
       " OrderedDict([('id', 10),\n",
       "              ('form', 'зображення'),\n",
       "              ('lemma', 'зображення'),\n",
       "              ('upostag', 'NOUN'),\n",
       "              ('xpostag', 'Ncnsnn'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Inan'),\n",
       "                            ('Case', 'Nom'),\n",
       "                            ('Gender', 'Neut'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 8),\n",
       "              ('deprel', 'appos'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000c')]))]),\n",
       " OrderedDict([('id', 11),\n",
       "              ('form', 'Венери'),\n",
       "              ('lemma', 'Венера'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npfsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Fem'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 10),\n",
       "              ('deprel', 'nmod'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000d')]))]),\n",
       " OrderedDict([('id', 12),\n",
       "              ('form', 'та'),\n",
       "              ('lemma', 'та'),\n",
       "              ('upostag', 'CCONJ'),\n",
       "              ('xpostag', 'Ccs'),\n",
       "              ('feats', None),\n",
       "              ('head', 13),\n",
       "              ('deprel', 'cc'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000e')]))]),\n",
       " OrderedDict([('id', 13),\n",
       "              ('form', 'Адоніса'),\n",
       "              ('lemma', 'Адоніс'),\n",
       "              ('upostag', 'PROPN'),\n",
       "              ('xpostag', 'Npmsgy'),\n",
       "              ('feats',\n",
       "               OrderedDict([('Animacy', 'Anim'),\n",
       "                            ('Case', 'Gen'),\n",
       "                            ('Gender', 'Masc'),\n",
       "                            ('NameType', 'Giv'),\n",
       "                            ('Number', 'Sing')])),\n",
       "              ('head', 11),\n",
       "              ('deprel', 'conj'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000f'), ('SpaceAfter', 'No')]))]),\n",
       " OrderedDict([('id', 14),\n",
       "              ('form', '.'),\n",
       "              ('lemma', '.'),\n",
       "              ('upostag', 'PUNCT'),\n",
       "              ('xpostag', 'U'),\n",
       "              ('feats', None),\n",
       "              ('head', 6),\n",
       "              ('deprel', 'punct'),\n",
       "              ('deps', None),\n",
       "              ('misc', OrderedDict([('Id', '000g')]))])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def shift_by_1(array):\n",
    "    return array[1:]\n",
    "def head(tok):\n",
    "    return tok['head'] if 'head' in tok else 0\n",
    "\n",
    "def is_left_arc(tok1, tok2):\n",
    "    return head(tok1) == tok2['id']\n",
    "\n",
    "def is_right_arc(tok1, tok2):\n",
    "    return tok1['id'] == head(tok2)\n",
    "\n",
    "def has_parent(tok1, rels):\n",
    "    all_with_parent = [pair[0] for pair in rels]\n",
    "    return tok1['id'] in all_with_parent\n",
    "\n",
    "def head_is_in_stack(queue_el, stack_el):\n",
    "    return head(queue_el) < stack_el['id']\n",
    "\n",
    "def return_static_oracle_action(s0, q0, rel, *args):\n",
    "    if s0 is None:\n",
    "        action = 'SHIFT'\n",
    "    elif q0 is None:\n",
    "        action = 'REDUCE'\n",
    "    elif is_left_arc(s0, q0):\n",
    "        action = 'LEFT'\n",
    "    elif is_right_arc(s0, q0):\n",
    "        action = 'RIGHT'\n",
    "    elif has_parent(s0, rel) and head_is_in_stack(q0, s0):\n",
    "        action = 'REDUCE'\n",
    "    else:\n",
    "        action = 'SHIFT'\n",
    "    return action\n",
    "\n",
    "\n",
    "# rels = [(child,parent)]\n",
    "def unwrap_to_relations(tree, get_action, extra_attrs = {}):\n",
    "    stack = [ROOT]\n",
    "    all_toks = tree.copy()\n",
    "    queue = tree.copy()\n",
    "    rel = []\n",
    "    actions = []\n",
    "    while len(queue) or len(stack):\n",
    "        s0 = stack[-1] if len(stack) else None\n",
    "        q0 = queue[0] if len(queue) else None\n",
    "        action = get_action(s0, q0, rel, stack, queue, all_toks, extra_attrs)\n",
    "        actions.append(action)\n",
    "        if action == 'LEFT':\n",
    "            if s0 and q0:\n",
    "                ids = (s0['id'], q0['id'])\n",
    "                if not ids in rel:\n",
    "                    rel.append(ids)\n",
    "                stack.pop()\n",
    "        elif action == 'RIGHT':\n",
    "            if s0 and q0:\n",
    "                ids = (q0['id'], s0['id'])\n",
    "                if not ids in rel:\n",
    "                    rel.append(ids)\n",
    "                stack.append(q0)\n",
    "                queue = shift_by_1(queue)\n",
    "        elif action == 'REDUCE':\n",
    "            if len(stack):\n",
    "                stack.pop()\n",
    "        elif action == 'SHIFT':\n",
    "            if not q0 is None:\n",
    "                stack.append(q0)\n",
    "                queue = shift_by_1(queue)\n",
    "        else:\n",
    "            raise Exception('Invalid action', action)\n",
    "\n",
    "    if len(actions) != len(tree) * 2 + 1:\n",
    "        print('Warning: len of actions is not tree*2+1: {} vs {}'.format(len(actions), len(tree) * 2 + 1))\n",
    "    return rel, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 2),\n",
       "  (3, 4),\n",
       "  (4, 2),\n",
       "  (5, 4),\n",
       "  (2, 6),\n",
       "  (6, 0),\n",
       "  (7, 8),\n",
       "  (8, 6),\n",
       "  (9, 10),\n",
       "  (10, 8),\n",
       "  (11, 10),\n",
       "  (12, 13),\n",
       "  (13, 11),\n",
       "  (14, 6)],\n",
       " ['SHIFT',\n",
       "  'LEFT',\n",
       "  'SHIFT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'RIGHT',\n",
       "  'SHIFT',\n",
       "  'LEFT',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'RIGHT',\n",
       "  'REDUCE',\n",
       "  'REDUCE',\n",
       "  'REDUCE'])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = train[0]\n",
    "unwrap_to_relations(tree, return_static_oracle_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_gold_relations(tree):\n",
    "    return [(tok['id'], head(tok)) for tok in tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel, actions = unwrap_to_relations(tree, return_static_oracle_action)\n",
    "g_rel = unwrap_gold_relations(tree)\n",
    "set(rel) == set(g_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the spacy post:\n",
    "- The first three words of the buffer (n0, n1, n2)\n",
    "- The top three words of the stack (s0, s1, s2)\n",
    "- The two leftmost children of s0 (s0b1, s0b2);\n",
    "- The two rightmost children of s0 (s0f1, s0f2);\n",
    "- The two leftmost children of n0 (n0b1, n0b2)\n",
    "\n",
    "For these 12 tokens, we refer to the word-form, the part-of-speech tag, and the number of left and right children attached to the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_count(tok, rels):\n",
    "    count = 0\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == parent_id:\n",
    "            count += 1\n",
    "    return count\n",
    "def get_parents_count(tok, rels):\n",
    "    count = 0\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == child_id:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def single_word_features(label, dict_vals, keys, rels):\n",
    "    res = {}\n",
    "    if dict_vals is None:\n",
    "        return {}\n",
    "    for key in keys:\n",
    "        if key == 'child_count':\n",
    "            res[label + '_c_count'] = get_children_count(dict_vals, rels)\n",
    "        elif key == 'parent_count':\n",
    "            res[label + '_p_count'] = get_parents_count(dict_vals, rels)\n",
    "        elif (type(dict_vals[key]) == OrderedDict):\n",
    "            for inner_key in dict_vals[key]:\n",
    "                res[label + '_' + key + '_' + inner_key] = dict_vals[key][inner_key]\n",
    "        else:\n",
    "            res[label + '_' + key] = dict_vals[key]\n",
    "    return res\n",
    "\n",
    "def to_features(stk, buf, rels, all_toks):\n",
    "    def get_by_id(id):\n",
    "        for tok in all_toks:\n",
    "            if tok['id'] == id:\n",
    "                return tok\n",
    "        return None\n",
    "\n",
    "    def get_child_1(tok):\n",
    "        if not tok:\n",
    "            return None\n",
    "        for (child_id, parent_id) in rels:\n",
    "            if tok['id'] == parent_id:\n",
    "                return get_by_id(child_id)\n",
    "        return None\n",
    "    def get_head_1(tok):\n",
    "        if not tok:\n",
    "            return None\n",
    "        for (child_id, parent_id) in rels:\n",
    "            if tok['id'] == child_id:\n",
    "                return get_by_id(parent_id)\n",
    "        return None\n",
    "\n",
    "    def get_n(col, n):\n",
    "        if col and 0 <= n < len(col):\n",
    "            return col[n]\n",
    "        else:\n",
    "            return None\n",
    "    res = {\n",
    "        **single_word_features('stk_0', get_n(stk, 0), ['form', 'upostag', 'child_count', 'parent_count'], rels),\n",
    "        **single_word_features('stk_1', get_n(stk, 1), ['form', 'upostag', 'child_count', 'parent_count'], rels),\n",
    "        **single_word_features('stk_2', get_n(stk, 2), ['form', 'upostag'], rels),\n",
    "        **single_word_features('ldep_stk_0', get_head_1(get_n(stk, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('rdep_stk_0', get_child_1(get_n(stk, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_0', get_n(buf, 0), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_1', get_n(buf, 1), ['form', 'upostag'], rels),\n",
    "        **single_word_features('buf_2', get_n(buf, 2), ['form', 'upostag'], rels),\n",
    "        **single_word_features('ldep_buf_0', get_head_1(get_n(buf, 0)), ['form', 'upostag'], rels),\n",
    "        **single_word_features('rdep_buf_0', get_child_1(get_n(buf, 0)), ['upostag'], rels)\n",
    "        # **single_word_features('buf_1', get_n(buf, 0), ['form', 'lemma', 'upostag', 'feats', 'deprel']),\n",
    "    }\n",
    "    if len(stk) and len(buf):\n",
    "        res[\"distance\"] = buf[0][\"id\"] - stk[-1][\"id\"]\n",
    "    return res\n",
    "\n",
    "def create_oracle_storing_data():\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    def oracle_extracting_data(s0, q0, rels, stk, buf, all_toks, extra_attrs = {}):\n",
    "        action = return_static_oracle_action(s0, q0, rels, stk, buf, all_toks)\n",
    "        X = to_features(stk, buf, rels, all_toks)\n",
    "        y = action\n",
    "        X.update(extra_attrs)        \n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "        return action\n",
    "    return Xs, ys, oracle_extracting_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = len(train)\n",
    "train_X, train_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(train):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_len = len(test)\n",
    "test_X, test_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(test):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_len = len(val)\n",
    "val_X, val_y, extractor = create_oracle_storing_data()\n",
    "for (i, tree) in enumerate(val):\n",
    "    unwrap_to_relations(tree, extractor)\n",
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer = DictVectorizer()\n",
    "dict_vectorizer.fit(train_X + test_X + val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(sparse_matrix):\n",
    "    sparse_matrix.data = np.nan_to_num(sparse_matrix.data)\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_X = fill_nans(dict_vectorizer.transform(train_X))\n",
    "test_features_X = fill_nans(dict_vectorizer.transform(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LogisticRegression(random_state=42)\n",
    "predictor.fit(train_features_X, train_y)\n",
    "train_y_predicted = predictor.predict(train_features_X)\n",
    "test_y_predicted = predictor.predict(test_features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.77      0.88      0.82     38446\n",
      "     REDUCE       0.90      0.81      0.85     41165\n",
      "      RIGHT       0.83      0.78      0.80     34669\n",
      "      SHIFT       0.92      0.93      0.93     40429\n",
      "\n",
      "avg / total       0.86      0.85      0.85    154709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y, train_y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       LEFT       0.65      0.87      0.74     38446\n",
    "     REDUCE       0.84      0.69      0.76     41165\n",
    "      RIGHT       0.73      0.59      0.65     34669\n",
    "      SHIFT       0.89      0.91      0.90     40429\n",
    "\n",
    "avg / total       0.78      0.77      0.77    154709\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.65      0.74      0.69      5127\n",
      "     REDUCE       0.87      0.66      0.75      5821\n",
      "      RIGHT       0.61      0.67      0.64      4972\n",
      "      SHIFT       0.83      0.86      0.84      5399\n",
      "\n",
      "avg / total       0.75      0.73      0.73     21319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, test_y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "     precision    recall  f1-score   support\n",
    "\n",
    "       LEFT       0.58      0.73      0.65      5127\n",
    "     REDUCE       0.85      0.61      0.71      5821\n",
    "      RIGHT       0.54      0.54      0.54      4972\n",
    "      SHIFT       0.83      0.87      0.85      5399\n",
    "\n",
    "avg / total       0.71      0.69      0.69     21319\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Wow, something is off here, as I get 10% worse average performance compared to results from @mariana-scorp. I even copied random_state for predictor, assuming that issue might be originating from there, but ~ same result. 🤔~~ Issue here was me adding sentence_i features which added noise to the data, removing it fixed this specific issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_moves(stack_len, queue_len):\n",
    "    moves = []\n",
    "    if queue_len > 0:\n",
    "        moves.append('SHIFT')\n",
    "    if stack_len > 0 and queue_len > 0:\n",
    "        moves.append('LEFT')\n",
    "        moves.append('RIGHT')\n",
    "    if stack_len > 0:\n",
    "        moves.append('REDUCE')\n",
    "    return moves\n",
    "def oracle_from_predictor(hasher, predictor):\n",
    "    def action_from_predictor(s0, q0, rels, stk, buf, all_toks, extra_attrs = {}):\n",
    "        possible_moves = get_valid_moves(len(stk), len(buf))\n",
    "        in_X = to_features(stk, buf, rels, all_toks)\n",
    "        in_X = fill_nans(hasher.transform(in_X))\n",
    "        all_possibilities = list(zip(predictor.classes_, predictor.predict_proba(in_X)[0]))\n",
    "        valid_possibilities = [pair for pair in all_possibilities if pair[0] in possible_moves]\n",
    "        max_prob = sorted(valid_possibilities, key=lambda pair: -pair[1])[0][0]\n",
    "        return max_prob\n",
    "    return action_from_predictor\n",
    "\n",
    "def get_uas(dataset, oracle):\n",
    "    total = 0\n",
    "    tp = 0\n",
    "    for sample in dataset:\n",
    "        rel_gold, _ = unwrap_to_relations(tree, return_static_oracle_action)\n",
    "        rel_ours, _ = unwrap_to_relations(tree, oracle)\n",
    "        total += len(sample)\n",
    "        tp += len(set(rel_gold) & set(rel_ours))\n",
    "    return tp/total , tp, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train. 0.5408532850408799 (40617 out of 75098 are correct)\n",
      "On test. 0.5007231703789413 (5193 out of 10371 are correct)\n"
     ]
    }
   ],
   "source": [
    "our_oracle = oracle_from_predictor(dict_vectorizer, predictor)\n",
    "ratio, tp, total = get_uas(train, our_oracle)\n",
    "print('On {}. {} ({} out of {} are correct)'.format('train', ratio, tp, total))\n",
    "ratio, tp, total = get_uas(test, our_oracle)\n",
    "print('On {}. {} ({} out of {} are correct)'.format('test', ratio, tp, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "On train. 0.5408532850408799 (40617 out of 75098 are correct)\n",
    "On test. 0.5007231703789413 (5193 out of 10371 are correct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- ✅fix issue with low metrics\n",
    "- ✅add new features (counts as improving the algo):\n",
    "- 🚫possibly dyn oracle\n",
    "- ✅run on new sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new features\n",
    "- adding ldep/rdep for stack[0] / queue[0] bumped avg precision/recall by 0.01 across both train / test, but it made uas drop by ~0.18 (to 0.36 on train and 0.33 on test)\n",
    "      - adding children / parent count for stk_0/buf_0 slightly improved peformance of action predictor on train, almost didn't on test, yet uas didn't change at all\n",
    "      - redid features similar to what described in https://explosion.ai/blog/parsing-english-in-python#features keeping following:\n",
    "        1. 'stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        2. 'stk_1' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        3. 'stk_2' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        4. 'ldep_stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        5. 'rdep_stk_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        6. 'buf_0' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        7. 'buf_1' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        8. 'buf_2' - ['form', 'upostag', 'child_count', 'parent_count']\n",
    "        9. 'ldep_buf_0' – ['form', 'upostag', 'child_count', 'parent_count']\n",
    "      It gave following results for action classification on train\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           LEFT       0.82      0.89      0.85     38446\n",
    "         REDUCE       0.90      0.85      0.87     41165\n",
    "          RIGHT       0.84      0.80      0.82     34669\n",
    "          SHIFT       0.92      0.93      0.92     40429\n",
    "\n",
    "    avg / total       0.87      0.87      0.87    154709\n",
    "    \n",
    "    and on test  \n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "           LEFT       0.63      0.72      0.67      5127\n",
    "         REDUCE       0.84      0.68      0.75      5821\n",
    "          RIGHT       0.61      0.64      0.62      4972\n",
    "          SHIFT       0.81      0.85      0.83      5399\n",
    "\n",
    "    avg / total       0.73      0.72      0.72     21319  \n",
    "    \n",
    "    and still gave same result on uas for train/test\n",
    "    - trying to figure out whether I can leave some of the features away, removed some of the features and ended up with some endless loops which might need special handling / default fallback for actions. Updated the code to have predict probabilities and filter out invalid moves (and choosing the most probable valid move) - it didn't affect the score, but supposedly, must make it possible to fully evaluate on any corpora\n",
    "    - not sure, but might be that 0.5 is upper bond for this classificator / approach on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running on new sentences\n",
    "\n",
    "In order to run on new sentence, I need \n",
    "1. form / upostag for each token in sentence\n",
    "2. head / id for each token in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from difflib import Differ\n",
    "from pprint import pprint\n",
    "# import tokenize_uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отримання необхідних фіч використаю http://ufal.mff.cuni.cz/udpipe/users-manual – схоже на гарний інструмент, але під мою ОС для REST сервіса необхідно компілювати, тому буду викликати його с команднрого рядка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_tree(tree):\n",
    "    res = []\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        res.append(\"{} <-- {}\\n\".format(node[\"form\"],\n",
    "                                 tree[head - 1][\"form\"]\n",
    "                                 if head > 0 else \"root\"))\n",
    "    return res\n",
    "def get_head_id(tok, rels):\n",
    "    if not tok:\n",
    "        return None\n",
    "    for (child_id, parent_id) in rels:\n",
    "        if tok['id'] == child_id:\n",
    "            return parent_id\n",
    "    return None\n",
    "def trace_rels(tree, rels):\n",
    "    res = []\n",
    "    for node in tree:\n",
    "        head = get_head_id(node, rels)\n",
    "        if head is None:\n",
    "            res.append(\"{} <-- N/A\\n\".format(node[\"form\"]))\n",
    "            continue\n",
    "        res.append(\"{} <-- {}\\n\".format(node[\"form\"],\n",
    "                         tree[head - 1][\"form\"]\n",
    "                         if head > 0 else \"root\"))\n",
    "    return res\n",
    "def sentence_to_dicts(sent):\n",
    "    res = []\n",
    "    result = subprocess.getoutput(\"echo \\\"{}\\\" | /Users/sudodoki/Downloads/udpipe-1.2.0-bin/bin-osx/udpipe --tokenize --tag --parse /Users/sudodoki/Downloads/Universal\\ Dependencies\\ 2.0\\ Models\\ for\\ UDPipe\\ \\(2017-08-01\\)/udpipe-ud-2.0-170801/ukrainian-ud-2.0-170801.udpipe\".format(sent))\n",
    "    lines = result.split('\\n')[5:-1]\n",
    "    for line in lines:\n",
    "        id, form, lemma, upostag, xpostag, feats, head, deprel, _, _ = line.split('\\t')\n",
    "        tok_dict = OrderedDict([('id', int(id)), ('form', form), ('lemma', lemma),\n",
    "                                ('upostag', upostag), ('xpostag', xpostag), ('feats', feats),\n",
    "                               ('head', int(head)), ('deprel', deprel)])\n",
    "        res.append(tok_dict)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = Differ()\n",
    "def compare(sentence):\n",
    "    gold = sentence_to_dicts(sentence)\n",
    "    rel_gold, _ = unwrap_to_relations(gold, return_static_oracle_action)\n",
    "    gold_res = trace_tree(gold)\n",
    "    \n",
    "    rel_ours, _ = unwrap_to_relations(gold, our_oracle)\n",
    "    our_res = trace_rels(gold, rel_ours)\n",
    "    \n",
    "    total = len(gold)\n",
    "    tp = len(set(rel_gold) & set(rel_ours))\n",
    "    print(\"Got {} ({} out of {})\".format(tp / total, tp, total))\n",
    "    \n",
    "    result = list(diff.compare(gold_res, our_res))\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.4864864864864865 (18 out of 37)\n",
      "['  Пригадую <-- root\\n',\n",
      " '- , <-- згодом\\n',\n",
      " '- уже <-- згодом\\n',\n",
      " '- згодом <-- Пригадую\\n',\n",
      " '? ^^^^^^\\n',\n",
      " '+ , <-- Пригадую\\n',\n",
      " '? ^\\n',\n",
      " '+ уже <-- відбував\\n',\n",
      " '+ згодом <-- відбував\\n',\n",
      " '  , <-- відбував\\n',\n",
      " '  коли <-- відбував\\n',\n",
      " '  я <-- відбував\\n',\n",
      " '- відбував <-- згодом\\n',\n",
      " '?              ^ ^ ^^\\n',\n",
      " '+ відбував <-- Пригадую\\n',\n",
      " '?              ^^^ ^ ^^\\n',\n",
      " '  свій <-- термін\\n',\n",
      " '  термін <-- відбував\\n',\n",
      " '  у <-- таборі\\n',\n",
      " '- таборі <-- відбував\\n',\n",
      " '- № <-- області\\n',\n",
      " '- 36 <-- області\\n',\n",
      " '- у <-- області\\n',\n",
      " '- Кучино <-- Пермської\\n',\n",
      " '+ таборі <-- термін\\n',\n",
      " '+ № <-- таборі\\n',\n",
      " '+ 36 <-- №\\n',\n",
      " '+ у <-- N/A\\n',\n",
      " '+ Кучино <-- N/A\\n',\n",
      " '  Пермської <-- області\\n',\n",
      " '- області <-- таборі\\n',\n",
      " '+ області <-- Кучино\\n',\n",
      " '  , <-- отримав\\n',\n",
      " '  я <-- отримав\\n',\n",
      " '- отримав <-- області\\n',\n",
      " '?              ^^^^^\\n',\n",
      " '+ отримав <-- таборі\\n',\n",
      " '?             +++ ^\\n',\n",
      " '  від <-- Михасі\\n',\n",
      " '  Михасі <-- отримав\\n',\n",
      " '- листівку <-- Михасі\\n',\n",
      " '?              ^^^ ^\\n',\n",
      " '+ листівку <-- таборі\\n',\n",
      " '?              ^ ^^^\\n',\n",
      " '- з <-- описом\\n',\n",
      " '?        ^^^ -\\n',\n",
      " '+ з <-- того\\n',\n",
      " '?       + ^\\n',\n",
      " '  жартівливим <-- описом\\n',\n",
      " '- описом <-- листівку\\n',\n",
      " '- того <-- описом\\n',\n",
      " '+ описом <-- з\\n',\n",
      " '+ того <-- таборі\\n',\n",
      " '  , <-- готується\\n',\n",
      " '- як <-- готується\\n',\n",
      " '+ як <-- Київ\\n',\n",
      " '  Київ <-- готується\\n',\n",
      " '- готується <-- того\\n',\n",
      " '?                 ^^\\n',\n",
      " '+ готується <-- таборі\\n',\n",
      " '?                ++ ^^\\n',\n",
      " '  до <-- святкування\\n',\n",
      " '  святкування <-- готується\\n',\n",
      " '  свого <-- 1500-ліття\\n',\n",
      " '- 1500-ліття <-- готується\\n',\n",
      " '- . <-- області\\n',\n",
      " '+ 1500-ліття <-- святкування\\n',\n",
      " '+ . <-- Пригадую\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"Пригадую, уже згодом, коли я відбував свій термін у таборі № 36 у Кучино Пермської області, я отримав від Михасі листівку з жартівливим описом того, як Київ готується до святкування свого 1500-ліття.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.64 (16 out of 25)\n",
      "['- 6 <-- C\\n',\n",
      " '- C <-- приземляється\\n',\n",
      " '? ^\\n',\n",
      " '+ 6 <-- приземляється\\n',\n",
      " '? ^\\n',\n",
      " '+ C <-- 6\\n',\n",
      " '  приземляється <-- root\\n',\n",
      " '  на <-- плече\\n',\n",
      " '  плече <-- приземляється\\n',\n",
      " '  , <-- перекочуючись\\n',\n",
      " '  перекочуючись <-- приземляється\\n',\n",
      " '  , <-- пролітає\\n',\n",
      " '  пролітає <-- приземляється\\n',\n",
      " '- метрів <-- пролітає\\n',\n",
      " '+ метрів <-- приземляється\\n',\n",
      " '- п’ятдесят <-- метрів\\n',\n",
      " '?               ^^^^^^\\n',\n",
      " '+ п’ятдесят <-- N/A\\n',\n",
      " '?               ^^^\\n',\n",
      " '  і <-- витягується\\n',\n",
      " '- витягується <-- приземляється\\n',\n",
      " '?                  ^^^ ------\\n',\n",
      " '+ витягується <-- п’ятдесят\\n',\n",
      " '?                  ^^^^   +\\n',\n",
      " '  на <-- снігу\\n',\n",
      " '  снігу <-- витягується\\n',\n",
      " '- за <-- кроків\\n',\n",
      " '+ за <-- N/A\\n',\n",
      " '  кілька <-- кроків\\n',\n",
      " '- кроків <-- снігу\\n',\n",
      " '?            ^^^^^\\n',\n",
      " '+ кроків <-- за\\n',\n",
      " '?            ^^\\n',\n",
      " '- від <-- уламками\\n',\n",
      " '+ від <-- N/A\\n',\n",
      " '- забризканої <-- уламками\\n',\n",
      " '?                 ^^^^^^^^\\n',\n",
      " '+ забризканої <-- N/A\\n',\n",
      " '?                 ^^^\\n',\n",
      " '  палаючими <-- уламками\\n',\n",
      " '- уламками <-- кроків\\n',\n",
      " '+ уламками <-- забризканої\\n',\n",
      " '  посадкової <-- смуги\\n',\n",
      " '  смуги <-- уламками\\n',\n",
      " '  . <-- приземляється\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"6C приземляється на плече, перекочуючись, пролітає метрів п’ятдесят і витягується на снігу за кілька кроків від забризканої палаючими уламками посадкової смуги.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0.5666666666666667 (17 out of 30)\n",
      "['  Дівчина <-- стояла\\n',\n",
      " '  стояла <-- root\\n',\n",
      " '  там <-- стояла\\n',\n",
      " '- , <-- де\\n',\n",
      " '- де <-- там\\n',\n",
      " '- й <-- була\\n',\n",
      " '- була <-- де\\n',\n",
      " '- , <-- де\\n',\n",
      " '+ , <-- N/A\\n',\n",
      " '+ де <-- N/A\\n',\n",
      " '+ й <-- N/A\\n',\n",
      " '+ була <-- стояла\\n',\n",
      " '+ , <-- N/A\\n',\n",
      " '  і <-- намагалася\\n',\n",
      " '  намагалася <-- стояла\\n',\n",
      " '- привести <-- намагалася\\n',\n",
      " '+ привести <-- стояла\\n',\n",
      " '  до <-- ладу\\n',\n",
      " '  ладу <-- привести\\n',\n",
      " '  скуйовджене <-- волосся\\n',\n",
      " '- волосся <-- привести\\n',\n",
      " '- , <-- розлючена\\n',\n",
      " '+ волосся <-- ладу\\n',\n",
      " '+ , <-- тим\\n',\n",
      " '  вкрай <-- розлючена\\n',\n",
      " '- розлючена <-- волосся\\n',\n",
      " '?               ^^^^^^^\\n',\n",
      " '+ розлючена <-- ,\\n',\n",
      " '?               ^\\n',\n",
      " '- тим <-- розлючена\\n',\n",
      " '+ тим <-- ладу\\n',\n",
      " '  , <-- побачили\\n',\n",
      " '  що <-- побачили\\n',\n",
      " '  це <-- побачили\\n',\n",
      " '- побачили <-- розлючена\\n',\n",
      " '?              --- ----\\n',\n",
      " '+ побачили <-- ладу\\n',\n",
      " '?                ++\\n',\n",
      " '- водії <-- побачили\\n',\n",
      " '+ водії <-- ладу\\n',\n",
      " '  , <-- чекали\\n',\n",
      " '  які <-- чекали\\n',\n",
      " '- чекали <-- водії\\n',\n",
      " '?            ^^ ^^\\n',\n",
      " '+ чекали <-- ладу\\n',\n",
      " '?            ^^ ^\\n',\n",
      " '  на <-- переїзді\\n',\n",
      " '  переїзді <-- чекали\\n',\n",
      " '  . <-- стояла\\n']\n"
     ]
    }
   ],
   "source": [
    "compare(\"Дівчина стояла там, де й була, і намагалася привести до ладу скуйовджене волосся, вкрай розлючена тим, що це побачили водії, які чекали на переїзді.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деякі відмінності видно у зв'язку з різною токенізацію (можливим розв'язком було використання tokenize_uk і відключення tokenize у udpipe). На даних реченнях uas варіюється 0.5-0.6, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
