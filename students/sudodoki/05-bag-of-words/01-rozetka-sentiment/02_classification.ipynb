{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>review_markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Холодильником користуюсь близько трьох тижнів,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Любителям класики пораджу придбання двокамерно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Місяць вже як користуюся холодильником Купувал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Все чудово працює..стильний і гарна ціна!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Питання до користувачів цим холодильником або ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                      review_markup\n",
       "0   neutral  Холодильником користуюсь близько трьох тижнів,...\n",
       "1  positive  Любителям класики пораджу придбання двокамерно...\n",
       "2  positive  Місяць вже як користуюся холодильником Купувал...\n",
       "3  positive          Все чудово працює..стильний і гарна ціна!\n",
       "4  positive  Питання до користувачів цим холодильником або ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored = pd.read_json('cleaned_data.json.gz')\n",
    "restored.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(restored['review_markup'], restored['class'], test_size=0.25, random_state=42, stratify=restored['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.name = 'train'\n",
    "X_test.name = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='char', ngram_range=(1, 4)),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label, predictor, X, y):\n",
    "    print(\"{}. Evaluating on {}.\".format(label, X.name))\n",
    "    y_pred = predictor.predict(X)\n",
    "    accuracy = metrics.accuracy_score(y, y_pred)\n",
    "    print(metrics.confusion_matrix(y, y_pred, labels=['positive', 'negative', 'neutral']))\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(numbers):\n",
    "    return float(sum(numbers)) / max(len(numbers), 1)\n",
    "\n",
    "def cross_validate(label, predictor, X, y):\n",
    "    scores = cross_val_score(predictor, X, y, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    print(avg(scores), '<-', scores)\n",
    "    y_pred = cross_val_predict(text_pipe_logit, X, y, cv=5, n_jobs=-1)\n",
    "    return metrics.confusion_matrix(y, y_pred, labels=('positive', 'neutral', 'negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='char', ngram_range=(1, 4)),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899319364172223 <- [0.8960396  0.8960396  0.90049751 0.89949749 0.90452261]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[858,   4,  11],\n",
       "       [ 32,   9,   2],\n",
       "       [ 51,   1,  35]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"Vanilla LogReg w/ CountVectorizer on char n-grams 1-4\"\n",
    "cross_validate(label, text_pipe_logit, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "чи допоможе class_weight='balanced' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='char', ngram_range=(1, 4)),\n",
    "    LogisticRegression(n_jobs=-1, class_weight='balanced', random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8983441912780492 <- [0.88613861 0.8960396  0.90049751 0.89949749 0.90954774]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[854,   6,  13],\n",
       "       [ 31,   9,   3],\n",
       "       [ 47,   2,  38]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"LogReg class_weight=balanced w/ CountVectorizer on char n-grams 1-4\"\n",
    "cross_validate(label, text_pipe_logit, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "схоже, що ні. Спробуємо використати словник тональності"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Всевишній</td>\n",
       "      <td>0.885078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Господь</td>\n",
       "      <td>0.816095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Христовий</td>\n",
       "      <td>0.814423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>аборт</td>\n",
       "      <td>0.050470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>аварія</td>\n",
       "      <td>0.036755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word     score\n",
       "0  Всевишній  0.885078\n",
       "1    Господь  0.816095\n",
       "2  Христовий  0.814423\n",
       "3      аборт  0.050470\n",
       "4     аварія  0.036755"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_vocab = pd.read_csv('https://raw.githubusercontent.com/lang-uk/tone-dict-uk/master/tone-dict-uk-auto.tsv', names=['word', 'score'], header=None, sep='\\t')\n",
    "uk_vocab.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='word', vocabulary=uk_vocab['word'].ravel()),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704127504177703 <- [0.86633663 0.86633663 0.87064677 0.87437186 0.87437186]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[873,   0,   0],\n",
       "       [ 43,   0,   0],\n",
       "       [ 87,   0,   0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"LogReg w/ CountVectorizer on words based on sentiment vocab\"\n",
    "cross_validate(label, text_pipe_logit, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Якість впала порівняно с буквеними н-грамами, при цьому модель по суті видавала єдиний клас. Перевіримо, наскільки словник перетинається з словами з датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>акуратний</td>\n",
       "      <td>0.789571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>багатофункціональність</td>\n",
       "      <td>0.778706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>бомба</td>\n",
       "      <td>0.019866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>брак</td>\n",
       "      <td>0.044983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>важкий</td>\n",
       "      <td>0.781705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>веселий</td>\n",
       "      <td>0.869653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>вечір</td>\n",
       "      <td>0.825002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>вирізати</td>\n",
       "      <td>0.044759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>високий</td>\n",
       "      <td>0.870438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>витягнути</td>\n",
       "      <td>0.032205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>вишуканий</td>\n",
       "      <td>0.802876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>впевнений</td>\n",
       "      <td>0.852834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>відмінний</td>\n",
       "      <td>0.887853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>гарний</td>\n",
       "      <td>0.929702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>голубий</td>\n",
       "      <td>0.868311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>гріх</td>\n",
       "      <td>0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>дарувати</td>\n",
       "      <td>0.865810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>добрий</td>\n",
       "      <td>0.943053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>добротний</td>\n",
       "      <td>0.971479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>дорогий</td>\n",
       "      <td>0.890574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>досконалий</td>\n",
       "      <td>0.768897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>достойний</td>\n",
       "      <td>0.827592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>дошкуляти</td>\n",
       "      <td>0.024069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>дратувати</td>\n",
       "      <td>0.030870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>діапазон</td>\n",
       "      <td>0.823913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>екстремальний</td>\n",
       "      <td>0.850349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>живий</td>\n",
       "      <td>0.793822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>жіночний</td>\n",
       "      <td>0.876202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>завершити</td>\n",
       "      <td>0.817056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>збалансований</td>\n",
       "      <td>0.811389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>обрамлення</td>\n",
       "      <td>0.818813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>палити</td>\n",
       "      <td>0.035695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>паршивий</td>\n",
       "      <td>0.021239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>повноцінний</td>\n",
       "      <td>0.803348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>подарунок</td>\n",
       "      <td>0.852501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>помогти</td>\n",
       "      <td>0.775823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>почесний</td>\n",
       "      <td>0.960917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>правильний</td>\n",
       "      <td>0.876900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>прекрасний</td>\n",
       "      <td>0.783466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>привабливий</td>\n",
       "      <td>0.868858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>прийняти</td>\n",
       "      <td>0.875478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>приємний</td>\n",
       "      <td>0.857305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>простіший</td>\n",
       "      <td>0.787424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>професійний</td>\n",
       "      <td>0.867845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>піднятий</td>\n",
       "      <td>0.809054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>симпатичний</td>\n",
       "      <td>0.838911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>скрипіти</td>\n",
       "      <td>0.032596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>слухати</td>\n",
       "      <td>0.771785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>стукнути</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>терпіння</td>\n",
       "      <td>0.834099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>точний</td>\n",
       "      <td>0.826504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>ура</td>\n",
       "      <td>0.801632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ховати</td>\n",
       "      <td>0.039449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>хороший</td>\n",
       "      <td>0.865073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>чистий</td>\n",
       "      <td>0.784211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>чудовий</td>\n",
       "      <td>0.905502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>швидкий</td>\n",
       "      <td>0.807917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>шикарний</td>\n",
       "      <td>0.845302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>широкий</td>\n",
       "      <td>0.849730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>яскравий</td>\n",
       "      <td>0.803820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word     score\n",
       "10                 акуратний  0.789571\n",
       "20    багатофункціональність  0.778706\n",
       "71                     бомба  0.019866\n",
       "74                      брак  0.044983\n",
       "93                    важкий  0.781705\n",
       "109                  веселий  0.869653\n",
       "110                    вечір  0.825002\n",
       "144                 вирізати  0.044759\n",
       "147                  високий  0.870438\n",
       "156                витягнути  0.032205\n",
       "159                вишуканий  0.802876\n",
       "171                впевнений  0.852834\n",
       "197                відмінний  0.887853\n",
       "222                   гарний  0.929702\n",
       "230                  голубий  0.868311\n",
       "238                     гріх  0.040567\n",
       "250                 дарувати  0.865810\n",
       "265                   добрий  0.943053\n",
       "270                добротний  0.971479\n",
       "282                  дорогий  0.890574\n",
       "284               досконалий  0.768897\n",
       "285                достойний  0.827592\n",
       "288                дошкуляти  0.024069\n",
       "291                дратувати  0.030870\n",
       "301                 діапазон  0.823913\n",
       "308            екстремальний  0.850349\n",
       "320                    живий  0.793822\n",
       "327                 жіночний  0.876202\n",
       "331                завершити  0.817056\n",
       "392            збалансований  0.811389\n",
       "...                      ...       ...\n",
       "757               обрамлення  0.818813\n",
       "793                   палити  0.035695\n",
       "796                 паршивий  0.021239\n",
       "839              повноцінний  0.803348\n",
       "852                подарунок  0.852501\n",
       "880                  помогти  0.775823\n",
       "898                 почесний  0.960917\n",
       "903               правильний  0.876900\n",
       "905               прекрасний  0.783466\n",
       "909              привабливий  0.868858\n",
       "916                 прийняти  0.875478\n",
       "932                 приємний  0.857305\n",
       "948                простіший  0.787424\n",
       "950              професійний  0.867845\n",
       "964                 піднятий  0.809054\n",
       "1055             симпатичний  0.838911\n",
       "1067                скрипіти  0.032596\n",
       "1073                 слухати  0.771785\n",
       "1118                стукнути  0.035996\n",
       "1146                терпіння  0.834099\n",
       "1158                  точний  0.826504\n",
       "1182                     ура  0.801632\n",
       "1212                  ховати  0.039449\n",
       "1214                 хороший  0.865073\n",
       "1237                  чистий  0.784211\n",
       "1240                 чудовий  0.905502\n",
       "1250                 швидкий  0.807917\n",
       "1252                шикарний  0.845302\n",
       "1253                 широкий  0.849730\n",
       "1267                яскравий  0.803820\n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sktext.CountVectorizer(preprocessor=preprocess, analyzer='word', vocabulary=uk_vocab['word'].ravel())\n",
    "senti_words = vocab.transform(X_train)\n",
    "uk_vocab[(senti_words.sum(axis=0) > 0).T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "лише 86 слів перетнулися, що призвело до дуже sparse матриці та напевно багатьох рядків, що повністю складаються з нулів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 700)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_words[senti_words.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "маємо таких рядків більше половини. Можливо, лематизація могла би допомогти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2lemmas (str):\n",
    "    words = re.split(\"\\s\", str)\n",
    "    res = []\n",
    "    for word in words:\n",
    "        tag = morph.parse(word)\n",
    "        res.append(tag[0].normal_form)\n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>адаптований</td>\n",
       "      <td>0.797213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>акуратний</td>\n",
       "      <td>0.789571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>багатий</td>\n",
       "      <td>0.849303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>багатофункціональність</td>\n",
       "      <td>0.778706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>бомба</td>\n",
       "      <td>0.019866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>боятися</td>\n",
       "      <td>0.020242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>брак</td>\n",
       "      <td>0.044983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>важкий</td>\n",
       "      <td>0.781705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>валити</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>веселий</td>\n",
       "      <td>0.869653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>вечір</td>\n",
       "      <td>0.825002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>виграш</td>\n",
       "      <td>0.917835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>вигідний</td>\n",
       "      <td>0.827291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>використати</td>\n",
       "      <td>0.765567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>винний</td>\n",
       "      <td>0.010222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>виручати</td>\n",
       "      <td>0.821970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>вирізати</td>\n",
       "      <td>0.044759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>високий</td>\n",
       "      <td>0.870438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>високотехнологічний</td>\n",
       "      <td>0.838688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>витягнути</td>\n",
       "      <td>0.032205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>вишуканий</td>\n",
       "      <td>0.802876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>властивий</td>\n",
       "      <td>0.790059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>впевнений</td>\n",
       "      <td>0.852834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>відмовитися</td>\n",
       "      <td>0.040837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>відмінний</td>\n",
       "      <td>0.887853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>гарантувати</td>\n",
       "      <td>0.872064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>гармонія</td>\n",
       "      <td>0.844835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>гарний</td>\n",
       "      <td>0.929702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>голубий</td>\n",
       "      <td>0.868311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>гріх</td>\n",
       "      <td>0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>скрипіти</td>\n",
       "      <td>0.032596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>слава</td>\n",
       "      <td>0.809981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>слухати</td>\n",
       "      <td>0.771785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>смердіти</td>\n",
       "      <td>0.023452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>сонячний</td>\n",
       "      <td>0.870131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>спасибі</td>\n",
       "      <td>0.969965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>спокійний</td>\n",
       "      <td>0.871941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>спітніти</td>\n",
       "      <td>0.018281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>сріблястий</td>\n",
       "      <td>0.770436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>срібний</td>\n",
       "      <td>0.798579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>стабілізація</td>\n",
       "      <td>0.868983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>стукнути</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>терпіння</td>\n",
       "      <td>0.834099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>точний</td>\n",
       "      <td>0.826504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>тріщати</td>\n",
       "      <td>0.043195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>ура</td>\n",
       "      <td>0.801632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ховати</td>\n",
       "      <td>0.039449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>хороший</td>\n",
       "      <td>0.865073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>хронічний</td>\n",
       "      <td>0.035452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>цінувати</td>\n",
       "      <td>0.943426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>чесний</td>\n",
       "      <td>0.803288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>чистий</td>\n",
       "      <td>0.784211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>чудовий</td>\n",
       "      <td>0.905502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>швидкий</td>\n",
       "      <td>0.807917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>швидший</td>\n",
       "      <td>0.784222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>шикарний</td>\n",
       "      <td>0.845302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>широкий</td>\n",
       "      <td>0.849730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>шкодувати</td>\n",
       "      <td>0.043690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>щасливий</td>\n",
       "      <td>0.904946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>яскравий</td>\n",
       "      <td>0.803820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word     score\n",
       "7                адаптований  0.797213\n",
       "10                 акуратний  0.789571\n",
       "18                   багатий  0.849303\n",
       "20    багатофункціональність  0.778706\n",
       "71                     бомба  0.019866\n",
       "73                   боятися  0.020242\n",
       "74                      брак  0.044983\n",
       "93                    важкий  0.781705\n",
       "94                    валити  0.014925\n",
       "109                  веселий  0.869653\n",
       "110                    вечір  0.825002\n",
       "120                   виграш  0.917835\n",
       "122                 вигідний  0.827291\n",
       "129              використати  0.765567\n",
       "135                   винний  0.010222\n",
       "143                 виручати  0.821970\n",
       "144                 вирізати  0.044759\n",
       "147                  високий  0.870438\n",
       "150      високотехнологічний  0.838688\n",
       "156                витягнути  0.032205\n",
       "159                вишуканий  0.802876\n",
       "164                властивий  0.790059\n",
       "171                впевнений  0.852834\n",
       "195              відмовитися  0.040837\n",
       "197                відмінний  0.887853\n",
       "218              гарантувати  0.872064\n",
       "220                 гармонія  0.844835\n",
       "222                   гарний  0.929702\n",
       "230                  голубий  0.868311\n",
       "238                     гріх  0.040567\n",
       "...                      ...       ...\n",
       "1067                скрипіти  0.032596\n",
       "1070                   слава  0.809981\n",
       "1073                 слухати  0.771785\n",
       "1076                смердіти  0.023452\n",
       "1085                сонячний  0.870131\n",
       "1091                 спасибі  0.969965\n",
       "1099               спокійний  0.871941\n",
       "1107                спітніти  0.018281\n",
       "1108              сріблястий  0.770436\n",
       "1109                 срібний  0.798579\n",
       "1110            стабілізація  0.868983\n",
       "1118                стукнути  0.035996\n",
       "1146                терпіння  0.834099\n",
       "1158                  точний  0.826504\n",
       "1164                 тріщати  0.043195\n",
       "1182                     ура  0.801632\n",
       "1212                  ховати  0.039449\n",
       "1214                 хороший  0.865073\n",
       "1217               хронічний  0.035452\n",
       "1231                цінувати  0.943426\n",
       "1235                  чесний  0.803288\n",
       "1237                  чистий  0.784211\n",
       "1240                 чудовий  0.905502\n",
       "1250                 швидкий  0.807917\n",
       "1251                 швидший  0.784222\n",
       "1252                шикарний  0.845302\n",
       "1253                 широкий  0.849730\n",
       "1254               шкодувати  0.043690\n",
       "1259                щасливий  0.904946\n",
       "1267                яскравий  0.803820\n",
       "\n",
       "[166 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lemmas = X_train.apply(words2lemmas)\n",
    "vocab = sktext.CountVectorizer(preprocessor=preprocess, analyzer='word', vocabulary=uk_vocab['word'].ravel())\n",
    "senti_words = vocab.transform(X_lemmas)\n",
    "uk_vocab[(senti_words.sum(axis=0) > 0).T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало краще, кілкість слів збільшилась вдвічі. Перевіримо, як це вплинуло на якість підходу з використанням словника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='word', vocabulary=uk_vocab['word'].ravel()),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8724228006690267 <- [0.86633663 0.86633663 0.87064677 0.87939698 0.87939698]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[873,   0,   0],\n",
       "       [ 43,   0,   0],\n",
       "       [ 85,   0,   2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"LogReg w/ CountVectorizer on words' lemmas based on sentiment vocab\"\n",
    "cross_validate(label, text_pipe_logit, X_lemmas, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Якість покращилися, але дуже незначним чином. Отримавши речення з лише леммами, скористаємося двома початковими підходами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='char', ngram_range=(1, 4)),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9073147868300669 <- [0.91089109 0.8960396  0.90049751 0.91959799 0.90954774]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[863,   3,   7],\n",
       "       [ 31,   8,   4],\n",
       "       [ 47,   1,  39]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"Vanilla LogReg w/ CountVectorizer on char n-grams 1-4 over lemmas\"\n",
    "cross_validate(label, text_pipe_logit, X_lemmas, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показник точності (accuracy) зріс у порівнянні з початковим, але при цьому середньоквадратичне відхилленя становить 0.008, що означає більш широкий інтервал для оцінки точності у порівнянні з 0.003 (0.907315 ± 0.008274 vs 0.899319 ± 0.003163).\n",
    "Ну що ж, тоді перевіримо обидві моделі на відкладенній виборці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747505786575145 <- [0.86764706 0.85074627 0.86567164 0.88059701 0.90909091]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[286,   1,   4],\n",
       "       [ 11,   2,   2],\n",
       "       [ 24,   0,   5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"Vanilla LogReg w/ CountVectorizer on char n-grams 1-4 over lemmas\"\n",
    "cross_validate(label, text_pipe_logit, X_test.apply(words2lemmas), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='char', ngram_range=(1, 4)),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747053502540771 <- [0.86764706 0.86567164 0.85074627 0.89552239 0.89393939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[284,   3,   4],\n",
       "       [ 13,   2,   0],\n",
       "       [ 22,   0,   7]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  = \"Vanilla LogReg w/ CountVectorizer on char n-grams 1-4\"\n",
    "cross_validate(label, text_pipe_logit, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данному випадку модель з леммами показала кращий результат. Можливо, це результат підгонки і недбалого використання тестового сету, що не дозволяє з певністю говорити про покращення якості з використанням лемм. Словник сентиментів не допоміг у покращенні моделі, гіпотетичні причини:\n",
    "- розподіл слів і значень у анатованих матеріалах (наприклад, \"бомба\" має низьку оцінку, але в даному контексті було використано у позитивному сенсі)\n",
    "- низький % перетину множин слів з словнику і у відгуках\n",
    "- мала кількіть зібраних вигуків / необхідність додаткової попередньої обробки / помилка у коді\n",
    "- неправильна детекція мови призвела до помилки у даних, що призвело до погіршення якості при використанні україномовного словника\n",
    "- помилки у словах користувачів призвели до неможливості співставити їх з початковим словом\n",
    "- неправильний поділ на позитивні/негативні/нейтральні відгуки і необхідність подальшого розбиття на речення з відповідними забарвленнями\n",
    "\n",
    "Можливі заходи для уникнення проблем:\n",
    "- ручні анотації сентиментів кожного окремого речення із відгуків\n",
    "- виправлення помилок користувачів / пошук у словниках найближчих слів за редакторською відстанню\n",
    "- пошук додаткових данних\n",
    "- побудова векторних представлень на корпусі інтернет-відгуків / інтернет комунікацій з подібним мовним розподілом і розширення словника тональності за рахунок їх"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забув спробувати використовувати набір стоп-слів, але, враховуючи, що найкращі модель н-грамні, їх використання не мусить значно покращити результат. Подивимось, що буде з моделями на словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://meta-ukraine.com/ua/pages/stopwrd.asp\n",
    "STOP_WORDS = \"навіть для де до дещо це адже авжеж що майже так такий також те тобто ледве тощо тож під отже отож як який\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8806754995078085 <- [0.86764706 0.86567164 0.88059701 0.89552239 0.89393939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[290,   0,   1],\n",
       "       [ 13,   2,   0],\n",
       "       [ 26,   0,   3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='word'),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")\n",
    "label  = \"Vanilla LogReg w/ CountVectorizer on words without stop words\"\n",
    "cross_validate(label, text_pipe_logit, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8806754995078085 <- [0.86764706 0.88059701 0.86567164 0.89552239 0.89393939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[291,   0,   0],\n",
       "       [ 13,   2,   0],\n",
       "       [ 27,   0,   2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    return text\n",
    "text_pipe_logit = make_pipeline(\n",
    "    sktext.CountVectorizer(preprocessor=preprocess, analyzer='word', stop_words=STOP_WORDS),\n",
    "    LogisticRegression(n_jobs=-1, random_state=42)\n",
    ")\n",
    "label  = \"Vanilla LogReg w/ CountVectorizer on words with stop words\"\n",
    "cross_validate(label, text_pipe_logit, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "точність не змінилася (додатково 1 правильно класифікований позитивний відгук і 1 неправильно класифікований негативний)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
