{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import qgrid\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:03<00:00, 77.94it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned = pd.read_csv('dataset/phrases_cleaned_1522422847595.csv', usecols=['id', 'phrase'])\n",
    "cleaned = cleaned.assign(doc=cleaned['phrase'].progress_apply(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:00<00:00, 30910.16it/s]\n"
     ]
    }
   ],
   "source": [
    "SPLITS = {'who', ',','and'}\n",
    "cleaned = cleaned.assign(idxs=cleaned['doc'].progress_apply(lambda doc: [tok.idx for tok in doc if tok.lemma_ in SPLITS]))\n",
    "splitted_again = []\n",
    "with_indicies = []\n",
    "for i,row in cleaned.iterrows():\n",
    "    idxs = set(row['idxs'])\n",
    "    phrase = row['phrase']\n",
    "    subphrases = []\n",
    "    subphrase = ''\n",
    "    for i,ch in enumerate(phrase):\n",
    "        if i in idxs:\n",
    "            subphrases.append(subphrase)\n",
    "            subphrase = ch\n",
    "        else:\n",
    "            subphrase += ch\n",
    "    splitted_again.append(subphrases)\n",
    "    with_indicies.append([[tok.idx,tok] for tok in row['doc']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b459b66007451b8a4e0ae27c889386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_dollars(phrase):\n",
    "    doc = nlp(phrase)\n",
    "    new_phrase = phrase\n",
    "    acc = 0\n",
    "    for tok in doc:\n",
    "        if tok.lemma_ in SPLITS:\n",
    "            new_phrase = new_phrase[:tok.idx+acc] + '$$' + new_phrase[tok.idx+acc:]\n",
    "            acc += 2\n",
    "    return new_phrase\n",
    "\n",
    "#qdf = pd.DataFrame({'text': cleaned['phrase'].apply(add_dollars)})\n",
    "qdf = pd.read_csv('new_splitted.csv', index_col=0)\n",
    "widget = qgrid.show_grid(qdf)\n",
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>search_attrs</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>98be4665-b3db-4133-a8cf-299dfa8205ab</td>\n",
       "      <td>Kostia Rybnikov</td>\n",
       "      <td>1522249286679</td>\n",
       "      <td>1522249944131</td>\n",
       "      <td>[{\"short\": \"whose bio contains 'biplane'\", \"type\": \"text\", \"name\": \"profile.bio\", \"example\": \"1\"}, {\"short\": \"1 times\", \"name\": \"events.count\"}, {\"short\": \"with positive sentiment\", \"type\": \"Sentiment\", \"name\": \"like.postSentiment\", \"human\": \"liked {sentiment} post\", \"example\": \"Attendees who li...</td>\n",
       "      <td>From people with a \"biplane\" in their profile description find those who attended an event once and liked a post that can be said to be a positive one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id           author        created  \\\n",
       "84  98be4665-b3db-4133-a8cf-299dfa8205ab  Kostia Rybnikov  1522249286679   \n",
       "\n",
       "         modified  \\\n",
       "84  1522249944131   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   search_attrs  \\\n",
       "84  [{\"short\": \"whose bio contains 'biplane'\", \"type\": \"text\", \"name\": \"profile.bio\", \"example\": \"1\"}, {\"short\": \"1 times\", \"name\": \"events.count\"}, {\"short\": \"with positive sentiment\", \"type\": \"Sentiment\", \"name\": \"like.postSentiment\", \"human\": \"liked {sentiment} post\", \"example\": \"Attendees who li...   \n",
       "\n",
       "                                                                                                                                                    phrase  \n",
       "84  From people with a \"biplane\" in their profile description find those who attended an event once and liked a post that can be said to be a positive one  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted = pd.read_csv('dataset/phrases_cleaned_1522422847595.csv')\n",
    "splitted.iloc[[84]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.get_changed_df().to_csv('new_splitted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find people $$who wrote posts mentioning Stacy Vaughn $$and liked any post 9 times $$and clicked on ad with 'blackout' in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Find all attendees $$who wrote at least one post with mention of Stacy Vaughn $$and liked any post 9 or more times $$and clickd on ad with text 'blackout' in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find all attendees $$who wrote a post about Stacy Vaughn $$and have at least nine likes $$and clickd on add that contained 'blackout'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find all attendees $$who clicked on ad about blackout $$and also liked post 9 times $$and wrote post with Stacy Vaughn's mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find client $$who wrote Stacy Vaughn's post $$and liked it 9 times $$as well as clicked on ad that contains 'blackout'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                               text\n",
       "0                                      Find people $$who wrote posts mentioning Stacy Vaughn $$and liked any post 9 times $$and clicked on ad with 'blackout' in it\n",
       "1  Find all attendees $$who wrote at least one post with mention of Stacy Vaughn $$and liked any post 9 or more times $$and clickd on ad with text 'blackout' in it\n",
       "2                             Find all attendees $$who wrote a post about Stacy Vaughn $$and have at least nine likes $$and clickd on add that contained 'blackout'\n",
       "3                                  Find all attendees $$who clicked on ad about blackout $$and also liked post 9 times $$and wrote post with Stacy Vaughn's mention\n",
       "4                                            Find client $$who wrote Stacy Vaughn's post $$and liked it 9 times $$as well as clicked on ad that contains 'blackout'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = pd.read_csv('new_splitted.csv', index_col=0)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_splitter_ids(text):\n",
    "    idxs = []\n",
    "    subs = 0\n",
    "    for match in re.finditer(r'\\$\\$', text):\n",
    "        idxs.append(match.start() - subs)\n",
    "        subs += 2\n",
    "    return idxs\n",
    "\n",
    "sdf = sdf.assign(idxs=sdf['text'].apply(extract_splitter_ids))\n",
    "sdf = sdf.assign(clean = sdf['text'].apply(lambda t: re.sub(r'\\$\\$', '', t)))\n",
    "cdf = sdf[['idxs', 'clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idxs</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 52, 79]</td>\n",
       "      <td>Find people who wrote posts mentioning Stacy Vaughn and liked any post 9 times and clicked on ad with 'blackout' in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19, 76, 111]</td>\n",
       "      <td>Find all attendees who wrote at least one post with mention of Stacy Vaughn and liked any post 9 or more times and clickd on ad with text 'blackout' in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[19, 55, 84]</td>\n",
       "      <td>Find all attendees who wrote a post about Stacy Vaughn and have at least nine likes and clickd on add that contained 'blackout'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19, 52, 80]</td>\n",
       "      <td>Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, 42, 63]</td>\n",
       "      <td>Find client who wrote Stacy Vaughn's post and liked it 9 times as well as clicked on ad that contains 'blackout'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idxs  \\\n",
       "0   [12, 52, 79]   \n",
       "1  [19, 76, 111]   \n",
       "2   [19, 55, 84]   \n",
       "3   [19, 52, 80]   \n",
       "4   [12, 42, 63]   \n",
       "\n",
       "                                                                                                                                                        clean  \n",
       "0                                      Find people who wrote posts mentioning Stacy Vaughn and liked any post 9 times and clicked on ad with 'blackout' in it  \n",
       "1  Find all attendees who wrote at least one post with mention of Stacy Vaughn and liked any post 9 or more times and clickd on ad with text 'blackout' in it  \n",
       "2                             Find all attendees who wrote a post about Stacy Vaughn and have at least nine likes and clickd on add that contained 'blackout'  \n",
       "3                                  Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention  \n",
       "4                                            Find client who wrote Stacy Vaughn's post and liked it 9 times as well as clicked on ad that contains 'blackout'  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idxs</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[12, 52, 79]</td>\n",
       "      <td>Find people who wrote posts mentioning Stacy Vaughn and liked any post 9 times and clicked on ad with 'blackout' in it</td>\n",
       "      <td>(Find, people, who, wrote, posts, mentioning, Stacy, Vaughn, and, liked, any, post, 9, times, and, clicked, on, ad, with, ', blackout, ', in, it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[19, 76, 111]</td>\n",
       "      <td>Find all attendees who wrote at least one post with mention of Stacy Vaughn and liked any post 9 or more times and clickd on ad with text 'blackout' in it</td>\n",
       "      <td>(Find, all, attendees, who, wrote, at, least, one, post, with, mention, of, Stacy, Vaughn, and, liked, any, post, 9, or, more, times, and, clickd, on, ad, with, text, ', blackout, ', in, it)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[19, 55, 84]</td>\n",
       "      <td>Find all attendees who wrote a post about Stacy Vaughn and have at least nine likes and clickd on add that contained 'blackout'</td>\n",
       "      <td>(Find, all, attendees, who, wrote, a, post, about, Stacy, Vaughn, and, have, at, least, nine, likes, and, clickd, on, add, that, contained, ', blackout, ')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19, 52, 80]</td>\n",
       "      <td>Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention</td>\n",
       "      <td>(Find, all, attendees, who, clicked, on, ad, about, blackout, and, also, liked, post, 9, times, and, wrote, post, with, Stacy, Vaughn, 's, mention)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, 42, 63]</td>\n",
       "      <td>Find client who wrote Stacy Vaughn's post and liked it 9 times as well as clicked on ad that contains 'blackout'</td>\n",
       "      <td>(Find, client, who, wrote, Stacy, Vaughn, 's, post, and, liked, it, 9, times, as, well, as, clicked, on, ad, that, contains, ', blackout, ')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idxs  \\\n",
       "0   [12, 52, 79]   \n",
       "1  [19, 76, 111]   \n",
       "2   [19, 55, 84]   \n",
       "3   [19, 52, 80]   \n",
       "4   [12, 42, 63]   \n",
       "\n",
       "                                                                                                                                                        clean  \\\n",
       "0                                      Find people who wrote posts mentioning Stacy Vaughn and liked any post 9 times and clicked on ad with 'blackout' in it   \n",
       "1  Find all attendees who wrote at least one post with mention of Stacy Vaughn and liked any post 9 or more times and clickd on ad with text 'blackout' in it   \n",
       "2                             Find all attendees who wrote a post about Stacy Vaughn and have at least nine likes and clickd on add that contained 'blackout'   \n",
       "3                                  Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention   \n",
       "4                                            Find client who wrote Stacy Vaughn's post and liked it 9 times as well as clicked on ad that contains 'blackout'   \n",
       "\n",
       "                                                                                                                                                                                           tokens  \n",
       "0                                               (Find, people, who, wrote, posts, mentioning, Stacy, Vaughn, and, liked, any, post, 9, times, and, clicked, on, ad, with, ', blackout, ', in, it)  \n",
       "1  (Find, all, attendees, who, wrote, at, least, one, post, with, mention, of, Stacy, Vaughn, and, liked, any, post, 9, or, more, times, and, clickd, on, ad, with, text, ', blackout, ', in, it)  \n",
       "2                                     (Find, all, attendees, who, wrote, a, post, about, Stacy, Vaughn, and, have, at, least, nine, likes, and, clickd, on, add, that, contained, ', blackout, ')  \n",
       "3                                             (Find, all, attendees, who, clicked, on, ad, about, blackout, and, also, liked, post, 9, times, and, wrote, post, with, Stacy, Vaughn, 's, mention)  \n",
       "4                                                    (Find, client, who, wrote, Stacy, Vaughn, 's, post, and, liked, it, 9, times, as, well, as, clicked, on, ad, that, contains, ', blackout, ')  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = cdf.assign(tokens=cdf['clean'].apply(lambda text: nlp(text)))\n",
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examples = []\n",
    "for i,row in tokenized.iterrows():\n",
    "    tokens = row['tokens']\n",
    "    idxs = set(row['idxs'])\n",
    "    row_labels = []\n",
    "    #print(idxs)\n",
    "    #print(list(zip(tokens, [token.idx for token in tokens])))\n",
    "    for token in tokens:\n",
    "        if token.idx in idxs:\n",
    "            row_labels.append(1)\n",
    "        else:\n",
    "            row_labels.append(0)\n",
    "    examples.append(list(zip([token.text for token in tokens], row_labels)))\n",
    "            \n",
    "with open('labled_tokenized.json', 'w') as f:\n",
    "    json.dump(examples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "with open('labled_tokenized.json', 'r') as f:\n",
    "    examples = json.load(f)\n",
    "train,test = train_test_split(examples)\n",
    "with open('labled_tokenized.train.json', 'w') as trf, open('labled_tokenized.test.json', 'w') as tt:\n",
    "    json.dump(train, trf)\n",
    "    json.dump(test, tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open('labled_tokenized.train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tokens):\n",
    "    N = len(tokens)\n",
    "    all_features = []\n",
    "    for i in range(N):\n",
    "        features = {\n",
    "            'text': tokens[i].text,\n",
    "            'lemma': tokens[i].lemma_,\n",
    "            'pos': tokens[i].tag_,\n",
    "            'text-1': tokens[i-1].text if i-1 >= 0 else 'NONE',\n",
    "            'lemma-1': tokens[i-1].lemma_ if i-1 >= 0 else 'NONE',\n",
    "            'pos-1': tokens[i-1].pos_ if i-1 >= 0 else 'NONE',\n",
    "            'text+1': tokens[i+1].text if i+1 < N else 'NONE',\n",
    "            'lemma+1': tokens[i+1].lemma_ if i+1 < N else 'NONE',\n",
    "            'pos+1': tokens[i+1].pos_ if i+1 < N else 'NONE'\n",
    "        }\n",
    "        all_features.append(features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(sentences):\n",
    "    all_features = []\n",
    "    ys = []\n",
    "    for sent in sentences:\n",
    "        tokens = spacy.tokens.Doc(nlp.vocab, words=[pair[0] for pair in sent])\n",
    "        nlp.tagger(tokens)\n",
    "        nlp.parser(tokens)\n",
    "        sent_features = extract(tokens)\n",
    "        ys += [pair[1] for pair in sent]\n",
    "        all_features += sent_features\n",
    "    return (all_features, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features,ys = extract_all(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "cv = cross_validate(pipe, all_features, ys, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/serhiinechyporhuk/.local/share/virtualenvs/SerhiiNechyporchuk-Ib9yWLjX/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04539394, 0.04273796, 0.04250598]),\n",
       " 'score_time': array([0.01965213, 0.01928902, 0.01919818]),\n",
       " 'test_score': array([0.88038278, 0.88305489, 0.88361045]),\n",
       " 'train_score': array([0.8973747 , 0.89663462, 0.9031477 ])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(all_features, ys)\n",
    "df = pd.DataFrame(all_features)\n",
    "df = df.assign(label = ys)\n",
    "df = df.assign(predicted = pipe.predict(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma+1</th>\n",
       "      <th>lemma-1</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos+1</th>\n",
       "      <th>pos-1</th>\n",
       "      <th>text</th>\n",
       "      <th>text+1</th>\n",
       "      <th>text-1</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>biologist</td>\n",
       "      <td>NONE</td>\n",
       "      <td>every</td>\n",
       "      <td>NN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>DET</td>\n",
       "      <td>biologist</td>\n",
       "      <td>NONE</td>\n",
       "      <td>every</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>with</td>\n",
       "      <td>'</td>\n",
       "      <td>people</td>\n",
       "      <td>IN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>with</td>\n",
       "      <td>'</td>\n",
       "      <td>people</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>attendee</td>\n",
       "      <td>name</td>\n",
       "      <td>for</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>attendees</td>\n",
       "      <td>named</td>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>click</td>\n",
       "      <td>5</td>\n",
       "      <td>user</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>clicked</td>\n",
       "      <td>5</td>\n",
       "      <td>users</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>those</td>\n",
       "      <td>who</td>\n",
       "      <td>find</td>\n",
       "      <td>DT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>those</td>\n",
       "      <td>who</td>\n",
       "      <td>find</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>administrative</td>\n",
       "      <td>generalist</td>\n",
       "      <td>all</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>DET</td>\n",
       "      <td>Administrative</td>\n",
       "      <td>Generalist</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>vida</td>\n",
       "      <td>NONE</td>\n",
       "      <td>find</td>\n",
       "      <td>FW</td>\n",
       "      <td>NONE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>vida</td>\n",
       "      <td>NONE</td>\n",
       "      <td>find</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>mention</td>\n",
       "      <td>'</td>\n",
       "      <td>who</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>mentioned</td>\n",
       "      <td>'</td>\n",
       "      <td>Who</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>with</td>\n",
       "      <td>\"</td>\n",
       "      <td>someone</td>\n",
       "      <td>IN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>with</td>\n",
       "      <td>\"</td>\n",
       "      <td>someone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>rgarcia@optonline.net</td>\n",
       "      <td>NONE</td>\n",
       "      <td>find</td>\n",
       "      <td>.</td>\n",
       "      <td>NONE</td>\n",
       "      <td>VERB</td>\n",
       "      <td>rgarcia@optonline.net</td>\n",
       "      <td>NONE</td>\n",
       "      <td>find</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lemma     lemma+1  lemma-1  pos  pos+1 pos-1  \\\n",
       "30                biologist        NONE    every   NN   NONE   DET   \n",
       "272                    with           '   people   IN  PUNCT  NOUN   \n",
       "292                attendee        name      for  NNS   VERB   ADP   \n",
       "642                   click           5     user  VBD    NUM  NOUN   \n",
       "855                   those         who     find   DT   NOUN  VERB   \n",
       "880          administrative  generalist      all  NNP  PROPN   DET   \n",
       "1944                   vida        NONE     find   FW   NONE  VERB   \n",
       "2349                mention           '      who  VBD  PUNCT  NOUN   \n",
       "4092                   with           \"  someone   IN  PUNCT  NOUN   \n",
       "4446  rgarcia@optonline.net        NONE     find    .   NONE  VERB   \n",
       "\n",
       "                       text      text+1   text-1  label  predicted  \n",
       "30                biologist        NONE    every      1          0  \n",
       "272                    with           '   people      1          0  \n",
       "292               attendees       named      for      1          0  \n",
       "642                 clicked           5    users      1          0  \n",
       "855                   those         who     find      1          0  \n",
       "880          Administrative  Generalist      all      1          0  \n",
       "1944                   vida        NONE     find      1          0  \n",
       "2349              mentioned           '      Who      1          0  \n",
       "4092                   with           \"  someone      1          0  \n",
       "4446  rgarcia@optonline.net        NONE     find      1          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['label'] == 1) & (df['predicted'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_ys = extract(json.load(open('labled_tokenized.train.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = pipe.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8997594226142742"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_ys, test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['splitter.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe, 'splitter.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize into tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Find, all, attendees],\n",
       " who,\n",
       " [clicked, on, ad, about, blackout],\n",
       " and,\n",
       " [also, liked, post, 9, times],\n",
       " and,\n",
       " [wrote, post, with, Stacy, Vaughn, 's, mention]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(cls, sent):\n",
    "    tokens = nlp(sent)\n",
    "    features = extract(tokens)\n",
    "    stops = cls.predict(features)\n",
    "    parts = []\n",
    "    part = []\n",
    "    for token,stop in zip(tokens, stops):\n",
    "        if stop:\n",
    "            parts.append(part)\n",
    "            parts.append(token)\n",
    "            part = []\n",
    "        else:\n",
    "            part.append(token)\n",
    "    parts.append(part)\n",
    "    return parts\n",
    "\n",
    "split(pipe, \"Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "spacy_tokenizer = lambda xs: [x.lemma_ for x in xs]\n",
    "fclf = joblib.load('filter_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = split(pipe, \"Find all attendees who clicked on ad about blackout and also liked post 9 times and wrote post with Stacy Vaughn's mention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_in_tree_(parts, tree):\n",
    "    if parts: \n",
    "        part = parts[0]\n",
    "        rest = parts[1:]\n",
    "        (l,n,r) = tree\n",
    "        if isinstance(part, list):\n",
    "            if not l:\n",
    "                return organize_in_tree_(rest, (part, n, r))\n",
    "            elif not r:\n",
    "                return organize_in_tree_(rest, (l,n,part))\n",
    "            else:\n",
    "                raise Exception(\"node in invalid position\")\n",
    "        else:\n",
    "            if not n:\n",
    "                return organize_in_tree_(rest, (l, part, r))\n",
    "            else:\n",
    "                return organize_in_tree_(rest, (tree, part, None))\n",
    "    else:\n",
    "        return tree\n",
    "        \n",
    "def organize_in_tree(parts):\n",
    "    return organize_in_tree_(parts[2:], (None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([clicked, on, ad, about, blackout], and, [also, liked, post, 9, times]),\n",
       " and,\n",
       " [wrote, post, with, Stacy, Vaughn, 's, mention])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organize_in_tree(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
