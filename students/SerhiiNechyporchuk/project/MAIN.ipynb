{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase                 attendees posted at least one post with <sentiment> sentiment\n",
      "replacements                                               {\"sentiment\": \"negative\"}\n",
      "label                                                                           post\n",
      "ex                               {\"post.sentiment\": \"negative\", \"post.count\": \">=1\"}\n",
      "final           (attendees, posted, at, least, one, post, with, negative, sentiment)\n",
      "orig_final                attendees posted at least one post with negative sentiment\n",
      "grepl                                                                             []\n",
      "Name: 290, dtype: object\n",
      "attendees posted at least one post with negative sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1625\" height=\"399.5\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">attendees</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">posted</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">least</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">one</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">post</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">negative</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sentiment</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attendee posted nsubj\n",
      "post posted ROOT\n",
      "at least advmod\n",
      "least one advmod\n",
      "one post nummod\n",
      "post posted dobj\n",
      "with post prep\n",
      "negative sentiment amod\n",
      "sentiment with pobj\n"
     ]
    }
   ],
   "source": [
    "%run ArgExtraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tokens):\n",
    "    N = len(tokens)\n",
    "    all_features = []\n",
    "    for i in range(N):\n",
    "        features = {\n",
    "            'text': tokens[i].text,\n",
    "            'lemma': tokens[i].lemma_,\n",
    "            'pos': tokens[i].tag_,\n",
    "            'text-1': tokens[i-1].text if i-1 >= 0 else 'NONE',\n",
    "            'lemma-1': tokens[i-1].lemma_ if i-1 >= 0 else 'NONE',\n",
    "            'pos-1': tokens[i-1].pos_ if i-1 >= 0 else 'NONE',\n",
    "            'text-2': tokens[i-2].text if i-2 >= 0 else 'NONE',\n",
    "            'lemma-2': tokens[i-2].lemma_ if i-2 >= 0 else 'NONE',\n",
    "            'pos-2': tokens[i-2].pos_ if i-2 >= 0 else 'NONE',\n",
    "            'text+1': tokens[i+1].text if i+1 < N else 'NONE',\n",
    "            'lemma+1': tokens[i+1].lemma_ if i+1 < N else 'NONE',\n",
    "            'pos+1': tokens[i+1].pos_ if i+1 < N else 'NONE',\n",
    "            'text+2': tokens[i+2].text if i+2 < N else 'NONE',\n",
    "            'lemma+2': tokens[i+2].lemma_ if i+2 < N else 'NONE',\n",
    "            'pos+2': tokens[i+2].pos_ if i+2 < N else 'NONE'\n",
    "        }\n",
    "        all_features.append(features)\n",
    "    return all_features\n",
    "\n",
    "def extract_all(sentences, nlp):\n",
    "    all_features = []\n",
    "    ys = []\n",
    "    for sent in sentences:\n",
    "        tokens = spacy.tokens.Doc(nlp.vocab, words=[pair[0] for pair in sent])\n",
    "        nlp.tagger(tokens)\n",
    "        nlp.parser(tokens)\n",
    "        sent_features = extract(tokens)\n",
    "        ys += [pair[1] for pair in sent]\n",
    "        all_features += sent_features\n",
    "    return (all_features, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    tokens = spacy.tokens.Doc(nlp.vocab, words=[pair[0] for pair in sent])\n",
    "    nlp.tagger(tokens)\n",
    "    nlp.parser(tokens)\n",
    "    return extract(tokens)\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return ['E' if pair[1] == 1 else 'N' for pair in sent]\n",
    "\n",
    "def crf_extract(sents):\n",
    "    return [sent2features(sent) for sent in tqdm(sents)]\n",
    "\n",
    "def crf_labels(sents):\n",
    "    return [sent2labels(sent) for sent in tqdm(sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(x):\n",
    "    return [t.lemma_ for t in nlp(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = joblib.load('crf_splitter.pkl')\n",
    "filter_classifier = joblib.load('filter_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 0 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'phrase': 'Find all attendees ', 'type': 'phrase'},\n",
       " {'phrase': 'whose post contains dog ', 'type': 'phrase'},\n",
       " {'conj': 'but', 'type': 'conj'},\n",
       " {'phrase': 'not ', 'type': 'phrase'},\n",
       " {'phrase': 'who liked a positive post', 'type': 'phrase'}]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONJUNCTIONS = {'and', 'or', 'but', 'except'}\n",
    "\n",
    "def split(sent, verbose=False):\n",
    "    tokens = nlp(sent)\n",
    "    features = extract(tokens)\n",
    "    stops = splitter.predict(features)\n",
    "    nullify = []\n",
    "    for i in range(len(stops)-1):\n",
    "        if stops[i] == 1 and stops[i+1] == 1:\n",
    "            nullify.append(i+1)\n",
    "    for idx in nullify:\n",
    "        stops[idx] = 0\n",
    "    if verbose:\n",
    "        print(stops)\n",
    "    parts = []\n",
    "    part = (0,0)\n",
    "    conj = (0,0)\n",
    "    prev = 0\n",
    "    for token,stop in zip(tokens, stops):\n",
    "        if stop == 0:\n",
    "            part = (part[0], part[1]+len(token.text)+1)\n",
    "        else:\n",
    "            parts.append({'type': 'phrase',\n",
    "                          'phrase': sent[part[0]:part[1]]})\n",
    "            if token.text in CONJUNCTIONS:\n",
    "                parts.append({'type': 'conj',\n",
    "                              'conj': token.text})\n",
    "                part = (part[1]+len(token.text)+1, part[1]+len(token.text)+1)\n",
    "\n",
    "            else:\n",
    "                part = (part[1], part[1]+len(token.text)+1)\n",
    "    parts.append({'type': 'phrase', \n",
    "                          'phrase': sent[part[0]:].strip()})\n",
    "    return parts\n",
    "\n",
    "split(\"Find all attendees whose post contains dog but not who liked a positive post\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'phrase': 'Find all attendees ', 'type': 'phrase'},\n",
       " {'phrase': 'whose post contains dog ', 'type': 'phrase'},\n",
       " {'conj': 'but', 'type': 'conj'},\n",
       " {'phrase': 'not who liked a positive post ', 'type': 'phrase'},\n",
       " {'conj': 'except', 'type': 'conj'},\n",
       " {'phrase': 'thoose who liked you', 'type': 'phrase'}]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONJUNCTIONS = {'and', 'or', 'but', 'except'}\n",
    "\n",
    "def split(sent, verbose=False):\n",
    "    tokens = nlp(sent)\n",
    "    features = extract(tokens)\n",
    "    stops = [1 if stop == 'E' else 0 for stop in splitter.predict([features])[0]]\n",
    "#     nullify = []\n",
    "#     for i in range(len(stops)-1):\n",
    "#         if stops[i] == 1 and stops[i+1] == 1:\n",
    "#             nullify.append(i+1)\n",
    "#     for idx in nullify:\n",
    "#         stops[idx] = 0\n",
    "    if verbose:\n",
    "        print(stops)\n",
    "    parts = []\n",
    "    part = (0,0)\n",
    "    conj = (0,0)\n",
    "    prev = 0\n",
    "    for token,stop in zip(tokens, stops):\n",
    "        if stop == 0:\n",
    "            part = (part[0], part[1]+len(token.text)+1)\n",
    "        else:\n",
    "            parts.append({'type': 'phrase',\n",
    "                          'phrase': sent[part[0]:part[1]]})\n",
    "            if token.text in CONJUNCTIONS:\n",
    "                parts.append({'type': 'conj',\n",
    "                              'conj': token.text})\n",
    "                part = (part[1]+len(token.text)+1, part[1]+len(token.text)+1)\n",
    "\n",
    "            else:\n",
    "                part = (part[1], part[1]+len(token.text)+1)\n",
    "    parts.append({'type': 'phrase', \n",
    "                          'phrase': sent[part[0]:].strip()})\n",
    "    return parts\n",
    "\n",
    "split(\"Find all attendees whose post contains dog but not who liked a positive post except thoose who liked you\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(part):\n",
    "    part['class'] = filter_classifier.predict([part['phrase']])[0]\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_args(part, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Extracting args: {}\".format(part))\n",
    "    if part['class'] != 'post':\n",
    "        part['args'] = []\n",
    "    else:\n",
    "        phrase = part['phrase']\n",
    "        text = replace_quotes_to_double_quotes(phrase)\n",
    "        df = pd.DataFrame({'final': [text.strip()]})\n",
    "        replace_search_strings(df)\n",
    "        df['final'] = df['final'].apply(nlp)\n",
    "        part['args'] = run_rules(df['final'], df['grepl'])\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_in_tree_(parts, tree):\n",
    "    if parts: \n",
    "        part = parts[0]\n",
    "        rest = parts[1:]\n",
    "        (l,n,r) = tree\n",
    "        if part['type'] == 'phrase':\n",
    "            if not l:\n",
    "                return organize_in_tree_(rest, (part, n, r))\n",
    "            elif not r:\n",
    "                return organize_in_tree_(rest, (l,n,part))\n",
    "            else:\n",
    "                raise Exception(\"node in invalid position\")\n",
    "        else:\n",
    "            if not n:\n",
    "                return organize_in_tree_(rest, (l, part, r))\n",
    "            else:\n",
    "                return organize_in_tree_(rest, (tree, part, None))\n",
    "    else:\n",
    "        return tree\n",
    "        \n",
    "def organize_in_tree(parts):\n",
    "    return organize_in_tree_(parts[:], (None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'phrase', 'phrase': 'whose post contains dog ', 'class': 'post', 'args': [{'post.text': 'dog'}]}, {'type': 'conj', 'conj': 'but'}, {'type': 'phrase', 'phrase': 'not who liked a positive post', 'class': 'like', 'args': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'args': [{'post.text': 'dog'}],\n",
       "  'class': 'post',\n",
       "  'phrase': 'whose post contains dog ',\n",
       "  'type': 'phrase'},\n",
       " {'conj': 'but', 'type': 'conj'},\n",
       " {'args': [],\n",
       "  'class': 'like',\n",
       "  'phrase': 'not who liked a positive post',\n",
       "  'type': 'phrase'})"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(s, verbose=False):\n",
    "    parts = split(s, verbose)\n",
    "    if verbose:\n",
    "        print(parts)\n",
    "    parts = parts[1:]\n",
    "    parts = parts[1:] if parts[0]['type'] == 'conj' else parts\n",
    "    parsed = [extract_args(classify(part), verbose) if part['type'] != 'conj' else part\n",
    "              for part in parts]\n",
    "    print(parsed)\n",
    "    return organize_in_tree(parsed)\n",
    "transform(\"Find all attendees whose post contains dog but not who liked a positive post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'phrase', 'phrase': 'who wrote about honey ', 'class': 'post', 'args': [{'post.text': 'honey'}]}, {'type': 'conj', 'conj': 'and'}, {'type': 'phrase', 'phrase': 'liked a post ', 'class': 'like', 'args': []}, {'type': 'conj', 'conj': 'but'}, {'type': 'phrase', 'phrase': 'not who wrote 2 positive posts', 'class': 'post', 'args': [{'post.count': '2', 'post.sentiment': 'positive'}]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(({'args': [{'post.text': 'honey'}],\n",
       "   'class': 'post',\n",
       "   'phrase': 'who wrote about honey ',\n",
       "   'type': 'phrase'},\n",
       "  {'conj': 'and', 'type': 'conj'},\n",
       "  {'args': [], 'class': 'like', 'phrase': 'liked a post ', 'type': 'phrase'}),\n",
       " {'conj': 'but', 'type': 'conj'},\n",
       " {'args': [{'post.count': '2', 'post.sentiment': 'positive'}],\n",
       "  'class': 'post',\n",
       "  'phrase': 'not who wrote 2 positive posts',\n",
       "  'type': 'phrase'})"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\"find attendees who wrote about honey and liked a post but not who wrote 2 positive posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'phrase', 'phrase': 'who wrote posts mentioning Stacy Vaughn ', 'class': 'post', 'args': [{'post.mention': 'Stacy Vaughn'}]}, {'type': 'conj', 'conj': 'and'}, {'type': 'phrase', 'phrase': 'liked any post 9 times ', 'class': 'like', 'args': []}, {'type': 'conj', 'conj': 'and'}, {'type': 'phrase', 'phrase': \"clicked on ad with 'blackout' in it\", 'class': 'ad', 'args': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(({'args': [{'post.mention': 'Stacy Vaughn'}],\n",
       "   'class': 'post',\n",
       "   'phrase': 'who wrote posts mentioning Stacy Vaughn ',\n",
       "   'type': 'phrase'},\n",
       "  {'conj': 'and', 'type': 'conj'},\n",
       "  {'args': [],\n",
       "   'class': 'like',\n",
       "   'phrase': 'liked any post 9 times ',\n",
       "   'type': 'phrase'}),\n",
       " {'conj': 'and', 'type': 'conj'},\n",
       " {'args': [],\n",
       "  'class': 'ad',\n",
       "  'phrase': \"clicked on ad with 'blackout' in it\",\n",
       "  'type': 'phrase'})"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\"Find people who wrote posts mentioning Stacy Vaughn and liked any post 9 times and clicked on ad with 'blackout' in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'phrase', 'phrase': 'who wrote at least 4 posts ', 'class': 'post', 'args': [{'post.count': '>=4'}]}, {'type': 'conj', 'conj': 'or'}, {'type': 'phrase', 'phrase': 'any positive post ', 'class': 'post', 'args': [{'post.sentiment': 'positive'}]}, {'type': 'conj', 'conj': 'and'}, {'type': 'phrase', 'phrase': \"has 'captive' in their bio\", 'class': 'profile', 'args': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(({'args': [{'post.count': '>=4'}],\n",
       "   'class': 'post',\n",
       "   'phrase': 'who wrote at least 4 posts ',\n",
       "   'type': 'phrase'},\n",
       "  {'conj': 'or', 'type': 'conj'},\n",
       "  {'args': [{'post.sentiment': 'positive'}],\n",
       "   'class': 'post',\n",
       "   'phrase': 'any positive post ',\n",
       "   'type': 'phrase'}),\n",
       " {'conj': 'and', 'type': 'conj'},\n",
       " {'args': [],\n",
       "  'class': 'profile',\n",
       "  'phrase': \"has 'captive' in their bio\",\n",
       "  'type': 'phrase'})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(\"Find eveyrone who wrote at least 4 posts or any positive post and has 'captive' in their bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
