{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = open('Kobzar_1371021036.txt').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 105414\n"
     ]
    }
   ],
   "source": [
    "tokens = [tok for tok in word_tokenize(sh) if not tok in '«[]();:».”?“']\n",
    "print(\"Number of tokens:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens, n):\n",
    "    return Counter([tuple(tokens[i:i+n]) for i in range(len(tokens) - (n - 1))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = ngrams(tokens, 1)\n",
    "g2 = ngrams(tokens, 2)\n",
    "g3 = ngrams(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',',), 14248),\n",
       " (('і',), 2811),\n",
       " (('!',), 2662),\n",
       " (('не',), 2376),\n",
       " (('а',), 1722),\n",
       " (('в',), 1675),\n",
       " (('на',), 1534),\n",
       " (('та',), 1381),\n",
       " (('?',), 1034),\n",
       " (('з',), 975)]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'і'), 835),\n",
       " ((',', 'а'), 713),\n",
       " ((',', 'як'), 478),\n",
       " ((',', 'що'), 468),\n",
       " ((',', 'та'), 456),\n",
       " ((',', 'не'), 404),\n",
       " (('та', 'й'), 330),\n",
       " ((',', '—'), 303),\n",
       " (('!', '..'), 253),\n",
       " ((',', 'в'), 223)]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(ngram, n_minus_1_ngram):\n",
    "    probs = {}\n",
    "    grams = dict(ngram)\n",
    "    for k1, v1 in grams.items():\n",
    "        tot = n_minus_1_ngram[tuple(k1[:-1])]\n",
    "        probs[k1] = v1 / (tot if tot != 0 else len(ngram))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = dict(g1)\n",
    "p2 = calc_prob(g2, g1)\n",
    "p3 = calc_prob(g3, g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'як його одній святії прожити літа молодії , сило молодая ! послужи , моя порадо i не видно слава богу ! і'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ['як', 'його']\n",
    "N = 20\n",
    "\n",
    "def generate(N, n, gen, ngrams):\n",
    "    for i in range(N):\n",
    "        probs = []\n",
    "        tokens = []\n",
    "        for k,prob in ngrams.items():\n",
    "            if k[:n-1] == tuple(gen[-(n-1):]):\n",
    "                probs.append(prob)\n",
    "                tokens.append(k[-1])\n",
    "        gen.append(np.random.choice(tokens, p=probs, size=(1,))[0])\n",
    "    return \" \".join(gen)\n",
    "\n",
    "generate(N, 3, gen, p3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rhyme_grams(text):\n",
    "    rows = [[tok for tok in word_tokenize(row) if not tok in string.punctuation] for row in text.split('\\n')]\n",
    "    bigrams = []\n",
    "    unigrams = []\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i]:\n",
    "            unigrams.append(rows[i][-1])\n",
    "        if i >= 2 and rows[i-2] and rows[i]:\n",
    "            bigrams.append((rows[i-2][-1], rows[i][-1]))\n",
    "    return Counter(bigrams), Counter(unigrams)\n",
    "\n",
    "r2, r1 = rhyme_grams(sh)\n",
    "pr2 = calc_prob(r2, r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('хіба', 'ні'), 4.7397857616835716e-05)]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k,v in pr2.items() if k[0] == 'хіба']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "о\n",
      ",\n",
      "куди піти я гне посумує сидячи соловейко \n",
      " чого немає пісок се сподіється чи , \n",
      " мені дає мій на отой проклятий що \n",
      " він хоче україну , де його , \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen = ['як',]\n",
    "N = 50\n",
    "\n",
    "def generate_poem(N, n, gen, ngrams, size, rows_starts):\n",
    "    (rows, cols) = size\n",
    "    poem = []\n",
    "    for i in range(rows):\n",
    "        row = rows_starts[i]\n",
    "        for j in range(cols):\n",
    "            if j == 0 :\n",
    "               row.append(sample_from_unigram())\n",
    "            elif j == 1:\n",
    "                row.append(sample_from_bigram(row[0]))\n",
    "            elif j == (cols-1) and  i >= 2:\n",
    "                probs = []\n",
    "#                 tokens = []\n",
    "#                 for k,prob in pr2.items():\n",
    "#                     if k[0] == poem[i-2][-2]:\n",
    "#                         probs.append(prob)\n",
    "#                         tokens.append(k[-1])\n",
    "                        \n",
    "                if not probs:\n",
    "                    probs = []\n",
    "                    tokens = []\n",
    "                    for k,prob in ngrams.items():\n",
    "                        #print(poem[i-2][-2][-len(k[-1][-1:]):], k[-1][-1:])\n",
    "                        if k[:2-1] == tuple(row[-(2-1):]) and (k[-1][-1:] == poem[i-2][-2][-len(k[-1][-1:]):]):\n",
    "                            probs.append(prob)\n",
    "                            tokens.append(k[-1])\n",
    "                    #print(poem)\n",
    "                    print(poem[i-2][-2][-len(k[-1][-1:]):])\n",
    "                    if not probs:\n",
    "                        probs = []\n",
    "                        tokens = []\n",
    "                        for k,prob in g1.items():\n",
    "                            if k[-1][-1:] == poem[i-2][-2][-len(k[-1][-1:]):]:\n",
    "                                probs.append(prob)\n",
    "                                tokens.append(k[-1])\n",
    "                        row.append(np.random.choice(tokens, p=normalize(probs), size=(1,))[0])\n",
    "                    else:\n",
    "                        row.append(np.random.choice(tokens, p=normalize(probs), size=(1,))[0])\n",
    "                else:\n",
    "                    se = np.random.choice(tokens, p=normalize(probs), size=(1,))[0]\n",
    "                    print(poem[i-2][-2], se)\n",
    "                    row.append(se)\n",
    "            else:\n",
    "                probs = []\n",
    "                tokens = []\n",
    "                for k,prob in ngrams.items():\n",
    "                    if k[:n-1] == tuple(row[-(n-1):]):\n",
    "                        probs.append(prob)\n",
    "                        tokens.append(k[-1])\n",
    "                        \n",
    "                if not probs:\n",
    "                    probs = []\n",
    "                    tokens = []\n",
    "                    for k,prob in ngrams.items():\n",
    "                        if k[:1] == tuple(row[-(2-1):]):\n",
    "                            probs.append(prob)\n",
    "                            tokens.append(k[-1])\n",
    "\n",
    "                    row.append(np.random.choice(tokens, p=normalize(probs), size=(1,))[0])\n",
    "                else:\n",
    "                    row.append(np.random.choice(tokens, p=normalize(probs), size=(1,))[0])\n",
    "        row.append('\\n')\n",
    "        poem.append(row)\n",
    "    return poem\n",
    "\n",
    "print(\" \".join([\" \".join(row) for row in generate_poem(N, 3, gen, p3, (4,5), [['куди', 'піти'], ['чого','немає'], ['мені','дає'], ['він','хоче']])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(xs):\n",
    "    s = sum(xs)\n",
    "    return [x/s for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'світі'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_from_unigram():\n",
    "    probs = []\n",
    "    tokens = []\n",
    "    for k,v in list(g1.items())[100:]:\n",
    "        probs.append(v)\n",
    "        tokens.append(k[0])\n",
    "    return np.random.choice(tokens, p=normalize(probs), size=(1,))[0]\n",
    "        \n",
    "sample_from_unigram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_from_bigram(prev):\n",
    "    probs = []\n",
    "    tokens = []\n",
    "    for k,v in list(g2.items())[100:]:\n",
    "        if k[0] == prev:\n",
    "            probs.append(v)\n",
    "            tokens.append(k[-1])\n",
    "    return np.random.choice(tokens, p=normalize(probs), size=(1,))[0]\n",
    "\n",
    "sample_from_bigram('я')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
