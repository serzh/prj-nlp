{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "# Read dataset\n",
    "review_data = []\n",
    "\n",
    "f = codecs.open('reviews_rozetka.txt', \"r\", \"utf-8\")\n",
    "text = f.read()\n",
    "lines = text.splitlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = line.split(\"/////\")\n",
    "    if (len(item) != 2):\n",
    "        print 'wrong item: ', item\n",
    "        continue\n",
    "    item[0] = item[0].encode('utf-8')\n",
    "    review_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 4832\n",
      "test set size: 1074\n"
     ]
    }
   ],
   "source": [
    "# Split data to train and test set\n",
    "\n",
    "train_set = sorted(review_data, key=lambda tup: tup[1])\n",
    "test_set = []\n",
    "for i, item in enumerate(train_set):\n",
    "    if (i % 9 == 0) or (i % 8 == 0):\n",
    "        test_set.append(item)\n",
    "        train_set.remove(item)\n",
    "\n",
    "print 'train set size:', str(len(train_set))\n",
    "print 'test set size:', str(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  1 :  157\n",
      "test  1 :  35\n",
      "train  2 :  180\n",
      "test  2 :  41\n",
      "train  3 :  277\n",
      "test  3 :  61\n",
      "train  4 :  909\n",
      "test  4 :  202\n",
      "train  5 :  3309\n",
      "test  5 :  735\n",
      "{1: 0.032491721854304635, 2: 0.037251655629139076, 3: 0.05732615894039735, 4: 0.18812086092715233, 5: 0.6848096026490066}\n"
     ]
    }
   ],
   "source": [
    "# Check star frequencies\n",
    "\n",
    "star_probability = {}\n",
    "for star in range(1, 6):\n",
    "    train_for_star = len(list(x for x in train_set if x[1] == str(star)))\n",
    "    print 'train ', str(star), ': ', str(train_for_star)\n",
    "    test_for_star = len(list(x for x in test_set if x[1] == str(star)))\n",
    "    print 'test ', str(star), ': ', str(test_for_star)\n",
    "\n",
    "    star_probability[star] = train_for_star / float(len(train_set))\n",
    "\n",
    "print star_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"polyglot.detect.base\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full vocabulary size: 15987\n"
     ]
    }
   ],
   "source": [
    "# form vocabulary\n",
    "\n",
    "import polyglot\n",
    "from polyglot.text import Text, Word\n",
    "import numpy as np\n",
    "\n",
    "vocabulary = {}\n",
    "for item in train_set:\n",
    "    text = Text(item[0])\n",
    "    for word in text.words:\n",
    "        word_text = word.lower()\n",
    "        if not vocabulary.has_key(word_text):\n",
    "            vocabulary[word_text] = 0\n",
    "        vocabulary[word_text] += 1\n",
    "\n",
    "print 'full vocabulary size:', len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final vocabulary size: 15439\n"
     ]
    }
   ],
   "source": [
    "# improvements:\n",
    "full_vocabulary = dict(vocabulary)\n",
    "stop_keyword = u'розет'\n",
    "for it, k in full_vocabulary.iteritems():\n",
    "    if it.isdigit():\n",
    "        del vocabulary[it]\n",
    "    elif (it.find('.') >= 0) or (it.find(',') >= 0) or (it.find('!') >= 0) or (it.find(':') >= 0):\n",
    "        if len(it) > 1:\n",
    "            del vocabulary[it]\n",
    "    elif it[0:5] == stop_keyword:\n",
    "        del vocabulary[it]\n",
    "        \n",
    "print 'final vocabulary size:', len(vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tone dictionary\n",
    "tone_dictionary = {}\n",
    "\n",
    "f = codecs.open('tone-dict-uk.tsv', \"r\", \"utf-8\")\n",
    "text = f.read()\n",
    "lines = text.splitlines()\n",
    "for line in lines:\n",
    "    item = line.split(\"\\t\")\n",
    "    if (len(item) != 2):\n",
    "        print 'wrong item: ', item\n",
    "        continue\n",
    "    item[0] = item[0].encode('utf-8')\n",
    "    tone_dictionary[item[0]] = item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tones for words in our vocabulary\n",
    "# use stemming to find words from reviews in tones dictionary\n",
    "# if more than one dictionary item fits a stem, use average tone\n",
    "word_tones = {}\n",
    "vocab_words = vocabulary.keys()\n",
    "for word in vocab_words:\n",
    "    stem = ''\n",
    "    if len(word) > 6:\n",
    "        stem = word[0:len(word) - 2]\n",
    "    else:\n",
    "        stem = word[0:len(word) - 1]\n",
    "        \n",
    "    if len(stem) <= 1:\n",
    "        continue\n",
    "    tone_items = list(int(t) for word, t in tone_dictionary.iteritems() if word == stem.encode('utf-8'))  \n",
    "    if len(tone_items) <= 0:\n",
    "        tone_items = list(int(t) for word, t in tone_dictionary.iteritems() \\\n",
    "                          if (word[0:2*len(stem)] == stem.encode('utf-8')) \\\n",
    "                          and (len(stem.encode('utf-8')) / float(len(word)) > 0.8))\n",
    "    if len(tone_items) > 0:\n",
    "        av_tone = sum(tone_items) / float(len(tone_items))\n",
    "        word_tones[word] = av_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0 2.0\n",
      "0.2 1.0\n"
     ]
    }
   ],
   "source": [
    "# scale tones to be in range(0, 1]\n",
    "\n",
    "min_tone = min(word_tones.values())\n",
    "max_tone = max(word_tones.values())\n",
    "print min_tone, max_tone\n",
    "\n",
    "for key in word_tones:\n",
    "    word_tones[key] = (word_tones[key] - min_tone + 1) / float(max_tone - min_tone + 1)\n",
    "\n",
    "min_tone = min(word_tones.values())\n",
    "max_tone = max(word_tones.values())\n",
    "print min_tone, max_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "чудовому 1.0\n",
      "використати 0.8\n",
      "чистими 0.8\n",
      "поганий 0.4\n",
      "дірками 0.4\n",
      "поганим 0.4\n",
      "морочитися 0.2\n",
      "рекомендації 0.8\n",
      "хорошийта 0.8\n",
      "позитивного 0.8\n",
      "міцними 0.8\n",
      "захвата 1.0\n",
      "адекватною 0.8\n",
      "незручнихз 0.4\n",
      "захвату 1.0\n",
      "професійних 0.8\n",
      "дивний 0.4\n",
      "захваті 1.0\n",
      "вигідний 0.8\n",
      "чарівними 1.0\n"
     ]
    }
   ],
   "source": [
    "print len(word_tones)\n",
    "\n",
    "for word in word_tones.keys()[0:20]:\n",
    "    print word, word_tones[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to vectors \n",
    "# 0 - word is not in text, 0.2 - 1 word tone  (0.6 is neutral and means that word is in text)\n",
    "# form train and test vector sets\n",
    "vocab_words = vocabulary.keys()\n",
    "vocab_word_tones = word_tones.keys()\n",
    "\n",
    "train_vectors_tone = []\n",
    "train_classes = []\n",
    "for item in train_set:\n",
    "    text = Text(item[0])\n",
    "    vector_x = np.zeros(len(vocab_words))\n",
    "    for word in text.words:\n",
    "        word_text = word.lower()\n",
    "        if word_text in vocab_word_tones:\n",
    "            vector_x[vocab_words.index(word_text)] = word_tones[word_text]\n",
    "        elif word_text in vocab_words:\n",
    "            vector_x[vocab_words.index(word_text)] = 0.6 #3/5\n",
    "    train_vectors_tone.append(vector_x)\n",
    "    train_classes.append(int(item[1]))\n",
    "\n",
    "\n",
    "test_vectors_tone = []\n",
    "test_classes = []\n",
    "for item in test_set:\n",
    "    text = Text(item[0])\n",
    "    vector_x = np.zeros(len(vocab_words))\n",
    "    for word in text.words:\n",
    "        word_text = word.lower()\n",
    "        if word_text in vocab_word_tones:\n",
    "            vector_x[vocab_words.index(word_text)] = word_tones[word_text]\n",
    "        elif word_text in vocab_words:\n",
    "            vector_x[vocab_words.index(word_text)] = 0.6 #3/5\n",
    "    test_vectors_tone.append(vector_x)\n",
    "    test_classes.append(int(item[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit SVM model, train one-vs-rest classifiers for multi-class classification\n",
    "# use balanced class weights to handle significant bias (68% of data are 5*)\n",
    "from sklearn import svm\n",
    "lin_clf_tone = svm.LinearSVC(class_weight='balanced')\n",
    "lin_clf_tone.fit(train_vectors_tone, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  825 / 1074\n",
      "errors (correct -> classified : count)\n",
      "1 -> 4 : 5\n",
      "1 -> 5 : 10\n",
      "1 -> 2 : 5\n",
      "1 -> 3 : 3\n",
      "4 -> 3 : 5\n",
      "4 -> 2 : 3\n",
      "4 -> 1 : 1\n",
      "5 -> 3 : 13\n",
      "5 -> 4 : 61\n",
      "4 -> 5 : 80\n",
      "3 -> 2 : 4\n",
      "3 -> 4 : 7\n",
      "5 -> 1 : 5\n",
      "2 -> 5 : 8\n",
      "2 -> 4 : 4\n",
      "3 -> 1 : 3\n",
      "2 -> 1 : 3\n",
      "5 -> 2 : 5\n",
      "2 -> 3 : 6\n",
      "3 -> 5 : 18\n"
     ]
    }
   ],
   "source": [
    "# run classifier on test set\n",
    "\n",
    "prediced_classes_tone = lin_clf_tone.predict(test_vectors_tone)\n",
    "common = 0\n",
    "errors_freqencies = {}\n",
    "errors = {}\n",
    "for i, clas in enumerate(test_classes):\n",
    "    if (clas == prediced_classes_tone[i]):\n",
    "        common += 1\n",
    "    else:\n",
    "\n",
    "        key = str(clas) + ' -> ' + str(prediced_classes_tone[i])\n",
    "        \n",
    "        if not errors_freqencies.has_key(key):\n",
    "            errors_freqencies[key] = 0\n",
    "        errors_freqencies[key] += 1\n",
    "        \n",
    "        if not errors.has_key(key):\n",
    "            errors[key] = []\n",
    "        errors[key].append(test_set[i])\n",
    "        \n",
    "print 'correct: ', str(common), '/', str(len(test_set))\n",
    "print 'errors (correct -> classified : count)'\n",
    "for key, freq in errors_freqencies.iteritems():\n",
    "    print key, ':', freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to display wrong classification examples\n",
    "for key, e in errors.iteritems():\n",
    "    print key\n",
    "    for er in e:\n",
    "        print er[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
