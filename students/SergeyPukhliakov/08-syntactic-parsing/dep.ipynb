{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../../../../NLP/dep/UD_Ukrainian-IU-master/uk_iu-ud-train.conllu\"\n",
    "test_file = \"../../../../NLP/dep/UD_Ukrainian-IU-master/uk_iu-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file, encoding='utf-8') as f:\n",
    "    train = f.read()\n",
    "\n",
    "with open(test_file,  encoding='utf-8') as f:\n",
    "    test = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "from collections import deque\n",
    "import collections\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trees_original = parse(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trees_original = parse(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_from_tree(t):\n",
    "    return [(x['id'],x['head']) for x in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue, rel):\n",
    "    features = {}\n",
    "    if (len(stack) > 0):\n",
    "        features[\"s_0_form\"] = stack[-1][\"form\"]\n",
    "        features[\"s_0_lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"s_0_postag\"] = stack[-1][\"upostag\"]\n",
    "        \n",
    "    \n",
    "    if len(stack) > 1:\n",
    "        features[\"s_1_postag\"] = stack[-2][\"upostag\"]\n",
    "    \n",
    "    if (len(queue) > 0):\n",
    "        features[\"q_0_form\"] = queue[0][\"form\"]\n",
    "        features[\"q_0_lemma\"] = queue[0][\"lemma\"]\n",
    "        features[\"q_0_postag\"] = queue[0][\"upostag\"]\n",
    "    \n",
    "    if (len(queue) > 1):\n",
    "        features[\"q_1_form\"] = queue[1][\"form\"]\n",
    "        features[\"q_1_postag\"] = queue[1][\"upostag\"]\n",
    "    \n",
    "    if (len(queue) > 2):\n",
    "        features[\"q_1_postag\"] = queue[2][\"upostag\"]\n",
    "    \n",
    "    if (len(queue) > 3):\n",
    "        features[\"q_1_postag\"] = queue[3][\"upostag\"]\n",
    "    return features\n",
    "\n",
    "def static_oracle(tree):\n",
    "    stack = [collections.OrderedDict({'id':0, 'head':0, \"form\": \"ROOT\", \"lemma\":\"\", \"upostag\":\"\"})]\n",
    "    queue = deque(list(tree))\n",
    "    actions = []\n",
    "    features = []\n",
    "    rel = []\n",
    "    while(len(queue) > 0):\n",
    "        head_s = stack[-1]\n",
    "        head_q = queue[0]        \n",
    "        features.append(extract_features(stack, queue, rel))\n",
    "        if head_s[\"head\"] == head_q['id']:\n",
    "            actions.append(\"LEFT\")\n",
    "            rel.append((head_s['id'], head_q['id']))\n",
    "            stack.pop()\n",
    "        elif head_q[\"head\"] == head_s[\"id\"]:           \n",
    "            actions.append(\"RIGHT\")\n",
    "            rel.append((head_q['id'], head_s['id']))\n",
    "            stack.append(head_q)\n",
    "            queue.popleft()            \n",
    "        elif head_s[\"id\"] in [x for (x,y) in rel] and head_s[\"id\"] not in [x['head'] for x in queue]:\n",
    "            actions.append(\"REDUCE\")\n",
    "            stack.pop()\n",
    "        else:          \n",
    "            actions.append(\"SHIFT\")\n",
    "            stack.append(head_q)\n",
    "            queue.popleft()\n",
    "    while(len(stack) > 0):\n",
    "        features.append(extract_features(stack,queue,rel))        \n",
    "        actions.append(\"REDUCE\")\n",
    "        stack.pop()    \n",
    "    return actions,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cross(tree):\n",
    "    ranges = [(min(x['id'], x['head']), max(x['id'], x['head'])) for x in tree]\n",
    "    for x in tree:\n",
    "        childI = x['id']\n",
    "        headI = x['head']    \n",
    "        for r1,r2 in ranges:        \n",
    "            if (r1 < childI < r2):\n",
    "                if headI < r1 or headI > r2:\n",
    "                    return True\n",
    "            if (r1 < headI < r2):\n",
    "                if childI < r1 or childI > r2:\n",
    "                    return True\n",
    "    return False\n",
    "train_trees = [t for t in train_trees_original if not check_cross(t)]\n",
    "test_trees = [t for t in test_trees_original if not check_cross(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acts_with_features(trees):\n",
    "    actions = []\n",
    "    features = []\n",
    "    for t in trees:\n",
    "        a,f = static_oracle(t)\n",
    "        actions += a\n",
    "        features += f\n",
    "    return actions,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,X_train_features = get_acts_with_features(train_trees)\n",
    "# y_test,X_test_features = get_acts_with_features(test_trees)\n",
    "X_train = vec.fit_transform(X_train_features)\n",
    "# X_test = vec.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = logistic.predict(X_train)\n",
    "predicted_test = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.93      0.96      0.95     34862\n",
      "     REDUCE       0.95      0.92      0.93     36150\n",
      "      RIGHT       0.93      0.92      0.92     31945\n",
      "      SHIFT       0.91      0.92      0.91     34862\n",
      "\n",
      "avg / total       0.93      0.93      0.93    137819\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.87      0.89      0.88      6997\n",
      "     REDUCE       0.84      0.77      0.81      7630\n",
      "      RIGHT       0.80      0.85      0.82      6882\n",
      "      SHIFT       0.77      0.78      0.77      6997\n",
      "\n",
      "avg / total       0.82      0.82      0.82     28506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, predicted_train))\n",
    "print()\n",
    "print(classification_report(y_test, predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(tree, classifier):\n",
    "    stack = [collections.OrderedDict({'id':0, 'head':0, \"form\": \"ROOT\", \"lemma\":\"\", \"upostag\":\"\"})]\n",
    "    queue = deque(list(tree))\n",
    "    rel = []\n",
    "    LEFT = 0\n",
    "    REDUCE = 1\n",
    "    RIGHT = 2\n",
    "    SHIFT = 3\n",
    "    \n",
    "    def get_valid(stack, queue, heads):\n",
    "        forbidden = []\n",
    "        if stack[-1][\"id\"] in heads or stack[-1][\"id\"] == 0:\n",
    "            forbidden.append(LEFT)\n",
    "        if queue[0][\"id\"] in heads:\n",
    "            forbidden.append(RIGHT)\n",
    "        if len(queue) == 1:            \n",
    "            forbidden.append(SHIFT)\n",
    "        if len(queue) == 1 and any([x[\"id\"] != 0 and x[\"id\"] not in heads for x in stack]): \n",
    "            forbidden.append(RIGHT) \n",
    "        if stack[-1][\"id\"] not in heads:\n",
    "            forbidden.append(REDUCE)\n",
    "        return [x for x in [LEFT,REDUCE,RIGHT,SHIFT] if x not in forbidden]\n",
    "    \n",
    "    def get_action(stack, queue, rel, valid):        \n",
    "        predict_prob = list(classifier.predict_proba(vec.transform(extract_features(stack,queue,rel)))[0])\n",
    "        ind =  predict_prob.index(max([x for  i, x in enumerate(predict_prob) if i in valid]))\n",
    "        true_ind = predict_prob.index(max([x for  i, x in enumerate(predict_prob)]))\n",
    "        return [LEFT,REDUCE,RIGHT,SHIFT][ind]\n",
    "    \n",
    "    while(queue):\n",
    "        valid = get_valid(stack,queue,[x for (x,y) in rel])\n",
    "        if valid == [] : break\n",
    "        action = get_action(stack,queue,rel,valid)\n",
    "        head_q = queue[0]\n",
    "        if action == SHIFT:\n",
    "            stack.append(head_q)\n",
    "            queue.popleft()\n",
    "            continue\n",
    "        head_s = stack[-1]\n",
    "        if action == LEFT:            \n",
    "            rel.append((head_s['id'], head_q['id']))\n",
    "            stack.pop()\n",
    "        elif action == RIGHT:\n",
    "            rel.append((head_q['id'], head_s['id']))\n",
    "            stack.append(head_q)\n",
    "            queue.popleft()            \n",
    "        elif action == REDUCE:\n",
    "            stack.pop()\n",
    "    rel.sort()\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parsing(trees, classifier):\n",
    "    predicted = []\n",
    "    true = []\n",
    "    for i,t in enumerate(trees):\n",
    "        p = parse(t, classifier)\n",
    "        t = get_relations_from_tree(t)\n",
    "        if len(p) != len(t):\n",
    "            print(\"FAIL:\",i)\n",
    "            continue\n",
    "        predicted += p\n",
    "        true += t\n",
    "    matched = sum([1 for i in range(len(predicted)) if predicted[i] == true[i]])\n",
    "    print (matched/len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8320086218510037\n"
     ]
    }
   ],
   "source": [
    "test_parsing(train_trees, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6522083723611212\n"
     ]
    }
   ],
   "source": [
    "test_parsing(test_trees, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097952009374417\n"
     ]
    }
   ],
   "source": [
    "test_parsing(train_trees_original, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6533235156302296\n"
     ]
    }
   ],
   "source": [
    "test_parsing(test_trees_original, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09618848620217595\n"
     ]
    }
   ],
   "source": [
    "test_parsing(test_trees, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09451770533502912\n"
     ]
    }
   ],
   "source": [
    "test_parsing(test_trees_original, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08479650336042631\n"
     ]
    }
   ],
   "source": [
    "test_parsing(train_trees, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08337106181256491\n"
     ]
    }
   ],
   "source": [
    "test_parsing(train_trees_original, svc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
