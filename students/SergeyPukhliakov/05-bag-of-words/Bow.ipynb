{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "from random import shuffle\n",
    "with open('./data.json', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "data = [json.loads(line, object_hook=lambda d: namedtuple('X', d.keys())(*d.values())) for line in content]\n",
    "shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = [(int(x.grade),x.text) for x in data]\n",
    "divider = int(round(0.7 * len(extracted_data)))\n",
    "learn_data = extracted_data[:divider]\n",
    "test_data = extracted_data[divider:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grade(grade):\n",
    "    if grade == 3 : return 0\n",
    "    if grade > 3 : return 1\n",
    "    if grade < 3 : return -1\n",
    "\n",
    "def process_data(data):\n",
    "    texts = []\n",
    "    grades = []\n",
    "    for grade,text in data:\n",
    "        texts.append(text)\n",
    "        grades.append(convert_grade(grade))\n",
    "    return texts, grades\n",
    "\n",
    "texts,grades = process_data(learn_data)\n",
    "test_texts,test_grades = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.09      0.07      0.08        27\n",
      "          0       0.07      0.05      0.06        56\n",
      "          1       0.87      0.90      0.89       575\n",
      "\n",
      "avg / total       0.77      0.79      0.78       658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_data = cv.fit_transform(texts).toarray()\n",
    "cNB = GaussianNB().fit(X_data,grades)\n",
    "X_test_data = cv.transform(test_texts).toarray()\n",
    "predicted_n = cNB.predict(X_test_data)\n",
    "print (classification_report(test_grades, predicted_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vocab = pd.read_csv(\"https://raw.githubusercontent.com/lang-uk/tone-dict-uk/master/tone-dict-uk-manual.tsv\",\n",
    "                    header=None, usecols=[0,1], encoding='utf-8', sep='\\t')\n",
    "vocab = set([(x,abs(y)) for x,y in zip(vocab[0].tolist(),vocab[1].tolist()) if y != 0])\n",
    "sent_dict = dict(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_words = count_vect.fit_transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_features(words_count_array, features, sent_dict):\n",
    "    for row in words_count_array:\n",
    "        for ind in range(0,len(features)):\n",
    "            sent_coeff = sent_dict.get(features[ind], None)\n",
    "            if sent_coeff != None:\n",
    "                row[ind] = row[ind] * sent_coeff * 100\n",
    "\n",
    "update_features(X_words, features, sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB().fit(X_words, grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.07      0.07      0.07        27\n",
      "          0       0.08      0.75      0.15        56\n",
      "          1       0.91      0.18      0.31       575\n",
      "\n",
      "avg / total       0.81      0.23      0.28       658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_words = count_vect.transform(test_texts).toarray()\n",
    "update_features(X_test_words, features, sent_dict)\n",
    "predicted_3 = clf.predict(X_test_words)\n",
    "print (classification_report(test_grades, predicted_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.33      0.22      0.27        27\n",
      "          0       0.35      0.11      0.16        56\n",
      "          1       0.90      0.97      0.93       575\n",
      "\n",
      "avg / total       0.83      0.87      0.84       658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linearSVC_pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])\n",
    "linearSVC_pipeline.fit(texts, grades)\n",
    "predicted_linear = linearSVC_pipeline.predict(test_texts)\n",
    "print (classification_report(test_grades, predicted_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.14      0.04      0.06        27\n",
      "          0       0.29      0.04      0.06        56\n",
      "          1       0.88      0.99      0.93       575\n",
      "\n",
      "avg / total       0.80      0.87      0.82       658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linearSVC_alt_pipeline = Pipeline([('vectorizer', CountVectorizer(ngram_range=(1, 3), analyzer='word')), ('classifier', LinearSVC())])\n",
    "linearSVC_alt_pipeline.fit(texts, grades)\n",
    "predicted_alt_linear = linearSVC_alt_pipeline.predict(test_texts)\n",
    "print (classification_report(test_grades, predicted_alt_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_balanced(data):\n",
    "    texts = []\n",
    "    grades = []\n",
    "    for grade,text in data:\n",
    "        converted_g = convert_grade(grade)\n",
    "        texts.append(text)\n",
    "        grades.append(converted_g)\n",
    "        if converted_g < 1:\n",
    "            for i in range(10):\n",
    "                texts.append(text)\n",
    "                grades.append(converted_g)\n",
    "    return texts, grades\n",
    "texts_b, grades_b = process_data_balanced(learn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.28      0.19      0.22        27\n",
      "          0       0.29      0.12      0.18        56\n",
      "          1       0.90      0.97      0.93       575\n",
      "\n",
      "avg / total       0.82      0.86      0.84       658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linearSVC_pipeline.fit(texts_b, grades_b)\n",
    "predicted_linear = linearSVC_pipeline.predict(test_texts)\n",
    "print (classification_report(test_grades, predicted_linear))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
