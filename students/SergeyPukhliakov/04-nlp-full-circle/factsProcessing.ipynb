{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from collections import namedtuple\n",
    "data = json.load(open('./extractedFactsWithYear.json'), object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "articles = data.articles\n",
    "shuffle(articles)\n",
    "divider = int(round(0.5 * len(data.articles)))\n",
    "learn_data = data.articles[:divider]\n",
    "test_data = data.articles[divider:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "entity_with_year_re = re.compile('''([A-Z][a-zA-Z'--(0-9)]*(?:\\s[A-Z-0-9][a-zA-Z'--(0-9)]*)*((:|\\sdel|\\sfor|\\sin|\\sthe|\\sof|\\sat|\\sand|\\sis|\\sor|\\s&|\\.|\\sto)*(?:\\s[A-Z-0-9][a-zA-Z'--(0-9)]*)+)*) \\(([1-3][0-9]{3})\\)''')\n",
    "entity_re = re.compile('''([A-Z][a-zA-Z'--(0-9)]*(?:\\s[A-Z-0-9][a-zA-Z-(0-9)]*)*((:|\\sdel|\\sfor|\\sin|\\sthe|\\sof|\\sat|\\sto|\\sde)*(?:\\s[A-Z-0-9][a-zA-Z'--(0-9)]*)+)*)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(fact_dic, fact):    \n",
    "    if fact['film'] not in fact_dic:\n",
    "        return 0\n",
    "    if fact_dic[fact['film']]['director'] == fact['director']: \n",
    "        if fact_dic[fact['film']]['year'] == fact['year']:\n",
    "            return 1\n",
    "        else:            \n",
    "            return 0.75\n",
    "    return 0.5\n",
    "\n",
    "def check(articles):\n",
    "    facts_amount = 0\n",
    "    final_score = 0\n",
    "    for article in articles:\n",
    "        facts_amount = facts_amount + len(article.facts)\n",
    "        extracted = extract(article)\n",
    "        facts_dic = {f.film:{'director':f.director, 'year':f.year} for f in article.facts}\n",
    "        for f in extracted:\n",
    "            final_score = final_score + score(facts_dic, f)\n",
    "    return final_score/facts_amount * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_from_article_name(article_name):\n",
    "    return next((ent.text for ent in nlp(article_name).ents if ent.label_ == 'PERSON'), '')\n",
    "\n",
    "def parse_director_name(article_name, doc):\n",
    "    director = next((ent.text for ent in doc.ents if ent.label_ == 'PERSON'), '')\n",
    "    director_from_name = director = director_from_article_name(article_name)\n",
    "    if director == '': return director_from_name\n",
    "    if len(director.split(' ')) < 2 : return director_from_name\n",
    "    return director\n",
    "\n",
    "def find_ind(doc, value):\n",
    "    i = 0 \n",
    "    for word in doc:\n",
    "        if word.text == value:\n",
    "            return i\n",
    "        i= i + 1\n",
    "    \n",
    "    \n",
    "def firstRule(article_name,sentence):\n",
    "    results = []\n",
    "    doc = nlp(sentence)\n",
    "    director = parse_director_name(article_name, doc)\n",
    "    for s in entity_with_year_re.finditer(sentence):\n",
    "        fact = {\n",
    "                'director':director,\n",
    "                'film' : s.group()[:-7],\n",
    "                'year' : s.group()[-5:-1]\n",
    "        }\n",
    "        results.append(fact)\n",
    "    return results\n",
    "def film_rule(article):\n",
    "    result = {'film':'', 'year':'', 'director':''}\n",
    "    doc = nlp(article.sentence)\n",
    "    entities = [s.group() for s in entity_re.finditer(article.sentence)]    \n",
    "    for ent in entities:    \n",
    "        ent_doc = nlp(ent)\n",
    "        start = find_ind(doc, ent_doc[0].text)\n",
    "        if start == None: continue\n",
    "        span = doc[start:start + len(ent_doc)]\n",
    "        span.merge()\n",
    "    #for word in doc:\n",
    "    #    print(\"Word:\", word.text, \" Tag:\", word.tag_, \" Head:\", word.head.text, \"Dependency relation:\", word.dep_)\n",
    "    #    print(\"Children:\", list(word.children))\n",
    "    #    print(\"\")\n",
    "    years = [s.group() for s in re.finditer(\"([1-3][0-9]{3})\",article.sentence)]\n",
    "    if len(years) ==1:\n",
    "        result['year'] = years[0]    \n",
    "    for w in doc:        \n",
    "        if w.text == \"film\":\n",
    "            if w.head.text in entities and w.dep_ == 'pobj':\n",
    "                result['film'] = w.head.text\n",
    "                continue\n",
    "            for child in w.children:\n",
    "                if child.text in entities and child.dep_ == 'appos':\n",
    "                    result['film'] = child.text\n",
    "                    break\n",
    "        if result['year'] != '': continue\n",
    "        if w.dep_ == \"ROOT\":\n",
    "            preps = [child for child in w.children if child.dep_ == \"prep\"]\n",
    "            for prep in preps:\n",
    "                match = re.search(\"([1-3][0-9]{3})\", prep.text)\n",
    "                if match:\n",
    "                    result['year'] = match.group()\n",
    "                    break\n",
    "    result['director'] = director_from_article_name(article.name)\n",
    "    return [result]\n",
    "\n",
    "def extract(article):\n",
    "    if re.search(\"\\(([1-3][0-9]{3})\\)\",article.sentence):\n",
    "        return firstRule(article.name, article.sentence)\n",
    "    entities = [s.group() for s in entity_re.finditer(article.sentence)]\n",
    "    years = [s.group() for s in re.finditer(\"([1-3][0-9]{3})\",article.sentence)]\n",
    "    if len(entities) == 1 and len(years) ==1:\n",
    "        return [{\n",
    "                'director':director_from_article_name(article.name),\n",
    "                'film' : entities[0],\n",
    "                'year' : years[0]\n",
    "        }]\n",
    "    if \"film\" in article.sentence:\n",
    "        return film_rule(article)\n",
    "    if \"directed\" in article.sentence:\n",
    "        return []\n",
    "    else :\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.44554455445545"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(learn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.396039603960396"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
