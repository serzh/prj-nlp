{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Покращення парсера залежностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import string\n",
    "import gzip\n",
    "\n",
    "from tokenize_uk import tokenize_words\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсери залежностей використовують різні алгоритми переходів, типи оракулів, ознаки для передбачення тощо. Для цієї домашньої роботи я спробував три підходи (усі з алгоритмом Arc-Eager):\n",
    "\n",
    "- парсер зі статичним оракулом - приблизно той, що ми будували на практичному занятті, з додатковими ознаками);\n",
    "- парсер зі статичним оракулом і промаркованими типами залежностей (labeled parser) - на основі попереднього парсера;\n",
    "- парсер із динамічним оракулом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data\n",
    "fname = 'uk_iu-ud-train.conllu.gz'\n",
    "with gzip.open(fname, 'rb') as f:\n",
    "    raw_train = f.read().decode()\n",
    "\n",
    "fname2 = 'uk_iu-ud-test.conllu.gz'\n",
    "with gzip.open(fname2, 'rb') as f2:\n",
    "    raw_test = f2.read().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсер №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser():\n",
    "    \"\"\"\n",
    "    Here we parse dependency tree with known dependencies,\n",
    "    learn features for classifier, and try to parse trees\n",
    "    with unknown dependencies given features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ROOT = OrderedDict({'form': 'ROOT', 'id': 0, 'head': -1, \n",
    "                                 'lemma': 'ROOT', 'upostag': 'ROOT',\n",
    "                                 'deprel': 'root'})\n",
    "        \n",
    "    def read_raw_conllu(self, raw_text):\n",
    "        \"\"\"\n",
    "        Parse CONLLU text with corresponding library.\n",
    "        Returns list of parsed sentences.\n",
    "        \"\"\"\n",
    "        trees = conllu.parse(raw_text)\n",
    "        return trees\n",
    "\n",
    "    def make_action(self, action, stack, queue, relations):\n",
    "        \"\"\"\n",
    "        Applies action to the stack, the queue, and the relations.\n",
    "        \"\"\"\n",
    "        w1 = stack[-1]\n",
    "        w2 = queue[0]\n",
    "        if action == 'SHIFT':\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == 'REDUCE':\n",
    "            stack.pop()\n",
    "        elif action == 'LEFT':\n",
    "            relations.append((w1['id'], w2['id']))\n",
    "            stack.pop()\n",
    "        elif action == 'RIGHT':\n",
    "            relations.append((w2['id'], w1['id']))\n",
    "            stack.append(queue.pop(0))\n",
    "        return stack, queue, relations\n",
    "\n",
    "    def oracle(self, top_stack, top_queue, relations):\n",
    "        \"\"\"\n",
    "        Returns the right action given the state\n",
    "        of the stack, the queue, and the relations.\n",
    "        \"\"\"\n",
    "        if top_stack and not top_queue:\n",
    "            return 'REDUCE'\n",
    "        elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "            return 'RIGHT'\n",
    "        elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "            return 'LEFT'\n",
    "        elif (top_stack[\"id\"] in [i[0] for i in relations] and \n",
    "             top_queue[\"head\"] < top_stack[\"id\"]):\n",
    "            return 'REDUCE'\n",
    "        else:\n",
    "            return 'SHIFT'\n",
    "\n",
    "    def apply_actions(self, tree, train=False):\n",
    "        \"\"\"\n",
    "        Produce dependencies for the tree with known dependencies.\n",
    "        If train=True, also get features and labels in the process.\n",
    "        \"\"\"\n",
    "        stack = [self.ROOT]\n",
    "        queue = tree[:]\n",
    "        relations = []\n",
    "        labels = []\n",
    "        features = []\n",
    "        while stack and queue:\n",
    "            top_stack = stack[-1] if stack else None\n",
    "            top_queue = queue[0] if queue else None\n",
    "            action = self.oracle(top_stack, top_queue, relations)\n",
    "            if train:\n",
    "                labels.append(action)\n",
    "                features.append(self.get_features(stack, queue, relations, tree))\n",
    "            stack, queue, relations = self.make_action(action, stack, queue, relations)\n",
    "        if train:\n",
    "            return relations, labels, features\n",
    "        return relations\n",
    "    \n",
    "    def get_morph_feats(self, word):\n",
    "        \"\"\"\n",
    "        Get what is in 'feats' dict of the parsed word.\n",
    "        \"\"\"\n",
    "        if (not 'feats' in word\n",
    "            or word['feats'] is None):\n",
    "            return {}\n",
    "        features = dict()\n",
    "        for k in word['feats'].keys():\n",
    "            features[k] = word['feats'][k]\n",
    "        return features\n",
    "    \n",
    "    def get_child_deps(self, wid, relations, tree):\n",
    "        \"\"\"\n",
    "        Get rightmost and leftmost child dependencies.\n",
    "        \"\"\"\n",
    "        children = list(filter(lambda x: x[1] == wid, relations))\n",
    "        if len(children):\n",
    "            nchildren = len([d for (d, h) in children])\n",
    "            lc1 = min(d for (d, h) in children)\n",
    "            rc1 = max(d for (d, h) in children)\n",
    "            return tree[lc1], tree[rc1], nchildren\n",
    "        return None\n",
    "        \n",
    "    def get_features(self, stack, queue, relations, tree):\n",
    "        \"\"\"\n",
    "        Create a dictionary of features for each action.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        if stack:\n",
    "            w = stack[-1]\n",
    "            features.update({\n",
    "                'st0form': w['form'],\n",
    "                'st0lemma': w['lemma'],\n",
    "                'st0pos': w['upostag'],\n",
    "                'st0form_pos': w['form']+'_'+w['upostag']\n",
    "            })\n",
    "            if self.get_child_deps(w['id'], relations, tree):\n",
    "                left_pos, right_pos, nchildren = self.get_child_deps(w['id'], relations, tree)\n",
    "                features.update({\n",
    "                    'st0leftc_pos': left_pos['upostag'],\n",
    "                    'st0rightc_pos': right_pos['upostag'],\n",
    "                    'st0nchildren': nchildren\n",
    "                })\n",
    "            features.update(self.get_morph_feats(w))\n",
    "        if len(stack) > 1:\n",
    "            w = stack[-2]\n",
    "            features.update({\n",
    "                'st1pos': w['upostag'],\n",
    "                'st1form': w['form'],\n",
    "                'st1form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'st0_1pos': stack[-1]['upostag'] + '_' + w['upostag']\n",
    "            })\n",
    "        if queue:\n",
    "            w = queue[0]\n",
    "            features.update({\n",
    "                'q0form': w['form'],\n",
    "                'q0lemma': w['lemma'],\n",
    "                'q0pos': w['upostag'],\n",
    "                'q0form_pos': w['form']+'_'+w['upostag']\n",
    "            })\n",
    "            if self.get_child_deps(w['id'], relations, tree):\n",
    "                left_pos, right_pos, nchildren = self.get_child_deps(w['id'], relations, tree)\n",
    "                features.update({\n",
    "                    'q0leftc_pos': left_pos['upostag'],\n",
    "                    'q0rightc_pos': right_pos['upostag'],\n",
    "                    'q0nchildren': nchildren\n",
    "                })\n",
    "            features.update(self.get_morph_feats(w))\n",
    "        if len(queue) > 1:\n",
    "            w = queue[1]\n",
    "            features.update({\n",
    "                'q1form': w['form'],\n",
    "                'q1lemma': w['lemma'],\n",
    "                'q1pos': w['upostag'],\n",
    "                'q1form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'q0_1pos': queue[0]['upostag'] + '_' + w['upostag']\n",
    "            })\n",
    "        if len(queue) > 2:\n",
    "            w = queue[2]\n",
    "            features.update({\n",
    "                'q2pos': w['upostag'],\n",
    "                'q2form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'q012pos': queue[0]['upostag'] + '_' + queue[1]['upostag'] + w['upostag']\n",
    "            })\n",
    "        if len(queue) > 3:\n",
    "            w = queue[3]\n",
    "            features.update({\n",
    "                'q3pos': w['upostag']\n",
    "            })\n",
    "        if stack and queue:\n",
    "            w1 = stack[-1]\n",
    "            w2 = queue[0]\n",
    "            features.update({\n",
    "                'distance': abs(w1['id'] - w2['id']),\n",
    "                'st0f_q0f': w1['form'] + '_' + w2['form'],\n",
    "                'st0p_q0p': w1['upostag'] + '_' + w2['upostag'],\n",
    "                'st0f_q0p': w1['form'] + '_' + w2['upostag'],\n",
    "                'st0p_q0f': w1['upostag'] + '_' + w2['form']\n",
    "            })\n",
    "        return features\n",
    "\n",
    "    def equal_to_gold(self, gold_tree, parsed_rel):\n",
    "        \"\"\"\n",
    "        Compare lists of relations, return True if they're the same.\n",
    "        \"\"\"\n",
    "        gold_rel = self.get_relations(gold_tree)\n",
    "        parsed_rel = sorted(parsed_rel)\n",
    "        if gold_rel == parsed_rel:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_relations(self, tree):\n",
    "        \"\"\"\n",
    "        Return list of relation nodes (child, parent)\n",
    "        \"\"\"\n",
    "        return [(w['id'], w['head']) for w in tree]\n",
    "       \n",
    "    def _check_parser(self, raw_text):\n",
    "        \"\"\"\n",
    "        Check if our parser creates the right relations,\n",
    "        given golden trees from CONLLU raw_text.\n",
    "        \"\"\"\n",
    "        wrong_count = 0\n",
    "        wrong = []\n",
    "        gold_trees = self.read_raw_conllu(raw_text)\n",
    "        parsed_rels = [self.apply_actions(tree) for tree in gold_trees]\n",
    "        for gold_tree, parsed_rel in zip(gold_trees, parsed_rels):\n",
    "            if self.equal_to_gold(gold_tree, parsed_rel):\n",
    "                continue\n",
    "            else:\n",
    "                wrong_count += 1\n",
    "                wrong.append(gold_trees.index(gold_tree))        \n",
    "        if wrong_count > 0:\n",
    "            print('There are {0} sentences parsed not quite right'.format(wrong_count))\n",
    "            print(wrong)\n",
    "        else:\n",
    "            print('All trees are good')\n",
    "            return\n",
    "        \n",
    "    def UAS_train(self, raw_text):\n",
    "        \"\"\"\n",
    "        Count Unlabeled Attachment Score for \"train set\".\n",
    "        That is, what % of dependencies we got right from the start.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        tp = 0\n",
    "        gold_trees = self.read_raw_conllu(raw_text)\n",
    "        for tree in gold_trees:\n",
    "            golden = set(self.get_relations(tree))\n",
    "            parsed = set(self.apply_actions(tree))\n",
    "            total += len(tree)\n",
    "            tp += len(golden.intersection(parsed))\n",
    "        return round(tp/total, 3)\n",
    "\n",
    "    def fit_classifier(self, features, labels, seed=505, clf='logistic', penalty='l2'):\n",
    "        \"\"\"\n",
    "        Fit Logistic Regression given vectorized train features and labels\n",
    "        \"\"\"\n",
    "        if clf == 'logistic':\n",
    "            clf_model = LogisticRegression(random_state=seed, penalty=penalty)\n",
    "        elif clf == 'sgd':\n",
    "            clf_model = SGDClassifier(random_state=seed, penalty=penalty,\n",
    "                                max_iter=1000, tol=1e-3)\n",
    "        vec = DictVectorizer()\n",
    "        pipeline = Pipeline([('vec', vec), ('clf', clf_model)])\n",
    "        pipeline.fit(features, labels)\n",
    "        return pipeline\n",
    "    \n",
    "    def classify_and_report(self, raw_train, raw_test,\n",
    "                            penalty='l2', clf='logistic'):\n",
    "        \"\"\"\n",
    "        Get all together\n",
    "        \"\"\"\n",
    "        train_features, train_labels = self.get_features_for_set(raw_train)\n",
    "        test_features, test_labels = self.get_features_for_set(raw_test)\n",
    "        pipeline = self.fit_classifier(train_features, train_labels, clf=clf, penalty=penalty)\n",
    "        predicted = pipeline.predict(test_features)\n",
    "        return classification_report(test_labels, predicted)\n",
    "    \n",
    "    def get_features_for_set(self, conllu_raw):\n",
    "        \"\"\"\n",
    "        Get features and labels for all of the trees in given set.\n",
    "        \"\"\"\n",
    "        set_trees = self.read_raw_conllu(conllu_raw)\n",
    "        features = []\n",
    "        labels = []\n",
    "        for t in set_trees:\n",
    "            _, labs, feats = self.apply_actions(t, train=True)\n",
    "            features.extend(feats)\n",
    "            labels.extend(labs)\n",
    "        return features, labels\n",
    "    \n",
    "    def predict_relations(self, tree, pipeline):\n",
    "        \"\"\"\n",
    "        A function that predict relations given classifier (oracle)\n",
    "        \"\"\"\n",
    "        stack, queue, relations = [self.ROOT], tree[:], []\n",
    "        while queue or stack:\n",
    "            if stack and not queue:\n",
    "                stack.pop()\n",
    "            else:\n",
    "                features = self.get_features(stack, queue, relations, tree)\n",
    "                action = pipeline.predict(features)[0]\n",
    "                if action == 'SHIFT':\n",
    "                    stack.append(queue.pop(0))\n",
    "                elif action == 'REDUCE':\n",
    "                    stack.pop()\n",
    "                elif action == 'LEFT':\n",
    "                    relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                    stack.pop()\n",
    "                elif action == 'RIGHT':\n",
    "                    relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                    stack.append(queue.pop(0))\n",
    "                else:\n",
    "                    print(\"Unknown action.\")\n",
    "        return sorted(relations)\n",
    "    \n",
    "    def train_and_save_model(self, raw, fname='model.pkl', clf='logistic', penalty='l2', seed=505):\n",
    "        \"\"\"\n",
    "        Save vectorizer and classifier for reuse.\n",
    "        \"\"\"\n",
    "        train_features, train_labels = self.get_features_for_set(raw)\n",
    "        vec = DictVectorizer()\n",
    "        if clf == 'sgd':\n",
    "            clf_model = SGDClassifier(random_state=seed, penalty=penalty,\n",
    "                                      max_iter=1000, tol=1e-3)\n",
    "        else:\n",
    "            clf_model = LogisticRegression(penalty=penalty, random_state=seed)\n",
    "        pipe = Pipeline([('vec', vec), ('clf', clf_model)])\n",
    "        pipe.fit(train_features, train_labels)\n",
    "        joblib.dump(pipe, fname)\n",
    "    \n",
    "    @classmethod\n",
    "    def pipeline_from_file(self, fname='model.pkl'):\n",
    "        \"\"\"\n",
    "        Load trained pipeline/model from file.\n",
    "        \"\"\"\n",
    "        pipeline = joblib.load(fname)\n",
    "        return pipeline\n",
    "    \n",
    "    def UAS_test(self, raw_train, raw_test, clf='logistic', penalty='l2', seed=505):\n",
    "        \"\"\"\n",
    "        Use predictions on test set, compute UAS\n",
    "        \"\"\"\n",
    "        train_features, train_labels = self.get_features_for_set(raw_train)\n",
    "        pipeline = self.fit_classifier(train_features, train_labels, clf=clf, \n",
    "                                       penalty=penalty, seed=seed)\n",
    "        test_trees = self.read_raw_conllu(raw_test)\n",
    "        total = 0\n",
    "        tp = 0\n",
    "        for tree in test_trees:\n",
    "            golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "            predicted = self.predict_relations(tree, pipeline)\n",
    "            total += len(tree)\n",
    "            tp += len(set(golden).intersection(set(predicted)))\n",
    "        uas = round(tp/total, 3)\n",
    "        return uas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Використаний у парсері статичний оракул та алгоритм Arc-Eager, придатний тільки для проективних дерев, не дають 100% надійності навіть для тих дерев, для яких усі залежності відомі. Точність (unlabeled attachment score) на тренувальному сеті тільки 97.4%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parser()\n",
    "p.UAS_train(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для покращення результатів на тестовому сеті ([бейзлайн - 0.69](https://github.com/vseloved/prj-nlp/blob/master/lectures/08-dep-parser-uk.ipynb)) я додав більше фіч:\n",
    "- POS-теги для найлівішої та найправішої дитини в уже передбачених залежностях (для одного слова з верхівки стеку і одного слова з початку черги);\n",
    "- кількість цих дітей;\n",
    "- морфологічні ознаки слова із підсловника 'feats';\n",
    "- поєднання форми слова + POS-тегу для слів з верхівки стеку і початку черги;\n",
    "- біграми і триграми POS-тегів для слів зі стеку, черги, черги+стеку тощо;\n",
    "- відстань між верхівкою стеку та початком черги (кількість слів у реченні між ними).\n",
    "\n",
    "Мінус усіх покращень - значне уповільнення тренування."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Parser()\n",
    "p.UAS_test(raw_train, raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дещо покращує результат використання параметру penalty='l1' для логістичної регресії. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.UAS_test(raw_train, raw_test, penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натомість використання SGDClassifier (який реалізує SVM) покращення не дає:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.UAS_test(raw_train, raw_test, clf='sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Також можна подивитись на іншу метрику - показники precision, recall, F1 для кожної з чотирьох дій алгоритму (бейзлайн - 0.81 для кожного показника в нижньому рядку)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       LEFT       0.91      0.93      0.92      7352\n",
      "     REDUCE       0.81      0.71      0.75      5511\n",
      "      RIGHT       0.81      0.86      0.83      7182\n",
      "      SHIFT       0.91      0.91      0.91      7757\n",
      "\n",
      "avg / total       0.86      0.86      0.86     27802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p.classify_and_report(raw_train, raw_test, penalty='l1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Великою проблемою є низький recall для REDUCE: класифікатор не завжди вчасно \"позбувається\" слова зі стеку, і це може призвести до купи помилок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсер №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledParser(Parser):\n",
    "    \"\"\"\n",
    "    Dependency parser using static oracle,\n",
    "    for labeled dependencies.\n",
    "    \"\"\"\n",
    "    def strip_colon(self, deprel):\n",
    "        \"\"\"\n",
    "        Strip the second part of deprel (after colon).\n",
    "        \"\"\"\n",
    "        if ':' in deprel:\n",
    "            new = deprel.split(':')[0].strip()\n",
    "            return new\n",
    "        else:\n",
    "            return deprel\n",
    "        \n",
    "    def make_action(self, action, stack, queue, relations):\n",
    "        \"\"\"\n",
    "        Applies action to the stack, the queue, and the relations.\n",
    "        \"\"\"\n",
    "        w1 = stack[-1]\n",
    "        w2 = queue[0]\n",
    "        if action[0] == 'SHIFT':\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action[0] == 'REDUCE':\n",
    "            stack.pop()\n",
    "        elif action[0] == 'LEFT':\n",
    "            relations.append((w1['id'], self.strip_colon(w1['deprel']), w2['id']))\n",
    "            stack.pop()\n",
    "        elif action[0] == 'RIGHT':\n",
    "            relations.append((w2['id'], self.strip_colon(w2['deprel']), w1['id']))\n",
    "            stack.append(queue.pop(0))\n",
    "        return stack, queue, relations\n",
    "\n",
    "    def oracle(self, top_stack, top_queue, relations):\n",
    "        \"\"\"\n",
    "        Returns the right action given the state\n",
    "        of the stack, the queue, and the relations.\n",
    "        \"\"\"\n",
    "        if top_stack and not top_queue:\n",
    "            return ('REDUCE', '')\n",
    "        elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "            return ('RIGHT', self.strip_colon(top_queue[\"deprel\"]))\n",
    "        elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "            return ('LEFT', self.strip_colon(top_stack[\"deprel\"]))\n",
    "        elif (top_stack[\"id\"] in [i[0] for i in relations] and \n",
    "             top_queue[\"head\"] < top_stack[\"id\"]):\n",
    "            return ('REDUCE', '')\n",
    "        else:\n",
    "            return ('SHIFT', '')\n",
    "\n",
    "    def get_child_deps(self, wid, relations, tree):\n",
    "        \"\"\"\n",
    "        Get rightmost and leftmost child dependencies.\n",
    "        \"\"\"\n",
    "        children = list(filter(lambda x: x[2] == wid, relations))\n",
    "        if len(children):\n",
    "            nchildren = len([x for x in children])\n",
    "            lc1 = min(d for (d, r, h) in children)\n",
    "            rc1 = max(d for (d, r, h) in children)\n",
    "            return tree[lc1], tree[rc1], nchildren\n",
    "        return None\n",
    "        \n",
    "    def get_features(self, stack, queue, relations, tree):\n",
    "        \"\"\"\n",
    "        Create a dictionary of features for each action.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        if stack:\n",
    "            w = stack[-1]\n",
    "            features.update({\n",
    "                'st0form': w['form'],\n",
    "                'st0lemma': w['lemma'],\n",
    "                'st0pos': w['upostag'],\n",
    "                'st0form_pos': w['form']+'_'+w['upostag']\n",
    "            })\n",
    "            if self.get_child_deps(w['id'], relations, tree):\n",
    "                left_pos, right_pos, nchildren = self.get_child_deps(w['id'], relations, tree)\n",
    "                features.update({\n",
    "                    'st0leftc_pos': left_pos['upostag'],\n",
    "                    'st0rightc_pos': right_pos['upostag'],\n",
    "                    'st0nchildren': nchildren\n",
    "                })\n",
    "            features.update(self.get_morph_feats(w))\n",
    "        if len(stack) > 1:\n",
    "            w = stack[-2]\n",
    "            features.update({\n",
    "                'st1pos': w['upostag'],\n",
    "                'st1form': w['form'],\n",
    "                'st1form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'st0_1pos': stack[-1]['upostag'] + '_' + w['upostag']\n",
    "            })\n",
    "        if queue:\n",
    "            w = queue[0]\n",
    "            features.update({\n",
    "                'q0form': w['form'],\n",
    "                'q0lemma': w['lemma'],\n",
    "                'q0pos': w['upostag'],\n",
    "                'q0form_pos': w['form']+'_'+w['upostag']\n",
    "            })\n",
    "            if self.get_child_deps(w['id'], relations, tree):\n",
    "                left_pos, right_pos, nchildren = self.get_child_deps(w['id'], relations, tree)\n",
    "                features.update({\n",
    "                    'q0leftc_pos': left_pos['upostag'],\n",
    "                    'q0rightc_pos': right_pos['upostag'],\n",
    "                    'q0nchildren': nchildren\n",
    "                })\n",
    "            features.update(self.get_morph_feats(w))\n",
    "        if len(queue) > 1:\n",
    "            w = queue[1]\n",
    "            features.update({\n",
    "                'q1form': w['form'],\n",
    "                'q1lemma': w['lemma'],\n",
    "                'q1pos': w['upostag'],\n",
    "                'q1form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'q0_1pos': queue[0]['upostag'] + '_' + w['upostag']\n",
    "            })\n",
    "        if len(queue) > 2:\n",
    "            w = queue[2]\n",
    "            features.update({\n",
    "                'q2pos': w['upostag'],\n",
    "                'q2form_pos': w['form'] + '_' + w['upostag'],\n",
    "                'q012pos': queue[0]['upostag'] + '_' + queue[1]['upostag'] + w['upostag']\n",
    "            })\n",
    "        if len(queue) > 3:\n",
    "            w = queue[3]\n",
    "            features.update({\n",
    "                'q3pos': w['upostag']\n",
    "            })\n",
    "        if stack and queue:\n",
    "            w1 = stack[-1]\n",
    "            w2 = queue[0]\n",
    "            features.update({\n",
    "                'distance': abs(w1['id'] - w2['id']),\n",
    "                'st0f_q0f': w1['form'] + '_' + w2['form'],\n",
    "                'st0p_q0p': w1['upostag'] + '_' + w2['upostag'],\n",
    "                'st0f_q0p': w1['form'] + '_' + w2['upostag'],\n",
    "                'st0p_q0f': w1['upostag'] + '_' + w2['form']\n",
    "            })\n",
    "        return features\n",
    "    \n",
    "    def get_relations(self, tree):\n",
    "        \"\"\"\n",
    "        Return list of relation nodes (child, rel, parent)\n",
    "        \"\"\"\n",
    "        return [(w['id'], self.strip_colon(w['deprel']), w['head']) for w in tree]\n",
    "       \n",
    "    def LAS_train(self, raw_text):\n",
    "        \"\"\"\n",
    "        Count Labeled Attachment Score for \"train set\".\n",
    "        That is, what % of dependencies we got right from the start.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        tp = 0\n",
    "        gold_trees = self.read_raw_conllu(raw_text)\n",
    "        for tree in gold_trees:\n",
    "            golden = set(self.get_relations(tree))\n",
    "            parsed = set(self.apply_actions(tree))\n",
    "            total += len(tree)\n",
    "            tp += len(golden.intersection(parsed))\n",
    "        return round(tp/total, 3)\n",
    "     \n",
    "    def get_features_for_set(self, conllu_raw):\n",
    "        \"\"\"\n",
    "        Get features and labels for all of the trees in given set.\n",
    "        \"\"\"\n",
    "        set_trees = self.read_raw_conllu(conllu_raw)\n",
    "        features = []\n",
    "        labels = []\n",
    "        for t in set_trees:\n",
    "            _, labs, feats = self.apply_actions(t, train=True)\n",
    "            features.extend(feats)\n",
    "            labels.extend([l[0]+'_'+l[1] for l in labs])\n",
    "        return features, labels\n",
    "    \n",
    "    def predict_relations(self, tree, pipeline):\n",
    "        \"\"\"\n",
    "        A function that predict relations given classifier (oracle)\n",
    "        \"\"\"\n",
    "        stack, queue, relations = [self.ROOT], tree[:], []\n",
    "        while queue or stack:\n",
    "            if stack and not queue:\n",
    "                stack.pop()\n",
    "            else:\n",
    "                features = self.get_features(stack, queue, relations, tree)\n",
    "                action_tuple = pipeline.predict(features)[0]\n",
    "                action = action_tuple.split('_')[0].strip()\n",
    "                pred_rel = action_tuple.split('_')[1].strip()\n",
    "                if action == 'SHIFT':\n",
    "                    stack.append(queue.pop(0))\n",
    "                elif action == 'REDUCE':\n",
    "                    stack.pop()\n",
    "                elif action == 'LEFT':\n",
    "                    relations.append((stack[-1][\"id\"], pred_rel, queue[0][\"id\"]))\n",
    "                    stack.pop()\n",
    "                elif action == 'RIGHT':\n",
    "                    relations.append((queue[0][\"id\"], pred_rel, stack[-1][\"id\"]))\n",
    "                    stack.append(queue.pop(0))\n",
    "                else:\n",
    "                    print(\"Unknown action.\")\n",
    "        return sorted(relations)\n",
    "    \n",
    "    def LAS_test(self, raw_train, raw_test, seed=505, penalty='l2'):\n",
    "        \"\"\"\n",
    "        Use predictions on test set, compute UAS\n",
    "        \"\"\"\n",
    "        train_features, train_labels = self.get_features_for_set(raw_train)\n",
    "        pipeline = self.fit_classifier(train_features, train_labels, seed=seed, penalty=penalty)\n",
    "        test_trees = self.read_raw_conllu(raw_test)\n",
    "        total = 0\n",
    "        tp = 0\n",
    "        for tree in test_trees:\n",
    "            golden = [(node[\"id\"], self.strip_colon(node[\"deprel\"]), node[\"head\"]) for node in tree]\n",
    "            predicted = self.predict_relations(tree, pipeline)\n",
    "            total += len(tree)\n",
    "            tp += len(set(golden).intersection(set(predicted)))\n",
    "        las = round(tp/total, 3)\n",
    "        return las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Складність парсера, який маркує залежності, в тому, що кожне поєднання \"дія+залежність\" рахується як окремий клас, і деякі з цих класів мають дуже малу кількість випадків. Щоб зменшити кількість класів, я видаляю функцією `strip_colon` \"уточнення\" після двокрапки для тих залежностей, які мають форму \"dep:detailed\". І все одно у нас лишилось 56 класів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = LabeledParser()\n",
    "lp.LAS_test(raw_train, raw_test, penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незважаючи на потребу маркувати тип кожної залежності, labeled attachment score на тестовому сеті ненабагато нижчий, ніж UAS (якщо я ніде не помилився)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     LEFT_advcl       0.65      0.41      0.50        63\n",
      "    LEFT_advmod       0.88      0.94      0.91       549\n",
      "      LEFT_amod       0.96      1.00      0.98      1375\n",
      "       LEFT_aux       0.94      0.89      0.92        19\n",
      "      LEFT_case       0.99      0.99      0.99      1355\n",
      "        LEFT_cc       0.94      0.94      0.94       541\n",
      "     LEFT_ccomp       0.00      0.00      0.00         1\n",
      "  LEFT_compound       0.83      0.33      0.48        15\n",
      "       LEFT_cop       0.89      0.97      0.93        65\n",
      "     LEFT_csubj       0.50      0.12      0.20         8\n",
      "       LEFT_dep       0.00      0.00      0.00         1\n",
      "       LEFT_det       0.96      0.99      0.98       433\n",
      " LEFT_discourse       0.74      0.79      0.76       134\n",
      "      LEFT_expl       0.86      0.50      0.63        12\n",
      "      LEFT_iobj       0.67      0.17      0.27        12\n",
      "      LEFT_mark       0.95      0.93      0.94       217\n",
      "      LEFT_nmod       1.00      0.15      0.27        13\n",
      "     LEFT_nsubj       0.87      0.87      0.87       581\n",
      "    LEFT_nummod       0.93      1.00      0.96       113\n",
      "       LEFT_obj       0.76      0.79      0.78       123\n",
      "       LEFT_obl       0.78      0.70      0.74       350\n",
      " LEFT_parataxis       0.57      0.13      0.22        30\n",
      "     LEFT_punct       0.83      0.95      0.89      1330\n",
      "  LEFT_vocative       0.60      1.00      0.75         3\n",
      "     LEFT_xcomp       0.80      0.44      0.57         9\n",
      "        REDUCE_       0.78      0.77      0.78      5511\n",
      "      RIGHT_acl       0.65      0.46      0.54       167\n",
      "    RIGHT_advcl       0.50      0.55      0.53        76\n",
      "   RIGHT_advmod       0.73      0.84      0.78        85\n",
      "     RIGHT_amod       0.55      0.38      0.45        55\n",
      "    RIGHT_appos       0.32      0.08      0.12       104\n",
      "      RIGHT_aux       1.00      0.75      0.86         8\n",
      "    RIGHT_ccomp       0.74      0.53      0.61        74\n",
      " RIGHT_compound       0.87      0.75      0.81        36\n",
      "     RIGHT_conj       0.64      0.48      0.55       774\n",
      "      RIGHT_cop       0.83      0.91      0.87        11\n",
      "    RIGHT_csubj       0.90      0.73      0.81        37\n",
      "      RIGHT_det       0.43      0.75      0.55         4\n",
      "RIGHT_discourse       0.82      0.72      0.77        39\n",
      "    RIGHT_fixed       0.73      0.35      0.48        31\n",
      "     RIGHT_flat       0.74      0.77      0.76       366\n",
      " RIGHT_goeswith       0.00      0.00      0.00         2\n",
      "     RIGHT_iobj       0.85      0.46      0.59        24\n",
      "     RIGHT_list       0.00      0.00      0.00         3\n",
      "     RIGHT_nmod       0.73      0.86      0.79      1666\n",
      "    RIGHT_nsubj       0.88      0.89      0.89       197\n",
      "   RIGHT_nummod       1.00      1.00      1.00         1\n",
      "      RIGHT_obj       0.88      0.86      0.87       492\n",
      "      RIGHT_obl       0.80      0.86      0.83       645\n",
      "   RIGHT_orphan       1.00      0.50      0.67         6\n",
      "RIGHT_parataxis       0.60      0.38      0.46       148\n",
      "    RIGHT_punct       0.86      0.82      0.84      1266\n",
      "     RIGHT_root       0.95      0.94      0.94       742\n",
      " RIGHT_vocative       0.00      0.00      0.00         2\n",
      "    RIGHT_xcomp       0.82      0.80      0.81       121\n",
      "         SHIFT_       0.91      0.92      0.92      7757\n",
      "\n",
      "    avg / total       0.85      0.85      0.85     27802\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/Bin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(lp.classify_and_report(raw_train, raw_test, penalty='l1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблиця за класами показує, що загалом чим менше випадків має клас, тим гірші для нього результати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Збережемо натреновані моделі парсерів для використання згодом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.train_and_save_model(raw_train, fname='model.pkl', penalty='l1')\n",
    "lp.train_and_save_model(raw_train, fname='model_labeled.pkl', penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсер №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Динамічний оракул для парсера залежностей описаний у [статті Голдберга і Нівре] (http://www.aclweb.org/anthology/C12-1059). Парсер із таким оракулом описано в статті \"Parsing English in 500 Lines of Python\", але я використав [імплементацію](https://github.com/dpressel/arcs-py) github-користувача dpressel. У цій імплементації працює \"знайомий\" нам алгоритм Arc-Eager із чотирма, а не трьома діями (в інших алгоритмах немає REDUCE). \n",
    "\n",
    "Я адаптував код у файлах парсера, внісши невеликі зміни та \"переклавши\" деякі частини на python 3. Найбільші зміни торкнулись файлу fx.py, який містить feature extractor: я додав такі фічі, як відстань, більше біграм, морфологічні ознаки слова із підсловника 'feats' і так далі.\n",
    "\n",
    "Цей парсер використовує on-line learning і вимагає декілька ітерацій для тренування: в якості класифікатора діє перцептрон, який модифікує ваги для фіч під час кожної ітерації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcs_py.parse import ArcEagerDepParser, GreedyDepParser, Classifier\n",
    "from arcs_py import fileio\n",
    "from arcs_py import fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формат представлення речень для цього парсера трохи відрізняється."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu(path):\n",
    "    data = conllu.parse(gzip.open(path, 'rb').read().decode())\n",
    "    sentences = []\n",
    "    for sent in data:\n",
    "        sentences.append([(w['form'], w['upostag'], w['head']-1, w['deprel'], w['lemma'], w['feats'])\n",
    "                               if not w['head'] == 0 \n",
    "                               else (w['form'], w['upostag'], len(sent), w['deprel'], w['lemma'], w['feats'])\n",
    "                               for w in sent])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = read_conllu('uk_iu-ud-train.conllu.gz')\n",
    "test_sentences = read_conllu('uk_iu-ud-test.conllu.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Також парсер не працює з непроективними деревами, тому відповідна функція позбувається близько 300 з 4500 тренувальних речень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4513\n",
      "4205\n"
     ]
    }
   ],
   "source": [
    "def filter_non_projective(gold):\n",
    "    gold_proj = []\n",
    "    for s in gold:\n",
    "        gold_conf = GreedyDepParser.get_gold_conf(s)\n",
    "        if GreedyDepParser.non_projective(gold_conf) is False:\n",
    "            gold_proj.append(s)\n",
    "        #elif opts.v is True:\n",
    "        #    print('Skipping non-projective sentence', s)\n",
    "    return gold_proj\n",
    "    \n",
    "print(len(train_sentences))\n",
    "train_sentences = filter_non_projective(train_sentences)\n",
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of correct transitions iteration 1: 119196/133614 = 0.892092\n",
      "fraction of correct transitions iteration 2: 124675/133614 = 0.933098\n",
      "fraction of correct transitions iteration 3: 127199/133614 = 0.951989\n",
      "fraction of correct transitions iteration 4: 129029/133614 = 0.965685\n",
      "fraction of correct transitions iteration 5: 130106/133614 = 0.973745\n",
      "fraction of correct transitions iteration 6: 130547/133614 = 0.977046\n",
      "fraction of correct transitions iteration 7: 131140/133614 = 0.981484\n",
      "fraction of correct transitions iteration 8: 131588/133614 = 0.984837\n",
      "fraction of correct transitions iteration 9: 132025/133614 = 0.988108\n",
      "fraction of correct transitions iteration 10: 132269/133614 = 0.989934\n",
      "fraction of correct transitions iteration 11: 132487/133614 = 0.991565\n",
      "fraction of correct transitions iteration 12: 132597/133614 = 0.992389\n",
      "fraction of correct transitions iteration 13: 132680/133614 = 0.993010\n",
      "fraction of correct transitions iteration 14: 132766/133614 = 0.993653\n",
      "fraction of correct transitions iteration 15: 132989/133614 = 0.995322\n",
      "fraction of correct transitions iteration 16: 132963/133614 = 0.995128\n",
      "fraction of correct transitions iteration 17: 132984/133614 = 0.995285\n",
      "fraction of correct transitions iteration 18: 133186/133614 = 0.996797\n",
      "fraction of correct transitions iteration 19: 133168/133614 = 0.996662\n",
      "fraction of correct transitions iteration 20: 133227/133614 = 0.997104\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = fx.ex\n",
    "model = Classifier({}, [0, 1, 2, 3])\n",
    "parser = ArcEagerDepParser(model, feature_extractor)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    correct_iter = 0\n",
    "    all_iter = 0\n",
    "    random.shuffle(train_sentences)\n",
    "    for gold_sent in train_sentences:\n",
    "        correct_s, all_s = parser.train(gold_sent, i)\n",
    "        correct_iter += correct_s\n",
    "        all_iter += all_s\n",
    "    print('fraction of correct transitions iteration %d: %d/%d = %f' \n",
    "          % (i, correct_iter, all_iter, correct_iter/float(all_iter)))\n",
    "parser.avg_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер на тестовому сеті:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS 11150/13879 = 0.803\n"
     ]
    }
   ],
   "source": [
    "test = filter_non_projective(test_sentences)\n",
    "all_arcs = 0\n",
    "correct_arcs = 0\n",
    "\n",
    "for gold_test_sent in test:\n",
    "\n",
    "    gold_arcs = [(gold_test_sent[i][2], i) for i in range(len(gold_test_sent))]\n",
    "    arcs = parser.run(gold_test_sent)\n",
    "    correct_arcs += len(set(gold_arcs) & set(arcs))\n",
    "    all_arcs += len(set(gold_arcs))\n",
    "\n",
    "print('UAS {ca}/{aa} = {uas}'.format(ca=correct_arcs, aa=all_arcs, \n",
    "                               uas=round(correct_arcs/all_arcs, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут можна зауважити, що тренувальна і тестова вибірка для цього парсера відрізняються, тому що не включають кількасот непроективних дерев. Але я окремо прогнав перший unlabeled парсер на \"відфільтрованих\" вибірках, і вийшов UAS 0.77 - мінімальне покращення порівняно з 0.768."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Використання парсерів на нових даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для використання парсера на нових даних, потрібно навчитись діставати з них не тільки POS-теги, але і різні морфологічні властивості - це pymorphy2 більш-менш також може робити."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PRED\": \"ADV\", \"PREP\": \"ADP\", \"PRCL\": \"PART\",\n",
    "           \"PNCT\": \"PUNCT\", \"LATN\": \"X\"}\n",
    "\n",
    "CONJ_COORD = [\"а\", \"або\", \"але\", \"ані\", \"все\", \"все-таки\", \"втім\", \"ж\", \"же\",\n",
    "              \"зате\", \"і\", \"й\", \"ніже\", \"однак\", \"одначе\", \"прецінь\", \"проте\",\n",
    "              \"та\", \"так\", \"також\", \"усе\", \"усе-таки\", \"утім\", \"чи\"]\n",
    "\n",
    "DET = ['інакший', 'його', 'тамтой', 'чий', 'їх', 'інш.', 'деякий', 'ввесь', 'ваш', \n",
    "     'ніякий', 'весь', 'інший', 'чийсь', 'жадний', 'другий', 'кожний', \n",
    "     'такий', 'оцей', 'скілька', 'цей', 'жодний', 'все', 'кілька', 'увесь', \n",
    "     'кожній', 'те', 'сей', 'ін.', 'отакий', 'котрий', 'усякий', 'самий', \n",
    "     'наш', 'усілякий', 'будь-який', 'сам', 'свій', 'всілякий', 'всенький', 'її', \n",
    "     'всякий', 'отой', 'небагато', 'який', 'їхній', 'той', 'якийсь', 'ин.', 'котрийсь', \n",
    "     'твій', 'мій', 'це', 'яка', 'якась', 'ця']\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if not word.tag.POS:\n",
    "        if word.word in string.punctuation:\n",
    "            return \"PUNCT\"\n",
    "        else:\n",
    "            return \"X\"\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if word.word in CONJ_COORD:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    if word.normal_form in DET:\n",
    "        return 'DET'\n",
    "    else:\n",
    "        return MAPPING.get(word.tag.POS, word.tag.POS)\n",
    "\n",
    "def morph_feats(word):\n",
    "    \"\"\"\n",
    "    Get morphological features of the word.\n",
    "    \"\"\"\n",
    "    morph_dict = {\n",
    "        'Gender': word.tag.gender,\n",
    "        'Case': word.tag.case,\n",
    "        'Number': word.tag.number,\n",
    "        'Animacy': word.tag.animacy,\n",
    "        'Mood': word.tag.mood,\n",
    "        'Tense': word.tag.tense,\n",
    "        'Aspect': word.tag.aspect,\n",
    "        'Person': word.tag.person,\n",
    "        'Voice': word.tag.voice\n",
    "    }\n",
    "    morph_mapping = {'femn': 'Fem', 'nomn': 'Nom', 'gent': 'Gen', 'datv': 'Dat',\n",
    "                    'ablt': 'Ins', 'accs': 'Acc', 'loct': 'Loc', 'voct': 'Voc',\n",
    "                    'indc': 'Ind', 'impr': 'Imp', 'futr': 'Fut', 'impf': 'Imp',\n",
    "                    '1per': '1', '2per': '2', '3per': '3', 'actv': 'Act',\n",
    "                    'pssv': 'Pass'}\n",
    "    feature_dict = OrderedDict()\n",
    "    for feat, value in morph_dict.items():\n",
    "        if not value:\n",
    "            continue\n",
    "        if value in morph_mapping.keys():\n",
    "            feature_dict[feat] = morph_mapping[value]\n",
    "        else:\n",
    "            feature_dict[feat] = value.title()\n",
    "    # let's also add some more verb recognition tools\n",
    "    if 'GRND' in word.tag:\n",
    "        feature_dict['VerbForm'] = 'Conv'\n",
    "    elif 'ADJF' in word.tag and 'pssv' in word.tag:\n",
    "        feature_dict['VerbForm'] = 'Part'\n",
    "    elif 'infn' in word.tag:\n",
    "        feature_dict['VerbForm'] = 'Inf'\n",
    "    elif 'VERB' in word.tag:\n",
    "        feature_dict['VerbForm'] = 'Fin'\n",
    "    return feature_dict\n",
    "\n",
    "def build_tree(sent):\n",
    "    \"\"\"\n",
    "    Build a tree from sent for parsing.\n",
    "    \"\"\"\n",
    "    words = tokenize_words(sent)\n",
    "    tree = []\n",
    "    i = 1\n",
    "    for word in words:\n",
    "        wparsed = morph.parse(word)[0]\n",
    "        word_dict = OrderedDict()\n",
    "        word_dict['id'] = i\n",
    "        word_dict['form'] = word\n",
    "        word_dict['lemma'] = wparsed.normal_form\n",
    "        word_dict['upostag'] = normalize_pos(wparsed)\n",
    "        if morph_feats(wparsed):\n",
    "            word_dict['feats'] = morph_feats(wparsed)\n",
    "        tree.append(word_dict)\n",
    "        i += 1\n",
    "    return tree\n",
    "\n",
    "def build_tree2(sent):\n",
    "    \"\"\"\n",
    "    Build a tree for a parser with dynamic oracle, of a form:\n",
    "    (word, POS, head, deprel, lemma, feats)\n",
    "    \"\"\"\n",
    "    words = tokenize_words(sent)\n",
    "    tree = []\n",
    "    for word in words:\n",
    "        wparsed = morph.parse(word)[0]\n",
    "        postag = normalize_pos(wparsed)\n",
    "        lemma = wparsed.normal_form\n",
    "        if morph_feats(wparsed):\n",
    "            feats = morph_feats(wparsed)\n",
    "        else:\n",
    "            feats = OrderedDict()\n",
    "        word_tuple = (word, postag, None, '', lemma, feats)\n",
    "        tree.append(word_tuple)\n",
    "    return tree\n",
    "        \n",
    "def dep_parse(sent, model):\n",
    "    \"\"\"\n",
    "    Dependepcy-parse a sentence in Ukrainian.\n",
    "    \"\"\"\n",
    "    tree = build_tree(sent)\n",
    "    p = Parser()\n",
    "    relations = p.predict_relations(tree, model)\n",
    "    return tree, relations\n",
    "\n",
    "def labeled_parse(sent, model):\n",
    "    \"\"\"\n",
    "    Parse a sentence in Ukrainian and label dependencies.\n",
    "    \"\"\"\n",
    "    tree = build_tree(sent)\n",
    "    lp = LabeledParser()\n",
    "    relations = lp.predict_relations(tree, model)\n",
    "    return tree, relations\n",
    "\n",
    "def dynamic_parse(sent, parser):\n",
    "    \"\"\"\n",
    "    Parse a sentence in Ukrainian with dynamic oracle.\n",
    "    \"\"\"\n",
    "    tree = build_tree2(sent)\n",
    "    relations = parser.run(tree)\n",
    "    return tree, sorted(relations, key = lambda x: x[1])\n",
    "    \n",
    "def visualize_tree(tree, relations):\n",
    "    \"\"\"\n",
    "    Draw some arrows.\n",
    "    \"\"\"\n",
    "    if len(relations[0]) == 3:\n",
    "        for rel in relations:\n",
    "            w1, deprel, w2 = rel\n",
    "            word1 = tree[w1-1]['form']\n",
    "            if w2 == 0:\n",
    "                word2 = 'ROOT'\n",
    "            else:\n",
    "                word2 = tree[w2-1]['form']\n",
    "            line = '{w1} --{deprel}--> {w2}'.format(\n",
    "                w1=word1, deprel=deprel, w2=word2)\n",
    "            print(line)\n",
    "    else:\n",
    "        for rel in relations:\n",
    "            w1, w2 = rel[0], rel[1]\n",
    "            word1 = tree[w1-1]['form']\n",
    "            if w2 == 0:\n",
    "                word2 = 'ROOT'\n",
    "            else:\n",
    "                word2 = tree[w2-1]['form']\n",
    "            line = '{w1} ---> {w2}'.format(\n",
    "                w1=word1, w2=word2)\n",
    "            print(line)\n",
    "\n",
    "def visualize_dynamic(tree, relations):\n",
    "    \"\"\"\n",
    "    Draw even more arrows.\n",
    "    \"\"\"\n",
    "    for (w1, w2) in relations:\n",
    "        child_word = tree[w2][0]\n",
    "        if w1 >= len(tree):\n",
    "            parent_word = 'ROOT'\n",
    "        else:\n",
    "            parent_word = tree[w1][0]\n",
    "        line = '{child} ---> {parent}'.format(\n",
    "            child=child_word, parent=parent_word)\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_model = Parser().pipeline_from_file('model.pkl')\n",
    "lab_model = LabeledParser().pipeline_from_file('model_labeled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Літературної англійської мови, такої яка є в інших країнах, де існують спеціальні інституції,\\\n",
    " що затверджують мовний стандарт, як наприклад Французька академія у Франції, не існує\",\n",
    " \"Запишіть ваші спостереження та результати в окремий файл\",\n",
    " \"Іноді деякі товари буває важко продати через зіпсовану упаковку чи якісь пошкодження,\\\n",
    " які не критично впливають на їх функції\",\n",
    " \"Дівчина стояла там, де й була, і намагалася привести до ладу скуйовджене волосся,\\\n",
    " вкрай розлючена тим, що це побачили водії, які чекали на переїзді\",\n",
    " \"Тисячі людей знову вийшли на вулиці Єревана після заклику лідера опозиції продовжити протести,\\\n",
    " щоб завершити оксамитову революцію\",\n",
    " \"Одного ранку, прокинувшись од неспокійного сну, Грегор Замза побачив, що він обернувся на страхітливу комаху\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parsers(sent):\n",
    "    print('Unlabeled parsing:\\n')\n",
    "    tree, rels = dep_parse(sent, unlab_model)\n",
    "    visualize_tree(tree, rels)\n",
    "    print('\\n=======================\\n')\n",
    "    print('Labeled parsing:\\n')\n",
    "    tree, rels = labeled_parse(sent, lab_model)\n",
    "    visualize_tree(tree, rels)\n",
    "    print('\\n=======================\\n')\n",
    "    print('Dynamic oracle parsing:\\n')\n",
    "    tree, rels = dynamic_parse(sent, parser)\n",
    "    visualize_dynamic(tree, rels)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Літературної ---> мови\n",
      "англійської ---> мови\n",
      "мови ---> є\n",
      ", ---> є\n",
      "такої ---> яка\n",
      "яка ---> є\n",
      "є ---> ROOT\n",
      "в ---> країнах\n",
      "інших ---> країнах\n",
      "країнах ---> є\n",
      ", ---> існують\n",
      "де ---> існують\n",
      "існують ---> є\n",
      "спеціальні ---> інституції\n",
      "інституції ---> існують\n",
      ", ---> затверджують\n",
      "що ---> затверджують\n",
      "затверджують ---> існують\n",
      "мовний ---> стандарт\n",
      "стандарт ---> затверджують\n",
      ", ---> наприклад\n",
      "як ---> наприклад\n",
      "Французька ---> академія\n",
      "академія ---> стандарт\n",
      "у ---> Франції\n",
      "Франції ---> академія\n",
      ", ---> існує\n",
      "не ---> існує\n",
      "існує ---> є\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Літературної --amod--> мови\n",
      "англійської --amod--> мови\n",
      "мови --obl--> існують\n",
      ", --punct--> є\n",
      "такої --obj--> є\n",
      "є --acl--> мови\n",
      "в --case--> країнах\n",
      "інших --det--> країнах\n",
      "країнах --obl--> є\n",
      ", --punct--> існують\n",
      "де --discourse--> існують\n",
      "існують --advcl--> існує\n",
      "існують --root--> ROOT\n",
      "спеціальні --amod--> інституції\n",
      "інституції --obj--> існують\n",
      ", --punct--> затверджують\n",
      "що --mark--> затверджують\n",
      "затверджують --conj--> існують\n",
      "мовний --amod--> стандарт\n",
      "стандарт --nsubj--> затверджують\n",
      ", --punct--> наприклад\n",
      "як --discourse--> наприклад\n",
      "Французька --amod--> академія\n",
      "академія --conj--> стандарт\n",
      "у --case--> Франції\n",
      "Франції --nmod--> стандарт\n",
      ", --punct--> існують\n",
      "не --advmod--> існує\n",
      "існує --root--> ROOT\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Літературної ---> мови\n",
      "англійської ---> мови\n",
      "мови ---> ROOT\n",
      ", ---> є\n",
      "такої ---> є\n",
      "яка ---> є\n",
      "є ---> мови\n",
      "в ---> країнах\n",
      "інших ---> країнах\n",
      "країнах ---> є\n",
      ", ---> існують\n",
      "де ---> існують\n",
      "існують ---> країнах\n",
      "спеціальні ---> інституції\n",
      "інституції ---> існують\n",
      ", ---> затверджують\n",
      "що ---> затверджують\n",
      "затверджують ---> інституції\n",
      "мовний ---> стандарт\n",
      "стандарт ---> затверджують\n",
      ", ---> затверджують\n",
      "як ---> академія\n",
      "наприклад ---> академія\n",
      "Французька ---> академія\n",
      "академія ---> існують\n",
      "у ---> Франції\n",
      "Франції ---> академія\n",
      ", ---> існує\n",
      "не ---> існує\n",
      "існує ---> мови\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це досить складне речення. Тут уже проявилась та проблема, що для деяких слів парсер зі статичним оракулом призначає дві залежності (у цьому випадку лише для деяких ком). Цю проблему можна вирішити, мабуть, змушуючи парсер вибирати найбільш імовірну з двох залежностей.\n",
    "\n",
    "В усіх парсерів проблеми з рутом: динамічний взагалі обрав іменник, другий парсер має два рути (хоча один з них правильний). Прикметники тут і далі добре промарковано як залежні від іменників, які вони модифікують."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Запишіть ---> ROOT\n",
      "ваші ---> спостереження\n",
      "спостереження ---> Запишіть\n",
      "та ---> результати\n",
      "результати ---> спостереження\n",
      "в ---> файл\n",
      "окремий ---> файл\n",
      "файл ---> Запишіть\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Запишіть --root--> ROOT\n",
      "ваші --det--> спостереження\n",
      "спостереження --nsubj--> Запишіть\n",
      "та --cc--> результати\n",
      "результати --conj--> Запишіть\n",
      "в --case--> файл\n",
      "окремий --amod--> файл\n",
      "файл --obl--> Запишіть\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Запишіть ---> ROOT\n",
      "ваші ---> спостереження\n",
      "спостереження ---> Запишіть\n",
      "та ---> результати\n",
      "результати ---> спостереження\n",
      "в ---> файл\n",
      "окремий ---> файл\n",
      "файл ---> спостереження\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це просте речення, яке парсери промаркували схожим чином. На цьому реченні я побачив, що парсери маркують \"ваші\" як підмет, залежний від дієслова. Винен був pymorphy2, який позначає \"ваші\" і схожі слова як займенники, хоча в тренувальній вибірці це DET, а займенниками є тільки іменнико-подібні слова (часто підмети). Тому я витягнув із тренувальної вибірки список слів, які потрібно позначати як DET, і це речення стало парситись майже ідеально."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Іноді ---> буває\n",
      "деякі ---> товари\n",
      "товари ---> буває\n",
      "буває ---> ROOT\n",
      "продати ---> буває\n",
      "через ---> упаковку\n",
      "зіпсовану ---> упаковку\n",
      "упаковку ---> продати\n",
      "чи ---> якісь\n",
      "якісь ---> пошкодження\n",
      "пошкодження ---> упаковку\n",
      ", ---> впливають\n",
      "які ---> впливають\n",
      "не ---> критично\n",
      "критично ---> впливають\n",
      "впливають ---> продати\n",
      "їх ---> на\n",
      "функції ---> впливають\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Іноді --nsubj--> буває\n",
      "деякі --det--> товари\n",
      "буває --root--> ROOT\n",
      "важко --advmod--> буває\n",
      "важко --advmod--> продати\n",
      "продати --conj--> буває\n",
      "через --case--> упаковку\n",
      "зіпсовану --amod--> упаковку\n",
      "упаковку --obl--> продати\n",
      "чи --discourse--> пошкодження\n",
      "якісь --det--> пошкодження\n",
      "пошкодження --conj--> упаковку\n",
      ", --punct--> впливають\n",
      "які --nsubj--> впливають\n",
      "не --advmod--> критично\n",
      "критично --advmod--> впливають\n",
      "впливають --acl--> пошкодження\n",
      "на --discourse--> функції\n",
      "їх --obj--> на\n",
      "функції --obl--> впливають\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Іноді ---> буває\n",
      "деякі ---> товари\n",
      "товари ---> буває\n",
      "буває ---> ROOT\n",
      "важко ---> продати\n",
      "продати ---> буває\n",
      "через ---> упаковку\n",
      "зіпсовану ---> упаковку\n",
      "упаковку ---> продати\n",
      "чи ---> пошкодження\n",
      "якісь ---> пошкодження\n",
      "пошкодження ---> продати\n",
      ", ---> впливають\n",
      "які ---> впливають\n",
      "не ---> критично\n",
      "критично ---> впливають\n",
      "впливають ---> пошкодження\n",
      "на ---> ROOT\n",
      "їх ---> на\n",
      "функції ---> на\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цьому реченні перший парсер пропустив слово \"важко\", другий призначив для цього слова дві залежності, а третій призначив два рути :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Дівчина ---> стояла\n",
      "стояла ---> ROOT\n",
      "стояла ---> була\n",
      "там ---> була\n",
      ", ---> там\n",
      ", ---> була\n",
      "де ---> була\n",
      "й ---> була\n",
      "була ---> ROOT\n",
      ", ---> намагалася\n",
      "і ---> намагалася\n",
      "намагалася ---> була\n",
      "привести ---> намагалася\n",
      "до ---> привести\n",
      "ладу ---> до\n",
      "скуйовджене ---> волосся\n",
      "волосся ---> до\n",
      ", ---> розлючена\n",
      "вкрай ---> розлючена\n",
      "розлючена ---> намагалася\n",
      "тим ---> розлючена\n",
      ", ---> побачили\n",
      "що ---> побачили\n",
      "це ---> побачили\n",
      "побачили ---> намагалася\n",
      "водії ---> побачили\n",
      ", ---> чекали\n",
      "які ---> чекали\n",
      "чекали ---> побачили\n",
      "на ---> переїзді\n",
      "переїзді ---> намагалася\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Дівчина --nsubj--> стояла\n",
      "стояла --root--> ROOT\n",
      "там --discourse--> була\n",
      ", --punct--> була\n",
      "де --discourse--> була\n",
      "й --cc--> була\n",
      "була --conj--> стояла\n",
      ", --punct--> намагалася\n",
      "і --cc--> намагалася\n",
      "намагалася --conj--> була\n",
      "привести --xcomp--> намагалася\n",
      "до --nsubj--> привести\n",
      "ладу --nmod--> до\n",
      "скуйовджене --amod--> волосся\n",
      "волосся --conj--> до\n",
      ", --punct--> розлючена\n",
      "вкрай --advmod--> розлючена\n",
      "розлючена --conj--> намагалася\n",
      "тим --obl--> розлючена\n",
      ", --punct--> побачили\n",
      "що --mark--> побачили\n",
      "це --obj--> побачили\n",
      "побачили --acl--> тим\n",
      "водії --obl--> побачили\n",
      ", --punct--> чекали\n",
      "які --nsubj--> чекали\n",
      "чекали --acl--> водії\n",
      "переїзді --nmod--> водії\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Дівчина ---> стояла\n",
      "стояла ---> ROOT\n",
      "там ---> ROOT\n",
      ", ---> була\n",
      "де ---> була\n",
      "й ---> була\n",
      "була ---> там\n",
      ", ---> намагалася\n",
      "і ---> намагалася\n",
      "намагалася ---> була\n",
      "привести ---> намагалася\n",
      "до ---> привести\n",
      "ладу ---> до\n",
      "скуйовджене ---> волосся\n",
      "волосся ---> до\n",
      ", ---> розлючена\n",
      "вкрай ---> розлючена\n",
      "розлючена ---> волосся\n",
      "тим ---> розлючена\n",
      ", ---> побачили\n",
      "що ---> побачили\n",
      "це ---> побачили\n",
      "побачили ---> розлючена\n",
      "водії ---> побачили\n",
      ", ---> чекали\n",
      "які ---> чекали\n",
      "чекали ---> водії\n",
      "на ---> чекали\n",
      "переїзді ---> чекали\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У перших двох випадках по декілька повторів :( А третій парсер порівняно непогано промаркував усе, крім рутів, яких знову два."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Тисячі ---> вийшли\n",
      "людей ---> Тисячі\n",
      "людей ---> вийшли\n",
      "знову ---> вийшли\n",
      "вийшли ---> ROOT\n",
      "на ---> продовжити\n",
      "Єревана ---> вулиці\n",
      "після ---> заклику\n",
      "заклику ---> Єревана\n",
      "лідера ---> заклику\n",
      "опозиції ---> лідера\n",
      "продовжити ---> вийшли\n",
      "протести ---> продовжити\n",
      ", ---> вийшли\n",
      "щоб ---> завершити\n",
      "завершити ---> вийшли\n",
      "оксамитову ---> революцію\n",
      "революцію ---> завершити\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Тисячі --obl--> вийшли\n",
      "людей --nmod--> Тисячі\n",
      "знову --advmod--> вийшли\n",
      "вийшли --advcl--> завершити\n",
      "вийшли --root--> ROOT\n",
      "на --discourse--> продовжити\n",
      "Єревана --nmod--> вулиці\n",
      "після --advmod--> заклику\n",
      "заклику --nmod--> Єревана\n",
      "лідера --nmod--> заклику\n",
      "опозиції --nmod--> лідера\n",
      "продовжити --conj--> вийшли\n",
      "протести --nsubj--> продовжити\n",
      ", --punct--> вийшли\n",
      ", --punct--> завершити\n",
      "щоб --discourse--> завершити\n",
      "оксамитову --amod--> революцію\n",
      "революцію --obj--> завершити\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Тисячі ---> вийшли\n",
      "людей ---> Тисячі\n",
      "знову ---> вийшли\n",
      "вийшли ---> ROOT\n",
      "на ---> заклику\n",
      "вулиці ---> на\n",
      "Єревана ---> вулиці\n",
      "після ---> заклику\n",
      "заклику ---> вийшли\n",
      "лідера ---> заклику\n",
      "опозиції ---> лідера\n",
      "продовжити ---> вийшли\n",
      "протести ---> продовжити\n",
      ", ---> завершити\n",
      "щоб ---> завершити\n",
      "завершити ---> продовжити\n",
      "оксамитову ---> революцію\n",
      "революцію ---> завершити\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут чомусь ще знову повтори у перших двох парсерах. Третій парсер цього разу найадекватніший, хоча теж є помітні помилки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled parsing:\n",
      "\n",
      "Одного ---> ранку\n",
      "ранку ---> прокинувшись\n",
      ", ---> прокинувшись\n",
      "прокинувшись ---> ROOT\n",
      "прокинувшись ---> побачив\n",
      "од ---> прокинувшись\n",
      "неспокійного ---> сну\n",
      "сну ---> од\n",
      ", ---> Грегор\n",
      "Грегор ---> од\n",
      "Грегор ---> побачив\n",
      "Замза ---> Грегор\n",
      "побачив ---> ROOT\n",
      ", ---> обернувся\n",
      "що ---> обернувся\n",
      "він ---> обернувся\n",
      "обернувся ---> побачив\n",
      "страхітливу ---> комаху\n",
      "комаху ---> обернувся\n",
      "\n",
      "=======================\n",
      "\n",
      "Labeled parsing:\n",
      "\n",
      "Одного --obl--> побачив\n",
      "ранку --nmod--> Одного\n",
      ", --punct--> прокинувшись\n",
      "прокинувшись --advcl--> побачив\n",
      "прокинувшись --nmod--> Одного\n",
      "од --obj--> прокинувшись\n",
      "неспокійного --amod--> сну\n",
      "сну --nmod--> од\n",
      ", --punct--> Грегор\n",
      "Грегор --nsubj--> прокинувшись\n",
      "побачив --root--> ROOT\n",
      ", --punct--> обернувся\n",
      "що --mark--> обернувся\n",
      "він --nsubj--> обернувся\n",
      "обернувся --ccomp--> побачив\n",
      "страхітливу --amod--> комаху\n",
      "комаху --obj--> обернувся\n",
      "\n",
      "=======================\n",
      "\n",
      "Dynamic oracle parsing:\n",
      "\n",
      "Одного ---> ранку\n",
      "ранку ---> ROOT\n",
      ", ---> прокинувшись\n",
      "прокинувшись ---> ранку\n",
      "од ---> прокинувшись\n",
      "неспокійного ---> сну\n",
      "сну ---> од\n",
      ", ---> побачив\n",
      "Грегор ---> побачив\n",
      "Замза ---> Грегор\n",
      "побачив ---> прокинувшись\n",
      ", ---> обернувся\n",
      "що ---> обернувся\n",
      "він ---> обернувся\n",
      "обернувся ---> побачив\n",
      "на ---> комаху\n",
      "страхітливу ---> комаху\n",
      "комаху ---> обернувся\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_parsers(sentences[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А тут третій парсер найгірший: він промаркував \"ранку\" як рут, хоча pymorphy2 це слово парсить як іменник (з лемою \"ранка\", але все ж). Тільки другий парсер побачив рут у слові \"побачив\", але підмет Грегор призначив слову \"прокинувшись\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загальні висновки:\n",
    "\n",
    "- українська мова має проблему з непроективними деревами. Можливо, варто пробувати також graph-based алгоритми парсингу;\n",
    "- біграми, триграми, та інші додаткові фічі дають покращення 6-9 відсоткових пунктів до UAS, і 5 відсоткових пунктів до F1 при класифікації;\n",
    "- невелика кількість тренувальних даних (всього кілька тисяч речень) ускладнює роботу labeled парсера для рідкісних типів залежностей;\n",
    "- динамічний оракул дозволяє досягнути до 80% UAS на тестовій вибірці;\n",
    "- я не встиг вирішити проблему, коли парсер призначає більш ніж один head тому самому слову або дає два рути для одного речення. По ідеї, потрібно заборонити функції predict_relations ставити ліву або праву арку для слова, яке вже має head; але тоді функція повинна обрати іншу дію, а отже класифікатор має видавати для розгляду функції не одну дію, а кілька проранжованих за імовірністю;\n",
    "- в цілому ж тестування на \"реальних\" реченнях показує відносно непогані результати в коротких реченнях, але дуже дивні рішення в довших і складніших."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
